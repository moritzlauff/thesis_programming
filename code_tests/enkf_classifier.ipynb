{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import mnist_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enkf_classifier(X_train,\n",
    "                    X_test,\n",
    "                    y_train,\n",
    "                    y_test,\n",
    "                    layers,\n",
    "                    neurons,\n",
    "                    particles,\n",
    "                    epochs,\n",
    "                    batch_size = None,\n",
    "                    h_0 = 2,\n",
    "                    delta = 0.005,\n",
    "                    epsilon = 0.5,\n",
    "                    randomization = False,\n",
    "                    shuffle = True,\n",
    "                    early_stopping = False,\n",
    "                    early_stopping_diff = 0.001\n",
    "                    ):\n",
    "\n",
    "    \"\"\" Function to define the structure of a neural network.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train (np.ndarray): Training data X.\n",
    "    X_test (np.ndarray): Test data X.\n",
    "    y_train (pd.DataFrame): Training data y.\n",
    "    y_test (pd.DataFrame): Test data y.\n",
    "    layers (int): Number of layers.\n",
    "    neurons (list): Number of neurons in each layer.\n",
    "    particles (int): Number of particles in the ensemble.\n",
    "    epochs (int): Number of epochs.\n",
    "    batch_size (None or int): Size of the batches. Must be between 0 and the number of observations in the training set.\n",
    "    h_0 (int or float): Starting step size.\n",
    "    delta (float): Constant for numerical stability in the jacobian.\n",
    "    epsilon (float): Constant for numerical stability in the step size.\n",
    "    randomization (bool): Whether or not to add noise to the particles and randomize them around their mean.\n",
    "    shuffle (bool): Whether or not to shuffle the data prior to each epoch.\n",
    "    early_stopping (bool): Whether or not to stop the calculation when the changes get small.\n",
    "    early_stopping_diff (bool): Minimum change before early stopping is applied.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    mean_model (tensorflow.python.keras.engine.sequential.Sequential): The final model.\n",
    "    mean_model_train_acc (list): Training accuracies of the averaged model after each epoch.\n",
    "    mean_model_test_acc (list): Test accuracies of the averaged model after each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_size == None:\n",
    "        batch_size = len(X_train)\n",
    "\n",
    "    n_cols = X_train.shape[1]\n",
    "\n",
    "    n = len(X_train)\n",
    "    num_batches = int(np.ceil(n / batch_size))\n",
    "    batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "    batch_indices[-1] = n\n",
    "\n",
    "    model_dict = {}\n",
    "    weights_dict = {}\n",
    "    y_pred_dict = {}\n",
    "    jacobian_dict = {}\n",
    "    weights_vector_dict = {}\n",
    "    train_acc_dict = {}\n",
    "    test_acc_dict = {}\n",
    "    iteration_dict = {}\n",
    "\n",
    "    # init_model already has weights and biases following the Glorot distribution\n",
    "    # it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "    # only used to determine shapes and shape_elements via its weights\n",
    "    init_model = nn_model_structure(layers = layers,\n",
    "                                    neurons = neurons,\n",
    "                                    n_cols = n_cols)\n",
    "    init_model = nn_model_compile(init_model,\n",
    "                                  optimizer = \"sgd\")\n",
    "    weights = init_model.get_weights()\n",
    "    # shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "    shapes = [np.array(params.shape) for params in weights]\n",
    "    # shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "    shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])\n",
    "\n",
    "    for i in range(particles):\n",
    "        # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "        model = nn_model_structure(layers = layers,\n",
    "                                   neurons = neurons,\n",
    "                                   n_cols = n_cols)\n",
    "        model = nn_model_compile(model,\n",
    "                                 optimizer = \"sgd\")\n",
    "        # for every particle write the model in a dictionary\n",
    "        model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "\n",
    "        # for every particles write the weights and biases in a dictionary\n",
    "        weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .get_weights()\n",
    "\n",
    "        train_acc_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        test_acc_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        iteration_dict[\"model_{}\".format(str(i+1))] = []\n",
    "\n",
    "    # mean_model as the model with the mean of the weights of all particle models\n",
    "    mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "    mean_model = init_model\n",
    "    mean_model.set_weights(mean_weights)\n",
    "\n",
    "    mean_model_train_acc = np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1])\n",
    "    mean_model_test_acc = np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "    # loop over all epochs\n",
    "    for epoch in range(epochs):\n",
    "        # early stopping\n",
    "        if early_stopping:\n",
    "            if epoch == 0:\n",
    "                train_acc_old = 0\n",
    "                test_acc_old = 0\n",
    "            else:\n",
    "                train_acc_new = mean_model_train_acc[epoch]\n",
    "                test_acc_new = mean_model_test_acc[epoch]\n",
    "                if np.absolute(test_acc_new - test_acc_old) <= early_stopping_diff and np.absolute(train_acc_new - train_acc_old) <= early_stopping_diff:\n",
    "                    print(\"STOP: Early Stopping after epoch {} because improvement in training accuracy is only {} and in test accuracy only {}.\"\\\n",
    "                                                                         .format(epoch+1, train_acc_new - train_acc_old, test_acc_new - test_acc_old))\n",
    "                    return mean_model, mean_model_train_acc, mean_model_test_acc\n",
    "                test_acc_old = test_acc_new\n",
    "        # shuffle the data\n",
    "        if shuffle:\n",
    "            indices = y_train.sample(frac=1).index\n",
    "            X_batches = [X_train[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        # loop over all batches\n",
    "        for b in range(num_batches):\n",
    "            for i in range(particles):\n",
    "                # set new weights for model\n",
    "                model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "\n",
    "                # for every particle write the predictions on the training batches in a dictionary\n",
    "                y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                .predict(X_batches[b])\n",
    "\n",
    "                # for every particle write the Jacobian in a dictionary\n",
    "                jacobian_dict[\"model_{}\".format(str(i+1))] = (-1) * np.multiply(np.array(y_batches[b]),\n",
    "                                                                                np.array(1 / (y_pred_dict[\"model_{}\".format(str(i+1))] + delta)))\n",
    "\n",
    "            # compute the mean of the predictions\n",
    "            y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "            # compute the matrix D elementwise\n",
    "            d = np.zeros(shape = (particles, particles))\n",
    "            for k in range(particles):\n",
    "                y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                for j in range(particles):\n",
    "                    d[k][j] = np.sum(np.multiply(y_pred_centered, jacobian_dict[\"model_{}\".format(str(j+1))]))\n",
    "            d = np.transpose(d)\n",
    "\n",
    "            # compute the scalar h_t\n",
    "            h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "            # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "            for i in range(particles):\n",
    "                weights_array = np.array([])\n",
    "                for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                    weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "            # matrix with particle parameters as row vectors\n",
    "            weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "            # compute the matrix with the updates for each particle\n",
    "            weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "            for i in range(particles):\n",
    "                # write the updates back into the dictionary\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                for l in range(len(shape_elements)-1):\n",
    "                    start = shape_elements[l]\n",
    "                    end = shape_elements[l+1]\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                if randomization:\n",
    "                    # add randomization/ noise to each particle\n",
    "                    new_weights = []\n",
    "                    # standard deviation for scaled Glorot distribution\n",
    "                    for s in range(len(shapes)):\n",
    "                        if shapes[s].shape[0] == 2:\n",
    "                            fan_in = shapes[s][0]\n",
    "                            fan_out = shapes[s][1]\n",
    "                        if shapes[s].shape[0] == 1:\n",
    "                            fan_in = shapes[s-1][0]\n",
    "                            fan_out = shapes[s][0]\n",
    "                        stddev = np.sqrt(np.sqrt(h_t)) * np.sqrt(2 / (fan_in + fan_out))\n",
    "                        noise = np.random.normal(loc = 0.0,\n",
    "                                                 scale = stddev,\n",
    "                                                 size = tuple(shapes[s]))\n",
    "                        new_weights.append(weights_dict[\"model_{}\".format(str(i+1))][s] + noise)\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))] = new_weights\n",
    "\n",
    "        if randomization:\n",
    "            # randomize particles around their mean\n",
    "            weights_mean = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "            for i in range(particles):\n",
    "                new_weights = []\n",
    "                # standard deviation for Glorot distribution\n",
    "                for s in range(len(shapes)):\n",
    "                    if shapes[s].shape[0] == 2:\n",
    "                        fan_in = shapes[s][0]\n",
    "                        fan_out = shapes[s][1]\n",
    "                    if shapes[s].shape[0] == 1:\n",
    "                        fan_in = shapes[s-1][0]\n",
    "                        fan_out = shapes[s][0]\n",
    "                    stddev = np.sqrt(2 / (fan_in + fan_out))\n",
    "                    noise = np.random.normal(loc = 0.0,\n",
    "                                             scale = stddev,\n",
    "                                             size = tuple(shapes[s]))\n",
    "                    new_weights.append(weights_mean[s] + noise)\n",
    "                weights_dict[\"model_{}\".format(str(i+1))] = new_weights\n",
    "\n",
    "        for i in range(particles):\n",
    "            # for every particle write the training accuracy of the current iteration in a dictionary\n",
    "            train_acc_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the test accuracy of the current iteration in a dictionary\n",
    "            test_acc_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the current iteration in a dictionary\n",
    "            iteration_dict[\"model_{}\".format(str(i+1))].append(\"Epoch: {}, Batch: {}.\".format(epoch+1, b+1))\n",
    "\n",
    "        # update the mean_model\n",
    "        mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "        mean_model.set_weights(mean_weights)\n",
    "\n",
    "        mean_model_train_acc = np.append(mean_model_train_acc, np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1]))\n",
    "        mean_model_test_acc = np.append(mean_model_test_acc, np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1]))\n",
    "\n",
    "    return mean_model, mean_model_train_acc, mean_model_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = mnist_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train_small = X_train[:1000, :]\n",
    "X_val_small = X_val[:500, :]\n",
    "y_train_small = y_train[:1000]\n",
    "y_val_small = y_val[:500]\n",
    "\n",
    "n_cols = X_train_small.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_small\n",
    "X_test = X_val_small\n",
    "y_train = y_train_small\n",
    "y_test = y_val_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50     # len(X_train)\n",
    "epochs = 10\n",
    "particles = 100\n",
    "early_stopping = False\n",
    "early_stopping_diff = 0.001\n",
    "shuffle = True\n",
    "randomization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 5\n",
    "neurons = [128, 128, 64, 32, 10]\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "h_0 = 2\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model, mean_model_train_acc, mean_model_test_acc = enkf_classifier(X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        layers,\n",
    "                                                                        neurons,\n",
    "                                                                        particles,\n",
    "                                                                        epochs,\n",
    "                                                                        batch_size,\n",
    "                                                                        h_0,\n",
    "                                                                        delta,\n",
    "                                                                        epsilon,\n",
    "                                                                        randomization,\n",
    "                                                                        shuffle,\n",
    "                                                                        early_stopping,\n",
    "                                                                        early_stopping_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation time: 12.772048087914785 minutes.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(\"Calculation time: {} minutes.\".format((end_time - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_epoch_acc(mean_model_train_acc,\n",
    "                  mean_model_test_acc,\n",
    "                  mean_comparison = 0.1,\n",
    "                  savefig = False,\n",
    "                  file = \"../img/enkf_model_mnist_E{}_B{}_P{}_H{}.png\".format(epochs, batch_size, particles, h_0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nn_save(mean_model, \n",
    "        \"../models/enkf_model_mnist_E{}_B{}_P{}_H{}.h5\".format(epochs, batch_size, particles, h_0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
