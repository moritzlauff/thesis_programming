{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import mnist_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enkf_classifier(X_train,\n",
    "                    X_test,\n",
    "                    y_train,\n",
    "                    y_test,\n",
    "                    layers,\n",
    "                    neurons,\n",
    "                    particles,\n",
    "                    epochs,\n",
    "                    batch_size = None,\n",
    "                    h_0 = 2,\n",
    "                    delta = 0.005,\n",
    "                    epsilon = 0.5,\n",
    "                    randomization = False,\n",
    "                    shuffle = True,\n",
    "                    early_stopping = False,\n",
    "                    early_stopping_diff = 0.001\n",
    "                    ):\n",
    "\n",
    "    \"\"\" Function to define the structure of a neural network.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train (np.ndarray): Training data X.\n",
    "    X_test (np.ndarray): Test data X.\n",
    "    y_train (pd.DataFrame): Training data y.\n",
    "    y_test (pd.DataFrame): Test data y.\n",
    "    layers (int): Number of layers.\n",
    "    neurons (list): Number of neurons in each layer.\n",
    "    particles (int): Number of particles in the ensemble.\n",
    "    epochs (int): Number of epochs.\n",
    "    batch_size (None or int): Size of the batches. Must be between 0 and the number of observations in the training set.\n",
    "    h_0 (int or float): Starting step size.\n",
    "    delta (float): Constant for numerical stability in the jacobian.\n",
    "    epsilon (float): Constant for numerical stability in the step size.\n",
    "    randomization (bool): Whether or not to add noise to the particles and randomize them around their mean.\n",
    "    shuffle (bool): Whether or not to shuffle the data prior to each epoch.\n",
    "    early_stopping (bool): Whether or not to stop the calculation when the changes get small.\n",
    "    early_stopping_diff (bool): Minimum change before early stopping is applied.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    mean_model (tensorflow.python.keras.engine.sequential.Sequential): The final model.\n",
    "    mean_model_train_acc (list): Training accuracies of the averaged model after each epoch.\n",
    "    mean_model_test_acc (list): Test accuracies of the averaged model after each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_size == None:\n",
    "        batch_size = len(X_train)\n",
    "\n",
    "    n_cols = X_train.shape[1]\n",
    "\n",
    "    n = len(X_train)\n",
    "    num_batches = int(np.ceil(n / batch_size))\n",
    "    batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "    batch_indices[-1] = n\n",
    "\n",
    "    model_dict = {}\n",
    "    weights_dict = {}\n",
    "    y_pred_dict = {}\n",
    "    jacobian_dict = {}\n",
    "    weights_vector_dict = {}\n",
    "    train_acc_dict = {}\n",
    "    test_acc_dict = {}\n",
    "    iteration_dict = {}\n",
    "\n",
    "    # init_model already has weights and biases following the Glorot distribution\n",
    "    # it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "    # only used to determine shapes and shape_elements via its weights\n",
    "    init_model = nn_model_structure(layers = layers,\n",
    "                                    neurons = neurons,\n",
    "                                    n_cols = n_cols)\n",
    "    init_model = nn_model_compile(init_model,\n",
    "                                  optimizer = \"sgd\")\n",
    "    weights = init_model.get_weights()\n",
    "    # shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "    shapes = [np.array(params.shape) for params in weights]\n",
    "    # shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "    shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])\n",
    "\n",
    "    for i in range(particles):\n",
    "        # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "        model = nn_model_structure(layers = layers,\n",
    "                                   neurons = neurons,\n",
    "                                   n_cols = n_cols)\n",
    "        model = nn_model_compile(model,\n",
    "                                 optimizer = \"sgd\")\n",
    "        # for every particle write the model in a dictionary\n",
    "        model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "\n",
    "        # for every particles write the weights and biases in a dictionary\n",
    "        weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .get_weights()\n",
    "\n",
    "        train_acc_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        test_acc_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        iteration_dict[\"model_{}\".format(str(i+1))] = []\n",
    "\n",
    "    # mean_model as the model with the mean of the weights of all particle models\n",
    "    mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "    mean_model = init_model\n",
    "    mean_model.set_weights(mean_weights)\n",
    "\n",
    "    mean_model_train_acc = np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1])\n",
    "    mean_model_test_acc = np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "    # loop over all epochs\n",
    "    for epoch in range(epochs):\n",
    "        # early stopping\n",
    "        if early_stopping:\n",
    "            if epoch == 0:\n",
    "                train_acc_old = 0\n",
    "                test_acc_old = 0\n",
    "            else:\n",
    "                train_acc_new = mean_model_train_acc[epoch]\n",
    "                test_acc_new = mean_model_test_acc[epoch]\n",
    "                if np.absolute(test_acc_new - test_acc_old) <= early_stopping_diff and np.absolute(train_acc_new - train_acc_old) <= early_stopping_diff:\n",
    "                    print(\"STOP: Early Stopping after epoch {} because improvement in training accuracy is only {} and in test accuracy only {}.\"\\\n",
    "                                                                         .format(epoch+1, train_acc_new - train_acc_old, test_acc_new - test_acc_old))\n",
    "                    return mean_model, mean_model_train_acc, mean_model_test_acc\n",
    "                test_acc_old = test_acc_new\n",
    "        # shuffle the data\n",
    "        if shuffle:\n",
    "            indices = y_train.sample(frac=1).index\n",
    "            X_batches = [X_train[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        # loop over all batches\n",
    "        for b in range(num_batches):\n",
    "            for i in range(particles):\n",
    "                # set new weights for model\n",
    "                model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "\n",
    "                # for every particle write the predictions on the training batches in a dictionary\n",
    "                y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                .predict(X_batches[b])\n",
    "\n",
    "                # for every particle write the Jacobian in a dictionary\n",
    "                jacobian_dict[\"model_{}\".format(str(i+1))] = (-1) * np.multiply(np.array(y_batches[b]),\n",
    "                                                                                np.array(1 / (y_pred_dict[\"model_{}\".format(str(i+1))] + delta)))\n",
    "\n",
    "            # compute the mean of the predictions\n",
    "            y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "            # compute the matrix D elementwise\n",
    "            d = np.zeros(shape = (particles, particles))\n",
    "            for k in range(particles):\n",
    "                y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                for j in range(particles):\n",
    "                    d[k][j] = np.sum(np.multiply(y_pred_centered, jacobian_dict[\"model_{}\".format(str(j+1))]))\n",
    "            d = np.transpose(d)\n",
    "\n",
    "            # compute the scalar h_t\n",
    "            h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "            # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "            for i in range(particles):\n",
    "                weights_array = np.array([])\n",
    "                for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                    weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "            # matrix with particle parameters as row vectors\n",
    "            weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "            # compute the matrix with the updates for each particle\n",
    "            weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "            for i in range(particles):\n",
    "                # write the updates back into the dictionary\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                for l in range(len(shape_elements)-1):\n",
    "                    start = shape_elements[l]\n",
    "                    end = shape_elements[l+1]\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                if randomization:\n",
    "                    # add randomization/ noise to each particle\n",
    "                    new_weights = []\n",
    "                    # standard deviation for scaled Glorot distribution\n",
    "                    for s in range(len(shapes)):\n",
    "                        if shapes[s].shape[0] == 2:\n",
    "                            fan_in = shapes[s][0]\n",
    "                            fan_out = shapes[s][1]\n",
    "                        if shapes[s].shape[0] == 1:\n",
    "                            fan_in = shapes[s-1][0]\n",
    "                            fan_out = shapes[s][0]\n",
    "                        stddev = np.sqrt(np.sqrt(h_t)) * np.sqrt(2 / (fan_in + fan_out))\n",
    "                        noise = np.random.normal(loc = 0.0,\n",
    "                                                 scale = stddev,\n",
    "                                                 size = tuple(shapes[s]))\n",
    "                        new_weights.append(weights_dict[\"model_{}\".format(str(i+1))][s] + noise)\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))] = new_weights\n",
    "\n",
    "        if randomization:\n",
    "            # randomize particles around their mean\n",
    "            weights_mean = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "            for i in range(particles):\n",
    "                new_weights = []\n",
    "                # standard deviation for Glorot distribution\n",
    "                for s in range(len(shapes)):\n",
    "                    if shapes[s].shape[0] == 2:\n",
    "                        fan_in = shapes[s][0]\n",
    "                        fan_out = shapes[s][1]\n",
    "                    if shapes[s].shape[0] == 1:\n",
    "                        fan_in = shapes[s-1][0]\n",
    "                        fan_out = shapes[s][0]\n",
    "                    stddev = np.sqrt(2 / (fan_in + fan_out))\n",
    "                    noise = np.random.normal(loc = 0.0,\n",
    "                                             scale = stddev,\n",
    "                                             size = tuple(shapes[s]))\n",
    "                    new_weights.append(weights_mean[s] + noise)\n",
    "                weights_dict[\"model_{}\".format(str(i+1))] = new_weights\n",
    "\n",
    "        for i in range(particles):\n",
    "            # for every particle write the training accuracy of the current iteration in a dictionary\n",
    "            train_acc_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the test accuracy of the current iteration in a dictionary\n",
    "            test_acc_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the current iteration in a dictionary\n",
    "            iteration_dict[\"model_{}\".format(str(i+1))].append(\"Epoch: {}, Batch: {}.\".format(epoch+1, b+1))\n",
    "\n",
    "        # update the mean_model\n",
    "        mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "        mean_model.set_weights(mean_weights)\n",
    "\n",
    "        mean_model_train_acc = np.append(mean_model_train_acc, np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1]))\n",
    "        mean_model_test_acc = np.append(mean_model_test_acc, np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1]))\n",
    "\n",
    "    return mean_model, mean_model_train_acc, mean_model_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = mnist_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train_small = X_train[:1000, :]\n",
    "X_val_small = X_val[:500, :]\n",
    "y_train_small = y_train[:1000]\n",
    "y_val_small = y_val[:500]\n",
    "\n",
    "n_cols = X_train_small.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_small\n",
    "X_test = X_val_small\n",
    "y_train = y_train_small\n",
    "y_test = y_val_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50     # len(X_train)\n",
    "epochs = 10\n",
    "particles = 50\n",
    "early_stopping = False\n",
    "early_stopping_diff = 0.001\n",
    "shuffle = True\n",
    "randomization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 5\n",
    "neurons = [128, 128, 64, 32, 10]\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "h_0 = 2\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_model, mean_model_train_acc, mean_model_test_acc = enkf_classifier(X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        layers,\n",
    "                                                                        neurons,\n",
    "                                                                        particles,\n",
    "                                                                        epochs,\n",
    "                                                                        batch_size,\n",
    "                                                                        h_0,\n",
    "                                                                        delta,\n",
    "                                                                        epsilon,\n",
    "                                                                        randomization,\n",
    "                                                                        shuffle,\n",
    "                                                                        early_stopping,\n",
    "                                                                        early_stopping_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation time: 13.497794306278228 minutes.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(\"Calculation time: {} minutes.\".format((end_time - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_epoch_acc(mean_model_train_acc,\n",
    "                  mean_model_test_acc,\n",
    "                  mean_comparison = 0.1,\n",
    "                  savefig = False,\n",
    "                  file = \"../img/enkf_model_mnist_E{}_B{}_P{}_H{}.png\".format(epochs, batch_size, particles, h_0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nn_save(mean_model, \n",
    "        \"../models/enkf_model_mnist_E{}_B{}_P{}_H{}.h5\".format(epochs, batch_size, particles, h_0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
