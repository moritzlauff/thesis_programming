{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import bike_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible\n",
    "from training_callback import BatchMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = bike_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:500]\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:500]\n",
    "\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = 3\n",
    "early_stopping = 0.001\n",
    "batch_normal = False # noch einbauen, aber Achtung mit den Dimensionen unten!!!\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 5\n",
    "neurons = [64, 32, 32, 16, 1]\n",
    "n_cols = X_train.shape[1]\n",
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "h_0 = 2\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "num_batches = int(np.ceil(n / batch_size))\n",
    "batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "batch_indices[-1] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "weights_dict = {}\n",
    "y_pred_dict = {}\n",
    "jacobian_dict = {}\n",
    "weights_vector_dict = {}\n",
    "train_mse_dict = {}\n",
    "test_mse_dict = {}\n",
    "iteration_dict = {}\n",
    "\n",
    "# init_model already has weights and biases following the Glorot distribution\n",
    "# it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "# only used to determine shapes and shape_elements via its weights\n",
    "init_model = nn_model_structure(layers = layers,\n",
    "                                neurons = neurons,\n",
    "                                n_cols = n_cols,\n",
    "                                classification = False)\n",
    "init_model = nn_model_compile(init_model,\n",
    "                              optimizer = \"sgd\")\n",
    "weights = init_model.get_weights()\n",
    "# shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "shapes = [np.array(params.shape) for params in weights]\n",
    "# shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(particles):\n",
    "    # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "    model = nn_model_structure(layers = layers,\n",
    "                               neurons = neurons,\n",
    "                               n_cols = n_cols,\n",
    "                               classification = False)\n",
    "    model = nn_model_compile(model,\n",
    "                             optimizer = \"sgd\")\n",
    "    # for every particle write the model in a dictionary\n",
    "    model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "    \n",
    "    # for every particles write the weights and biases in a dictionary\n",
    "    weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                    .get_weights()\n",
    "    \n",
    "    train_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "    test_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "    iteration_dict[\"model_{}\".format(str(i+1))] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 873us/step - loss: 66411.4375 - mse: 66411.4375\n",
      "66411.4375\n",
      "16/16 [==============================] - 0s 806us/step - loss: 66964.4453 - mse: 66964.4453\n",
      "66964.4453125\n",
      "16/16 [==============================] - 0s 795us/step - loss: 66130.4609 - mse: 66130.4609\n",
      "66130.4609375\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47872955, -0.511487  , -0.42715484, -0.48712772, -0.46620053,\n",
       "       -0.5026307 , -0.35378993, -0.46760172, -0.48110506, -0.58408266,\n",
       "       -0.5765587 , -0.44448945, -0.5164765 , -0.5060588 , -0.46371466,\n",
       "       -0.49161887, -0.55356497, -0.5305277 , -0.4989056 , -0.44920608,\n",
       "       -0.49841318, -0.5468869 , -0.5253587 , -0.44356123, -0.5410129 ,\n",
       "       -0.50543875, -0.46908674, -0.4691642 , -0.5358598 , -0.47555184,\n",
       "       -0.52610934, -0.66956687, -0.48787743, -0.37061036, -0.45226723,\n",
       "       -0.5068594 , -0.3432906 , -0.5205811 , -0.4697257 , -0.47698972,\n",
       "       -0.45780292, -0.47396708, -0.40968627, -0.49542427, -0.40776315,\n",
       "       -0.526463  , -0.48711234, -0.4591254 , -0.4986636 , -0.4978826 ,\n",
       "       -0.49697086, -0.5144859 , -0.49164724, -0.46483797, -0.5059922 ,\n",
       "       -0.55      , -0.49043202, -0.47152078, -0.4926811 , -0.45892453,\n",
       "       -0.5360638 , -0.50750875, -0.44052416, -0.4764443 , -0.45755547,\n",
       "       -0.4982125 , -0.44433403, -0.49109983, -0.4724952 , -0.53093004,\n",
       "       -0.36360136, -0.4155563 , -0.6001374 , -0.45452368, -0.52850926,\n",
       "       -0.46104848, -0.39248362, -0.42094955, -0.57983166, -0.43507567,\n",
       "       -0.46663943, -0.21262623, -0.48904383, -0.52781785, -0.46547872,\n",
       "       -0.45643443, -0.507012  , -0.50814915, -0.4980487 , -0.5314303 ,\n",
       "       -0.52723056, -0.45676374, -0.47769612, -0.5121184 , -0.30698624,\n",
       "       -0.48557225, -0.6033782 , -0.5015427 , -0.43499732, -0.25784504,\n",
       "       -0.48478654, -0.51367354, -0.56831384, -0.5589471 , -0.43366027,\n",
       "       -0.2352095 , -0.56242555, -0.511743  , -0.4869631 , -0.49856865,\n",
       "       -0.44779304, -0.46998167, -0.4665429 , -0.48841906, -0.5201006 ,\n",
       "       -0.46637446, -0.45985705, -0.6213958 , -0.60942614, -0.49268448,\n",
       "       -0.45097244, -0.48533082, -0.40569377, -0.4697297 , -0.5223253 ,\n",
       "       -0.41564977, -0.4594155 , -0.46074888, -0.5267391 , -0.3033636 ,\n",
       "       -0.54469687, -0.50931865, -0.45484954, -0.5071139 , -0.5281507 ,\n",
       "       -0.47887135, -0.49536163, -0.6842097 , -0.60659665, -0.49503845,\n",
       "       -0.4568239 , -0.5732258 , -0.52464366, -0.46357676, -0.41087186,\n",
       "       -0.44720334, -0.3975671 , -0.45150378, -0.5539002 , -0.23314518,\n",
       "       -0.51594675, -0.53499675, -0.27717575, -0.4469039 , -0.45608667,\n",
       "       -0.50170475, -0.3369519 , -0.3973385 , -0.31349358, -0.49004415,\n",
       "       -0.56372255, -0.54800975, -0.5051161 , -0.51658344, -0.50919074,\n",
       "       -0.46443027, -0.4388022 , -0.42256048, -0.5044601 , -0.5578159 ,\n",
       "       -0.44175047, -0.31336987, -0.47463474, -0.45448023, -0.43546596,\n",
       "       -0.49962363, -0.57045627, -0.4972646 , -0.41531217, -0.51115173,\n",
       "       -0.48172265, -0.49844778, -0.43352383, -0.47300598, -0.4503663 ,\n",
       "       -0.5157873 , -0.50709677, -0.44974303, -0.5151354 , -0.5016363 ,\n",
       "       -0.63054717, -0.4241493 , -0.66881144, -0.57615083, -0.49902964,\n",
       "       -0.40124816, -0.5253478 , -0.517946  , -0.49619785, -0.44170642,\n",
       "       -0.29718527, -0.47956   , -0.261321  , -0.49299884, -0.43027982,\n",
       "       -0.24051425, -0.46080336, -0.5195433 , -0.480506  , -0.510067  ,\n",
       "       -0.46284902, -0.34796998, -0.48746103, -0.50612956, -0.5100072 ,\n",
       "       -0.49253976, -0.5913015 , -0.3417307 , -0.47125736, -0.48990554,\n",
       "       -0.578716  , -0.5174893 , -0.4363934 , -0.47979444, -0.5329005 ,\n",
       "       -0.6264922 , -0.21597816, -0.36010182, -0.54294425, -0.61576086,\n",
       "       -0.5393897 , -0.50201935, -0.6505238 , -0.56134933, -0.4973126 ,\n",
       "       -0.4427415 , -0.5059895 , -0.4646823 , -0.4992024 , -0.54292285,\n",
       "       -0.47889838, -0.46833804, -0.3540014 , -0.42700127, -0.38961214,\n",
       "       -0.5146075 , -0.51392126, -0.51112986, -0.44401196, -0.52437896,\n",
       "       -0.49795777, -0.46487582, -0.42635164, -0.46797842, -0.46014094,\n",
       "       -0.44197738, -0.51540136, -0.46315104, -0.54015106, -0.62407243,\n",
       "       -0.4303583 , -0.49418977, -0.46120808, -0.5420662 , -0.43614954,\n",
       "       -0.5100908 , -0.25841555, -0.23854855, -0.54938245, -0.57106966,\n",
       "       -0.38421983, -0.5121871 , -0.54518604, -0.46201032, -0.4842788 ,\n",
       "       -0.4793445 , -0.3769705 , -0.45968848, -0.48067716, -0.544468  ,\n",
       "       -0.5117797 , -0.41175726, -0.5481284 , -0.39027447, -0.5029208 ,\n",
       "       -0.546868  , -0.4827175 , -0.4353    , -0.514599  , -0.50471663,\n",
       "       -0.26223928, -0.4402868 , -0.5571941 , -0.56973565, -0.5143627 ,\n",
       "       -0.41850463, -0.5295223 , -0.5040475 , -0.43355379, -0.5481757 ,\n",
       "       -0.4296174 , -0.48633683, -0.47013333, -0.4776973 , -0.53627384,\n",
       "       -0.65694904, -0.44898856, -0.45885044, -0.34185243, -0.46223232,\n",
       "       -0.49637187, -0.546807  , -0.4035899 , -0.58881575, -0.5211898 ,\n",
       "       -0.605857  , -0.50045824, -0.520156  , -0.49460158, -0.5548494 ,\n",
       "       -0.6311981 , -0.41600245, -0.5391823 , -0.3563662 , -0.52505004,\n",
       "       -0.58980304, -0.50877124, -0.4619646 , -0.21890913, -0.6581061 ,\n",
       "       -0.48112407, -0.47741395, -0.21674272, -0.4019274 , -0.42837554,\n",
       "       -0.577327  , -0.5620866 , -0.5052457 , -0.5835091 , -0.46291804,\n",
       "       -0.331103  , -0.51695216, -0.48692793, -0.48695406, -0.4714483 ,\n",
       "       -0.40343633, -0.52143514, -0.63129556, -0.55396366, -0.5050037 ,\n",
       "       -0.5929043 , -0.48501888, -0.49337074, -0.5150745 , -0.52961344,\n",
       "       -0.5251943 , -0.5427861 , -0.4783171 , -0.4434367 , -0.52452016,\n",
       "       -0.54124814, -0.50183463, -0.41752014, -0.4182602 , -0.46013525,\n",
       "       -0.5054027 , -0.44040895, -0.39656615, -0.27652672, -0.5166801 ,\n",
       "       -0.5981464 , -0.40993026, -0.50359356, -0.52445996, -0.48894426,\n",
       "       -0.5931874 , -0.5008966 , -0.43908364, -0.45968148, -0.4734413 ,\n",
       "       -0.43931496, -0.5071318 , -0.43473622, -0.39188713, -0.52293575,\n",
       "       -0.41140822, -0.41183695, -0.5619229 , -0.5136555 , -0.521619  ,\n",
       "       -0.43996042, -0.43343368, -0.44212168, -0.42810142, -0.4964025 ,\n",
       "       -0.5292217 , -0.48750955, -0.49273854, -0.39818472, -0.41744065,\n",
       "       -0.45354652, -0.36879447, -0.49187452, -0.49940327, -0.42112705,\n",
       "       -0.46401986, -0.4606495 , -0.42000234, -0.4856971 , -0.57571983,\n",
       "       -0.39238268, -0.72804105, -0.4775755 , -0.55186033, -0.5008111 ,\n",
       "       -0.5371984 , -0.44291332, -0.43394417, -0.43239674, -0.51371753,\n",
       "       -0.61072636, -0.4637444 , -0.38689113, -0.4233951 , -0.47793227,\n",
       "       -0.5050311 , -0.49753743, -0.5681807 , -0.44600278, -0.5822512 ,\n",
       "       -0.54797816, -0.3937589 , -0.46051216, -0.48314935, -0.37490267,\n",
       "       -0.5007303 , -0.44465154, -0.57507104, -0.43331295, -0.37517184,\n",
       "       -0.49533767, -0.5532038 , -0.5470806 , -0.44395757, -0.5876451 ,\n",
       "       -0.48804873, -0.46581054, -0.51736784, -0.50890434, -0.505378  ,\n",
       "       -0.5377176 , -0.4938873 , -0.37247637, -0.47775865, -0.50860953,\n",
       "       -0.47908288, -0.4853472 , -0.44361788, -0.49485815, -0.52749777,\n",
       "       -0.4846112 , -0.33864534, -0.4254301 , -0.47547385, -0.47998923,\n",
       "       -0.47894457, -0.24564356, -0.4246866 , -0.5500933 , -0.6293482 ,\n",
       "       -0.50254136, -0.44504243, -0.27480364, -0.59357667, -0.45672393,\n",
       "       -0.49961698, -0.50562656, -0.5430717 , -0.49749076, -0.47085246,\n",
       "       -0.47024685, -0.5457451 , -0.5065832 , -0.4844482 , -0.5565175 ,\n",
       "       -0.54507947, -0.5518073 , -0.22099756, -0.41456857, -0.27378753,\n",
       "       -0.58283114, -0.5266077 , -0.5437608 , -0.41283083, -0.59603226,\n",
       "       -0.44732404, -0.5233461 , -0.5003646 , -0.46745133, -0.49785143],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[\"model_1\"].predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all epochs\n",
    "for epoch in range(epochs):\n",
    "    # shuffle the data\n",
    "    if shuffle:\n",
    "        indices = y_train.sample(frac=1).index\n",
    "        X_batches = [np.array(X_train)[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        y_batches = [np.array(i) for i in y_batches]\n",
    "    # loop over all batches\n",
    "    for b in range(num_batches):    \n",
    "        for i in range(particles):\n",
    "            # set new weights for model\n",
    "            model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "            \n",
    "            # for every particle write the predictions on the training batches in a dictionary\n",
    "            y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                            .predict(X_batches[b])\n",
    "\n",
    "            # for every particle write the Jacobian in a dictionary\n",
    "            jacobian_dict[\"model_{}\".format(str(i+1))] = 1/len(y_batches[b]) * (-2)*(y_batches[b] - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "            \n",
    "            # for every particle write the training accuracy of the current iteration in a dictionary\n",
    "            train_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "            \n",
    "            # for every particle write the test accuracy of the current iteration in a dictionary\n",
    "            test_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "            \n",
    "            # for every particle write the current iteration in a dictionary\n",
    "            iteration_dict[\"model_{}\".format(str(i+1))].append(\"Epoch: {}, Batch: {}.\".format(epoch+1, b+1))\n",
    "            \n",
    "        #print(y_pred_dict[\"model_1\"])\n",
    "            \n",
    "        # compute the mean of the predictions\n",
    "        y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "        \n",
    "        # compute the matrix D elementwise\n",
    "        d = np.zeros(shape = (particles, particles))\n",
    "        for k in range(particles):\n",
    "            y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "            for j in range(particles):\n",
    "                d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_dict[\"model_{}\".format(str(j+1))])\n",
    "                                       \n",
    "        # compute the scalar h_t\n",
    "        h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "        \n",
    "        # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "        for i in range(particles):\n",
    "            weights_array = np.array([])\n",
    "            for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "            weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "          \n",
    "        # matrix with particle parameters as row vectors\n",
    "        weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "        # compute the matrix with the updates for each particle\n",
    "        weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "        for i in range(particles):\n",
    "            # write the updates back into the dictionary\n",
    "            weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "            # reshape the updates, so that they are of the original matrx and vector shape\n",
    "            for l in range(len(shape_elements)-1):\n",
    "                start = shape_elements[l]\n",
    "                end = shape_elements[l+1]\n",
    "                weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 745us/step - loss: 66924.5391 - mse: 66924.5391\n",
      "66924.5390625\n",
      "16/16 [==============================] - 0s 997us/step - loss: 66553.5625 - mse: 66553.5625\n",
      "66553.5625\n",
      "16/16 [==============================] - 0s 908us/step - loss: 66138.3984 - mse: 66138.3984\n",
      "66138.3984375\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "init_model.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 830us/step - loss: 66478.1016 - mse: 66478.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[66478.1015625, 66478.1015625]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.18360597,  0.022454  ,  0.12975092, ...,  0.0927804 ,\n",
       "          0.13099273, -0.26845765],\n",
       "        [-0.01268142,  0.18863858,  0.04429561, ...,  0.5081108 ,\n",
       "         -0.02412708,  0.3116532 ],\n",
       "        [ 0.06836764,  0.22700316, -0.04966023, ...,  0.07185508,\n",
       "         -0.10577945,  0.15329163],\n",
       "        ...,\n",
       "        [-0.38343355, -0.00320738, -0.2286397 , ..., -0.22235315,\n",
       "          0.27801573, -0.08232591],\n",
       "        [-0.07971447,  0.05779862,  0.02084918, ...,  0.17779309,\n",
       "          0.42194882, -0.19201313],\n",
       "        [ 0.03048011, -0.11129764, -0.025444  , ...,  0.05233171,\n",
       "          0.04826559, -0.25867543]], dtype=float32),\n",
       " array([ 0.18422544,  0.06601666,  0.23378216, -0.09825441, -0.01555302,\n",
       "        -0.03161227,  0.13647   ,  0.37561738, -0.05155   ,  0.363177  ,\n",
       "        -0.04308495, -0.18380335,  0.16644965,  0.11196081,  0.00572907,\n",
       "        -0.22127123, -0.27903196, -0.02440498,  0.23455556,  0.18083887,\n",
       "         0.1324117 , -0.10937811, -0.0640647 , -0.00842765, -0.0377272 ,\n",
       "         0.0009629 ,  0.08458   ,  0.03637128,  0.26238135, -0.1804041 ,\n",
       "        -0.1270331 , -0.3025811 ,  0.12787358,  0.23593043,  0.07360201,\n",
       "        -0.17158951, -0.11485285, -0.11746169,  0.07023595,  0.15717517,\n",
       "        -0.15816803, -0.07423025, -0.04679288, -0.14893562, -0.30577493,\n",
       "         0.05476791,  0.3505032 ,  0.12696484, -0.37536365,  0.12826467,\n",
       "        -0.27076057, -0.02884173, -0.18652451, -0.26292512, -0.23762344,\n",
       "         0.07059744, -0.10423911,  0.03783204,  0.18801583, -0.19594148,\n",
       "        -0.01376436,  0.20335846,  0.12046418,  0.05196212], dtype=float32),\n",
       " array([[ 0.1562433 , -0.03067857,  0.15718943, ..., -0.17085467,\n",
       "         -0.01767604,  0.17642322],\n",
       "        [-0.10240717,  0.08223585, -0.14756665, ..., -0.02485426,\n",
       "          0.02563432,  0.2534993 ],\n",
       "        [-0.09426369, -0.14807197,  0.14227742, ...,  0.16450658,\n",
       "          0.33340263, -0.40642226],\n",
       "        ...,\n",
       "        [ 0.02604734,  0.11713842, -0.21217017, ..., -0.21446106,\n",
       "          0.18956277,  0.16030845],\n",
       "        [ 0.04391161,  0.21328254,  0.26029554, ..., -0.09814723,\n",
       "         -0.05131238,  0.36058727],\n",
       "        [ 0.16617861, -0.1768499 , -0.04460347, ...,  0.04418516,\n",
       "         -0.1365187 ,  0.13703108]], dtype=float32),\n",
       " array([ 0.19696535, -0.05703004,  0.00244159, -0.1991961 ,  0.08035029,\n",
       "        -0.3468179 ,  0.09434193, -0.15234472, -0.14798373,  0.00681499,\n",
       "         0.07923971, -0.10797828,  0.4703287 , -0.05096586, -0.04464165,\n",
       "         0.1801118 ,  0.09663115, -0.18448815,  0.83260953, -0.15674892,\n",
       "        -0.07246924,  0.3812416 , -0.06884824, -0.1988072 ,  0.8585931 ,\n",
       "         0.0707366 , -0.283368  ,  0.1773375 , -0.3266519 , -0.12262958,\n",
       "        -0.00784299, -0.7152946 ], dtype=float32),\n",
       " array([[ 0.20237996,  0.00116395, -0.3332483 , ..., -0.08543985,\n",
       "          0.17857593, -0.05460247],\n",
       "        [ 0.01928364,  0.05129689,  0.22173187, ...,  0.00303549,\n",
       "          0.2777371 ,  0.00329499],\n",
       "        [-0.47741896,  0.31858554,  0.25302142, ...,  0.13229226,\n",
       "         -0.27479637,  0.16967034],\n",
       "        ...,\n",
       "        [-0.01149391, -0.1640562 ,  0.05124906, ...,  0.07108314,\n",
       "         -0.00246757, -0.2621854 ],\n",
       "        [ 0.14485893,  0.2485884 ,  0.09040063, ...,  0.59562296,\n",
       "          0.17196216, -0.07394137],\n",
       "        [ 0.02243509,  0.32000843, -0.4017624 , ..., -0.0039708 ,\n",
       "          0.43247083,  0.3095609 ]], dtype=float32),\n",
       " array([-0.13610458, -0.01880844,  0.15672567,  0.17075518,  0.30036518,\n",
       "         0.26295695, -0.07532149,  0.4841464 ,  0.07903462,  0.5368394 ,\n",
       "        -0.08678492, -0.28892028,  0.0550984 ,  0.29982838, -0.04985695,\n",
       "         0.4256496 , -0.04911923, -0.01569786,  0.06407039, -0.10689417,\n",
       "        -0.24531932,  0.13031438,  0.03826986, -0.11067845, -0.0900651 ,\n",
       "        -0.2685049 ,  0.3362847 , -0.20928267, -0.4740784 ,  0.28364214,\n",
       "         0.07266565,  0.20818709], dtype=float32),\n",
       " array([[ 1.96982324e-01,  4.17382389e-01, -2.11467817e-01,\n",
       "         -3.55903566e-01, -3.89895231e-01,  4.67483327e-02,\n",
       "          2.31235400e-02, -5.08205295e-02,  3.26110214e-01,\n",
       "          4.10779744e-01, -3.23898464e-01,  6.41587079e-01,\n",
       "          1.57877788e-01, -2.23581642e-01, -7.40063190e-01,\n",
       "          1.46079389e-03],\n",
       "        [ 1.76313236e-01, -3.35623354e-01,  3.05731520e-02,\n",
       "          2.55679697e-01, -6.98608626e-03,  6.43768191e-01,\n",
       "         -7.28576064e-01,  2.19661340e-01,  1.59676865e-01,\n",
       "          4.94284004e-01,  1.38825014e-01,  3.16999257e-01,\n",
       "          5.33157550e-02, -3.04247409e-01, -7.39030242e-01,\n",
       "          1.06649905e-01],\n",
       "        [ 1.58945441e-01,  1.45824151e-02,  3.08403075e-02,\n",
       "          6.53220952e-01,  3.87730360e-01, -2.26284727e-01,\n",
       "         -1.62800178e-01, -9.74794328e-02, -1.64436147e-01,\n",
       "          9.67455059e-02,  1.81559131e-01, -1.05882861e-01,\n",
       "          4.54949707e-01, -3.53910804e-01, -3.22021574e-01,\n",
       "         -4.27797943e-01],\n",
       "        [ 6.13839319e-03, -3.34866345e-02, -1.10440664e-01,\n",
       "          3.35009575e-01, -7.82461390e-02,  2.82762617e-01,\n",
       "          1.87508628e-01,  4.81201679e-01,  4.11999613e-01,\n",
       "          2.66904980e-01,  9.28765759e-02, -5.94066828e-02,\n",
       "          2.47396260e-01, -5.81854582e-01, -7.02620745e-02,\n",
       "          2.17931554e-01],\n",
       "        [-4.62796420e-01, -3.34760487e-01,  7.78153837e-02,\n",
       "         -1.29581213e-01, -1.16205610e-01, -4.30852294e-01,\n",
       "         -8.06559715e-03,  9.43876505e-02,  1.66710839e-01,\n",
       "         -3.26090753e-01, -1.21237993e-01, -2.14367300e-01,\n",
       "          1.30185500e-01, -6.06998056e-02, -1.71783835e-01,\n",
       "          3.53023037e-02],\n",
       "        [ 2.49753619e-04, -3.48297358e-01,  4.59615946e-01,\n",
       "         -4.66638535e-01, -2.52462268e-01,  9.90359262e-02,\n",
       "         -1.55916303e-01, -3.79696712e-02,  1.31163061e-01,\n",
       "          1.97584286e-01, -1.68891072e-01,  7.42061809e-02,\n",
       "         -2.35747974e-02,  1.13661930e-01,  3.31584543e-01,\n",
       "          2.44162977e-01],\n",
       "        [-1.16006784e-01, -7.47271255e-02, -4.44453478e-01,\n",
       "          1.37389705e-01, -2.21107200e-01,  9.55662355e-02,\n",
       "          4.90627050e-01, -1.02388524e-01,  2.50935167e-01,\n",
       "          1.92836389e-01,  4.61284548e-01, -4.32159044e-02,\n",
       "          1.36142075e-01, -7.14248940e-02, -4.40215498e-01,\n",
       "          1.00724399e-01],\n",
       "        [ 8.55301321e-01, -3.26997004e-02, -2.70259321e-01,\n",
       "         -2.09493622e-01,  3.92698914e-01, -2.94588685e-01,\n",
       "          5.80928149e-03, -3.45945328e-01,  1.49118811e-01,\n",
       "         -2.71439552e-01, -2.61911690e-01,  3.25581789e-01,\n",
       "          3.37654725e-02,  2.33881265e-01, -1.35219684e-02,\n",
       "         -1.43453121e-01],\n",
       "        [ 1.47825688e-01, -1.35576755e-01, -3.72873873e-01,\n",
       "         -3.41412798e-02,  1.86114013e-01, -3.21332216e-01,\n",
       "         -4.77387190e-01, -2.62511373e-01, -1.06732666e-01,\n",
       "          1.71622813e-01, -1.76276401e-01,  2.66900957e-01,\n",
       "          3.86155367e-01,  1.97455555e-01,  2.48408526e-01,\n",
       "         -4.16530937e-01],\n",
       "        [-1.72114193e-01,  4.32862401e-01,  1.14033394e-01,\n",
       "          7.58395046e-02, -2.17637300e-01,  2.36523971e-01,\n",
       "         -1.59436047e-01,  4.70017374e-01, -3.00118655e-01,\n",
       "         -9.43384692e-02,  5.02290623e-03, -2.99685657e-01,\n",
       "         -6.49313331e-02, -5.50445095e-02,  2.46681403e-02,\n",
       "          3.24013472e-01],\n",
       "        [ 1.34315435e-02,  1.70493037e-01,  4.67638433e-01,\n",
       "         -4.72580194e-01, -1.26248136e-01, -2.32670739e-01,\n",
       "          1.26393288e-02, -3.90083462e-01, -2.13080645e-01,\n",
       "         -6.03399575e-02, -1.54909529e-02,  2.49093056e-01,\n",
       "          3.61630470e-01,  3.16974334e-02, -3.04012686e-01,\n",
       "         -7.71503001e-02],\n",
       "        [-2.14493707e-01, -2.72673406e-02,  2.15229660e-01,\n",
       "          1.09896034e-01,  1.11871332e-01, -1.71013638e-01,\n",
       "         -2.27645606e-01, -1.95587739e-01, -8.43956843e-02,\n",
       "         -1.97333828e-01, -1.70238748e-01,  3.77572238e-01,\n",
       "         -3.99470270e-01, -4.14110601e-01,  1.52484821e-02,\n",
       "          9.39051285e-02],\n",
       "        [-5.15813649e-01, -2.14330018e-01, -3.30720693e-01,\n",
       "         -2.60021854e-02,  7.94149656e-03, -1.22577965e-01,\n",
       "          5.43528982e-02, -3.93739998e-01,  2.51812220e-01,\n",
       "         -2.67715454e-01, -5.98902166e-01,  3.86654943e-01,\n",
       "         -3.23082469e-02, -2.33917966e-01, -3.62071931e-01,\n",
       "         -4.52043056e-01],\n",
       "        [-2.76850581e-01, -3.19356471e-02, -4.43401873e-01,\n",
       "          1.01148352e-01,  8.88789594e-02, -1.17122307e-01,\n",
       "         -1.36997417e-01, -5.38794883e-02, -1.66016728e-01,\n",
       "         -7.41985440e-02, -2.26637766e-01, -4.09842432e-02,\n",
       "          1.77898780e-01,  2.59114414e-01,  1.42281339e-01,\n",
       "         -2.33470127e-01],\n",
       "        [ 2.27258846e-01, -2.00593233e-01,  9.21277553e-02,\n",
       "         -2.65187323e-01, -1.86628908e-01, -2.84278989e-01,\n",
       "          1.64162382e-01, -4.82359320e-01, -5.41208126e-02,\n",
       "          3.17101985e-01, -1.63160875e-01, -5.64043343e-01,\n",
       "         -1.54314395e-02,  1.24797888e-01, -2.95002591e-02,\n",
       "          1.70213208e-01],\n",
       "        [-2.16311604e-01,  8.43201727e-02, -5.13894774e-04,\n",
       "          6.14379719e-02, -1.73671499e-01, -2.91688871e-02,\n",
       "         -1.93146303e-01, -3.91588032e-01, -5.92588246e-01,\n",
       "          2.25127563e-01, -1.90123301e-02,  3.60226333e-01,\n",
       "         -1.29245639e-01,  4.15285915e-01,  2.16341000e-02,\n",
       "         -5.41338697e-02],\n",
       "        [-2.99242347e-01, -2.67612427e-01,  1.28748164e-01,\n",
       "          2.79574513e-01,  2.01007187e-01,  1.59470573e-01,\n",
       "          1.54215723e-01, -1.91876262e-01,  5.49195111e-02,\n",
       "          3.08312058e-01,  4.03826237e-02,  2.66745925e-01,\n",
       "          9.19221863e-02,  9.97491553e-02,  2.37679273e-01,\n",
       "          3.85204166e-01],\n",
       "        [-2.66046435e-01, -5.27444363e-01, -1.49307027e-01,\n",
       "         -7.24204555e-02,  6.04179949e-02,  1.42528517e-02,\n",
       "         -1.52907297e-01,  2.74259061e-01,  3.03645790e-01,\n",
       "         -3.28219719e-02, -8.06539953e-02, -1.28997013e-01,\n",
       "          7.34613895e-01, -1.92088746e-02, -3.37374866e-01,\n",
       "         -3.40413838e-03],\n",
       "        [-7.32356489e-01, -1.02088682e-01,  2.51656860e-01,\n",
       "          1.31883353e-01, -2.96044499e-01,  1.75894707e-01,\n",
       "         -1.26950229e-02, -4.10378277e-02,  3.42099547e-01,\n",
       "          2.07613572e-01,  2.84127533e-01,  1.38202503e-01,\n",
       "         -6.38030827e-01,  4.16719437e-01,  2.86672950e-01,\n",
       "         -2.78216422e-01],\n",
       "        [ 2.29029581e-01, -2.56821513e-01,  1.02482811e-01,\n",
       "          2.84074783e-01,  3.91408801e-01, -2.86073744e-01,\n",
       "          1.84131444e-01,  7.23198950e-02,  2.49905754e-02,\n",
       "         -1.16135940e-01, -1.36170536e-01,  3.41762453e-02,\n",
       "          6.35232270e-01, -2.45714545e-01,  3.49151939e-01,\n",
       "         -2.55968422e-01],\n",
       "        [-1.32337928e-01, -1.19889043e-01, -1.07913844e-01,\n",
       "         -8.43451694e-02,  2.62529492e-01, -2.80806601e-01,\n",
       "         -2.92072058e-01, -2.90380627e-01,  3.25473875e-01,\n",
       "         -4.75335047e-02, -3.93720686e-01,  2.13356949e-02,\n",
       "          5.95548227e-02,  1.16316065e-01, -6.76576048e-02,\n",
       "         -1.25153050e-01],\n",
       "        [ 3.36281627e-01, -4.04503703e-01, -1.20902628e-01,\n",
       "         -1.26828579e-02, -1.42304391e-01,  2.43621156e-01,\n",
       "          6.29082918e-01, -4.50686127e-01,  6.50944054e-01,\n",
       "         -3.58447880e-02,  4.93519634e-01, -1.46490276e-01,\n",
       "         -1.89583972e-01, -4.34471101e-01, -4.47901219e-01,\n",
       "          7.01163173e-01],\n",
       "        [-4.39184636e-01,  3.12066197e-01,  3.11122034e-02,\n",
       "         -2.29255602e-01,  2.23511264e-01, -1.05866179e-01,\n",
       "          7.50430167e-01, -2.78716207e-01,  3.46570939e-01,\n",
       "          2.03080833e-01, -3.05151045e-01,  2.22739637e-01,\n",
       "          1.19500980e-02, -4.85933572e-01,  1.01035401e-01,\n",
       "          2.61962917e-02],\n",
       "        [ 2.27462932e-01,  4.81210709e-01, -3.38727802e-01,\n",
       "          1.19948268e-01, -9.19737145e-02,  9.96979102e-02,\n",
       "         -5.57930171e-01, -8.65899682e-01,  3.46262157e-02,\n",
       "          9.67065692e-02, -6.24173701e-01, -1.38361648e-01,\n",
       "         -3.70001495e-01, -2.95615673e-01,  3.82247418e-01,\n",
       "          6.93074107e-01],\n",
       "        [-2.65634984e-01,  5.62464952e-01,  2.65309632e-01,\n",
       "         -2.13042215e-01,  2.46734411e-01,  3.74997795e-01,\n",
       "         -7.61559885e-03, -1.15036838e-01, -3.59738439e-01,\n",
       "         -3.94616783e-01, -3.18432778e-01,  6.00172207e-02,\n",
       "         -3.62806886e-01, -2.17496961e-01, -9.14784819e-02,\n",
       "          1.83003202e-01],\n",
       "        [ 6.07595146e-01, -8.32460746e-02, -1.27917543e-01,\n",
       "         -1.72016189e-01,  2.49949172e-01, -1.45474106e-01,\n",
       "         -5.25709271e-01, -8.16440642e-01, -3.66663396e-01,\n",
       "         -3.88534516e-01,  3.55059832e-01,  1.98731840e-01,\n",
       "          1.32226437e-01,  3.07541341e-01, -1.39106572e-01,\n",
       "         -2.40850374e-01],\n",
       "        [-5.94070435e-01,  2.03479886e-01, -1.20797865e-01,\n",
       "         -1.32885367e-01,  3.08067471e-01, -5.96715137e-02,\n",
       "          1.57219425e-01, -6.97895736e-02,  9.77203622e-02,\n",
       "          1.63570881e-01,  5.35869479e-01, -2.03748167e-01,\n",
       "         -4.89310175e-01,  5.20468652e-01, -5.30160815e-02,\n",
       "          2.05702528e-01],\n",
       "        [-2.39467725e-01,  2.73619026e-01,  1.65160626e-01,\n",
       "          4.43145275e-01,  1.78305000e-01, -3.30101997e-02,\n",
       "         -6.43900812e-01,  3.44642639e-01,  9.86642987e-02,\n",
       "          8.67625028e-02,  4.56600171e-03,  2.14318827e-01,\n",
       "         -3.28405619e-01,  3.94677460e-01,  3.19331735e-01,\n",
       "          4.55093563e-01],\n",
       "        [ 2.12955233e-02,  2.63670236e-01, -1.11786522e-01,\n",
       "          4.89925504e-01, -2.34840751e-01,  2.03941241e-01,\n",
       "         -1.34386405e-01,  1.45528421e-01,  9.23829898e-02,\n",
       "          1.02766395e-01, -9.91808698e-02,  2.89671302e-01,\n",
       "         -1.05589051e-02,  3.84847857e-02, -1.05563700e-01,\n",
       "         -1.81481823e-01],\n",
       "        [-4.03323770e-02,  3.13820004e-01,  2.58352667e-01,\n",
       "          1.34425566e-01,  6.15462810e-02,  3.28699380e-01,\n",
       "          4.44220990e-01,  6.46725178e-01, -4.08634037e-01,\n",
       "          8.54257643e-02,  7.83362519e-03,  2.85405833e-02,\n",
       "          4.81482923e-01, -5.54934502e-01, -2.63033301e-01,\n",
       "          6.61117911e-01],\n",
       "        [-9.95588899e-02, -1.87132686e-01, -3.56526941e-01,\n",
       "         -5.98228693e-01, -3.31488609e-01,  2.00233072e-01,\n",
       "          2.26668313e-01, -5.21088243e-01, -4.06580269e-01,\n",
       "          3.57875913e-01, -5.92262566e-01, -2.44372025e-01,\n",
       "          1.47016183e-01,  3.21533144e-01, -1.20683037e-01,\n",
       "         -5.56864023e-01],\n",
       "        [-4.02629793e-01, -3.61896545e-01, -7.29362518e-02,\n",
       "         -2.32966885e-01, -3.09427440e-01, -4.01437208e-02,\n",
       "          4.48073626e-01, -5.87313250e-02,  1.15559496e-01,\n",
       "         -1.40999585e-01,  3.89061987e-01, -6.01488709e-01,\n",
       "          1.58819497e-01, -7.12071732e-02,  4.91616428e-01,\n",
       "          3.62717927e-01]], dtype=float32),\n",
       " array([ 0.6232081 ,  0.8860739 ,  0.40218163, -0.24470678, -0.08652116,\n",
       "        -0.6854285 ,  0.15064791,  0.33345118,  0.14975214,  0.06623632,\n",
       "        -0.64105517, -0.1509193 ,  0.13128535,  0.38682967, -0.06386399,\n",
       "         0.8076854 ], dtype=float32),\n",
       " array([[ 0.3352241 ],\n",
       "        [-0.60471004],\n",
       "        [-0.26646507],\n",
       "        [-1.2210882 ],\n",
       "        [ 0.6268929 ],\n",
       "        [ 0.13772139],\n",
       "        [ 0.50189346],\n",
       "        [-0.14257938],\n",
       "        [-0.2872022 ],\n",
       "        [ 0.15328163],\n",
       "        [ 0.4048468 ],\n",
       "        [-0.6437205 ],\n",
       "        [ 0.21746308],\n",
       "        [-1.3543591 ],\n",
       "        [ 0.27562016],\n",
       "        [-0.126425  ]], dtype=float32),\n",
       " array([-0.94907445], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[\"model_1\"].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2538965 ],\n",
       "       [-1.3301928 ],\n",
       "       [-0.06830102],\n",
       "       [-2.8859062 ],\n",
       "       [-0.20925683],\n",
       "       [-1.7674813 ],\n",
       "       [-2.0626311 ],\n",
       "       [-3.1697261 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dict[\"model_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-104.56347412,   -3.3325482 ,  -33.01707526,  -52.47147655,\n",
       "        -35.30231421, -195.19187033,   -2.51565778, -101.79243153])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_dict[\"model_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': [73259.7734375,\n",
       "  73353.703125,\n",
       "  72979.1953125,\n",
       "  73643.2421875,\n",
       "  73063.2265625,\n",
       "  73683.1171875,\n",
       "  72971.5546875,\n",
       "  73680.3671875,\n",
       "  73101.3359375,\n",
       "  73758.6953125,\n",
       "  73019.1484375,\n",
       "  73701.3828125,\n",
       "  72979.3125,\n",
       "  73775.890625,\n",
       "  72930.5078125,\n",
       "  73784.2890625,\n",
       "  72935.90625,\n",
       "  73797.46875,\n",
       "  72932.7265625,\n",
       "  73774.234375,\n",
       "  72947.3046875,\n",
       "  73751.4921875,\n",
       "  73039.3828125,\n",
       "  73898.09375,\n",
       "  72992.203125,\n",
       "  73853.921875,\n",
       "  73020.2734375,\n",
       "  73802.328125,\n",
       "  73020.6171875,\n",
       "  73765.34375,\n",
       "  72964.3203125,\n",
       "  73811.09375,\n",
       "  72997.3984375,\n",
       "  73835.6171875,\n",
       "  72976.59375,\n",
       "  73877.0234375,\n",
       "  72964.1953125,\n",
       "  73820.703125,\n",
       "  72983.4296875,\n",
       "  73826.6953125,\n",
       "  72989.5703125,\n",
       "  73819.59375,\n",
       "  72979.9296875,\n",
       "  73843.7890625,\n",
       "  72966.96875,\n",
       "  73814.8515625,\n",
       "  73012.9453125,\n",
       "  73713.5546875,\n",
       "  73036.3984375,\n",
       "  73798.78125,\n",
       "  72962.9609375,\n",
       "  73812.7578125,\n",
       "  72978.765625,\n",
       "  73829.203125,\n",
       "  72962.265625,\n",
       "  73825.6484375,\n",
       "  72998.4765625,\n",
       "  73761.5859375,\n",
       "  73025.9765625,\n",
       "  73787.34375,\n",
       "  72997.328125,\n",
       "  73827.2578125,\n",
       "  73003.6328125,\n",
       "  73760.6953125,\n",
       "  72964.7890625,\n",
       "  73809.140625,\n",
       "  72994.859375,\n",
       "  73705.390625,\n",
       "  73039.3984375,\n",
       "  73926.015625,\n",
       "  72990.265625,\n",
       "  73840.6953125,\n",
       "  72994.2421875,\n",
       "  73906.03125,\n",
       "  73005.484375,\n",
       "  73812.5390625,\n",
       "  73042.2109375,\n",
       "  73738.7421875,\n",
       "  73077.8984375,\n",
       "  73805.4453125,\n",
       "  72995.5234375,\n",
       "  73917.25,\n",
       "  72985.5078125,\n",
       "  73886.3203125,\n",
       "  72972.4609375,\n",
       "  73852.6484375,\n",
       "  73004.90625,\n",
       "  73796.5390625,\n",
       "  73051.7734375,\n",
       "  73737.3046875,\n",
       "  72988.9921875,\n",
       "  73800.734375,\n",
       "  73007.4375,\n",
       "  73754.453125,\n",
       "  72986.171875,\n",
       "  73836.1328125,\n",
       "  73015.4609375,\n",
       "  73802.5625,\n",
       "  72997.5234375,\n",
       "  73799.703125,\n",
       "  73033.0078125,\n",
       "  73739.5390625,\n",
       "  73006.3515625,\n",
       "  73812.15625,\n",
       "  72984.8828125,\n",
       "  73849.796875,\n",
       "  72957.625,\n",
       "  73840.5546875,\n",
       "  72962.2421875,\n",
       "  73882.1875,\n",
       "  72960.375,\n",
       "  73862.4140625,\n",
       "  72961.484375,\n",
       "  73838.765625,\n",
       "  72966.8515625,\n",
       "  73852.5625,\n",
       "  72964.9375,\n",
       "  73823.4453125,\n",
       "  72969.578125,\n",
       "  73835.1171875,\n",
       "  72964.8984375,\n",
       "  73764.1484375,\n",
       "  73019.3828125,\n",
       "  73709.359375,\n",
       "  73063.25,\n",
       "  73811.8203125,\n",
       "  73005.34375,\n",
       "  73783.0859375,\n",
       "  72967.4140625,\n",
       "  73797.921875,\n",
       "  72971.1796875,\n",
       "  73825.609375,\n",
       "  72993.1796875,\n",
       "  73722.9453125,\n",
       "  73048.0625,\n",
       "  73794.3046875,\n",
       "  72994.1328125,\n",
       "  73847.8671875,\n",
       "  72992.8671875,\n",
       "  73796.8828125,\n",
       "  73007.109375,\n",
       "  73726.40625,\n",
       "  73033.609375,\n",
       "  73748.625,\n",
       "  72998.6328125,\n",
       "  73796.8203125,\n",
       "  72964.0,\n",
       "  73844.5859375,\n",
       "  72970.0703125,\n",
       "  73794.0703125,\n",
       "  72980.9921875,\n",
       "  73788.1171875,\n",
       "  72979.0703125,\n",
       "  73767.28125,\n",
       "  73020.9140625,\n",
       "  73806.84375,\n",
       "  73010.2734375,\n",
       "  73781.8515625,\n",
       "  72993.71875,\n",
       "  73783.875],\n",
       " 'model_2': [73833.328125,\n",
       "  73227.4765625,\n",
       "  73328.90625,\n",
       "  73522.3203125,\n",
       "  73230.5234375,\n",
       "  73484.90625,\n",
       "  73351.234375,\n",
       "  73502.2421875,\n",
       "  73209.71875,\n",
       "  73397.734375,\n",
       "  73303.5390625,\n",
       "  73511.2578125,\n",
       "  73364.2890625,\n",
       "  73363.484375,\n",
       "  73513.3203125,\n",
       "  73297.046875,\n",
       "  73473.6953125,\n",
       "  73231.453125,\n",
       "  73467.59375,\n",
       "  73313.9921875,\n",
       "  73399.5078125,\n",
       "  73384.546875,\n",
       "  73242.09375,\n",
       "  73142.3671875,\n",
       "  73484.0,\n",
       "  73306.328125,\n",
       "  73367.7578125,\n",
       "  73414.0859375,\n",
       "  73363.0234375,\n",
       "  73473.8984375,\n",
       "  73472.6171875,\n",
       "  73374.7421875,\n",
       "  73384.421875,\n",
       "  73333.4375,\n",
       "  73440.1328125,\n",
       "  73195.5078125,\n",
       "  73490.2109375,\n",
       "  73354.7890625,\n",
       "  73422.6328125,\n",
       "  73342.5078125,\n",
       "  73397.7421875,\n",
       "  73351.5703125,\n",
       "  73422.84375,\n",
       "  73294.0390625,\n",
       "  73476.28125,\n",
       "  73366.0,\n",
       "  73342.4765625,\n",
       "  73511.84375,\n",
       "  73311.375,\n",
       "  73405.1875,\n",
       "  73472.6953125,\n",
       "  73371.296875,\n",
       "  73417.8671875,\n",
       "  73342.40625,\n",
       "  73480.2265625,\n",
       "  73344.65625,\n",
       "  73356.9140625,\n",
       "  73439.296875,\n",
       "  73314.6171875,\n",
       "  73412.2890625,\n",
       "  73367.78125,\n",
       "  73357.6171875,\n",
       "  73352.171875,\n",
       "  73450.7578125,\n",
       "  73438.671875,\n",
       "  73374.8515625,\n",
       "  73358.515625,\n",
       "  73519.84375,\n",
       "  73298.359375,\n",
       "  73247.8671875,\n",
       "  73457.875,\n",
       "  73410.1484375,\n",
       "  73443.0390625,\n",
       "  73281.140625,\n",
       "  73382.65625,\n",
       "  73416.296875,\n",
       "  73318.1953125,\n",
       "  73508.71875,\n",
       "  73278.0859375,\n",
       "  73435.0234375,\n",
       "  73406.3828125,\n",
       "  73242.46875,\n",
       "  73421.84375,\n",
       "  73275.6640625,\n",
       "  73498.90625,\n",
       "  73346.40625,\n",
       "  73378.65625,\n",
       "  73422.0625,\n",
       "  73296.328125,\n",
       "  73493.4375,\n",
       "  73393.4453125,\n",
       "  73400.3828125,\n",
       "  73353.0390625,\n",
       "  73465.3671875,\n",
       "  73395.9921875,\n",
       "  73346.3671875,\n",
       "  73328.3515625,\n",
       "  73398.0078125,\n",
       "  73365.28125,\n",
       "  73401.8671875,\n",
       "  73299.4921875,\n",
       "  73468.5703125,\n",
       "  73339.3125,\n",
       "  73378.375,\n",
       "  73389.6484375,\n",
       "  73326.484375,\n",
       "  73512.796875,\n",
       "  73335.8046875,\n",
       "  73482.546875,\n",
       "  73224.3125,\n",
       "  73511.5625,\n",
       "  73279.7421875,\n",
       "  73491.1953125,\n",
       "  73321.4375,\n",
       "  73459.4140625,\n",
       "  73288.7890625,\n",
       "  73465.5859375,\n",
       "  73335.03125,\n",
       "  73431.8671875,\n",
       "  73300.0859375,\n",
       "  73457.7265625,\n",
       "  73427.4375,\n",
       "  73323.921875,\n",
       "  73499.703125,\n",
       "  73269.109375,\n",
       "  73387.875,\n",
       "  73365.875,\n",
       "  73426.390625,\n",
       "  73463.4140625,\n",
       "  73389.5078125,\n",
       "  73445.375,\n",
       "  73336.4765625,\n",
       "  73366.8828125,\n",
       "  73478.59375,\n",
       "  73281.6328125,\n",
       "  73396.0078125,\n",
       "  73380.0078125,\n",
       "  73321.7421875,\n",
       "  73383.9453125,\n",
       "  73392.9609375,\n",
       "  73348.15625,\n",
       "  73487.6796875,\n",
       "  73308.3046875,\n",
       "  73462.765625,\n",
       "  73369.375,\n",
       "  73400.0625,\n",
       "  73480.171875,\n",
       "  73305.7734375,\n",
       "  73440.5078125,\n",
       "  73384.1484375,\n",
       "  73400.5078125,\n",
       "  73390.09375,\n",
       "  73404.34375,\n",
       "  73419.7265625,\n",
       "  73314.5078125,\n",
       "  73373.7734375,\n",
       "  73335.0546875,\n",
       "  73405.1796875,\n",
       "  73372.03125,\n",
       "  73406.0703125],\n",
       " 'model_3': [72955.6796875,\n",
       "  74084.8671875,\n",
       "  89956.7421875,\n",
       "  72980.6953125,\n",
       "  74024.8828125,\n",
       "  72981.234375,\n",
       "  73906.265625,\n",
       "  72975.0546875,\n",
       "  73990.5703125,\n",
       "  72985.828125,\n",
       "  73882.5625,\n",
       "  72960.4296875,\n",
       "  73829.734375,\n",
       "  73007.21875,\n",
       "  73660.0390625,\n",
       "  73059.703125,\n",
       "  73718.5859375,\n",
       "  73127.25,\n",
       "  73743.9140625,\n",
       "  73053.1328125,\n",
       "  73848.6015625,\n",
       "  73011.28125,\n",
       "  74027.0625,\n",
       "  73173.671875,\n",
       "  73602.390625,\n",
       "  72984.6171875,\n",
       "  73756.1171875,\n",
       "  72949.65625,\n",
       "  73768.0234375,\n",
       "  72938.8671875,\n",
       "  73686.71875,\n",
       "  72973.4453125,\n",
       "  73777.71875,\n",
       "  72991.609375,\n",
       "  73720.5390625,\n",
       "  73120.8203125,\n",
       "  73676.4921875,\n",
       "  72979.90625,\n",
       "  73751.9296875,\n",
       "  72987.484375,\n",
       "  73790.125,\n",
       "  72985.703125,\n",
       "  73765.5859375,\n",
       "  73023.328125,\n",
       "  73705.015625,\n",
       "  72976.96875,\n",
       "  73862.96875,\n",
       "  72943.296875,\n",
       "  73879.6640625,\n",
       "  72963.3984375,\n",
       "  73723.203125,\n",
       "  72979.96875,\n",
       "  73782.9921875,\n",
       "  72994.9140625,\n",
       "  73717.7265625,\n",
       "  72994.8046875,\n",
       "  73865.78125,\n",
       "  72962.7890625,\n",
       "  73896.4140625,\n",
       "  72968.21875,\n",
       "  73839.4765625,\n",
       "  72987.2890625,\n",
       "  73858.3984375,\n",
       "  72958.9453125,\n",
       "  73781.1328125,\n",
       "  72986.2890625,\n",
       "  73863.5625,\n",
       "  72949.125,\n",
       "  73896.09375,\n",
       "  73037.421875,\n",
       "  73690.171875,\n",
       "  72946.6484375,\n",
       "  73705.84375,\n",
       "  73012.8984375,\n",
       "  73790.296875,\n",
       "  72955.0390625,\n",
       "  73843.96875,\n",
       "  72939.140625,\n",
       "  73863.0546875,\n",
       "  72949.2578125,\n",
       "  73763.4296875,\n",
       "  73052.0390625,\n",
       "  73764.765625,\n",
       "  73031.171875,\n",
       "  73680.2265625,\n",
       "  72981.7578125,\n",
       "  73802.2578125,\n",
       "  72956.6953125,\n",
       "  73875.140625,\n",
       "  72945.375,\n",
       "  73807.0546875,\n",
       "  72971.2109375,\n",
       "  73841.1484375,\n",
       "  72953.7890625,\n",
       "  73805.5703125,\n",
       "  72995.0234375,\n",
       "  73871.46875,\n",
       "  72974.7265625,\n",
       "  73831.8671875,\n",
       "  72973.8671875,\n",
       "  73892.4375,\n",
       "  72961.375,\n",
       "  73860.21875,\n",
       "  72985.3203125,\n",
       "  73811.3671875,\n",
       "  73008.53125,\n",
       "  73691.703125,\n",
       "  73003.78125,\n",
       "  73721.3984375,\n",
       "  73103.4453125,\n",
       "  73691.109375,\n",
       "  73044.859375,\n",
       "  73717.234375,\n",
       "  73013.5546875,\n",
       "  73750.2578125,\n",
       "  73038.03125,\n",
       "  73748.9609375,\n",
       "  73007.359375,\n",
       "  73791.9609375,\n",
       "  73034.1796875,\n",
       "  73764.265625,\n",
       "  72967.328125,\n",
       "  73871.3359375,\n",
       "  72952.7265625,\n",
       "  73898.125,\n",
       "  72971.6796875,\n",
       "  73812.6796875,\n",
       "  72960.390625,\n",
       "  73743.0546875,\n",
       "  72977.3515625,\n",
       "  73760.640625,\n",
       "  73003.9375,\n",
       "  73838.78125,\n",
       "  72958.0234375,\n",
       "  73890.1875,\n",
       "  72974.9296875,\n",
       "  73807.796875,\n",
       "  73005.4921875,\n",
       "  73803.171875,\n",
       "  72975.8203125,\n",
       "  73834.546875,\n",
       "  72952.578125,\n",
       "  73853.453125,\n",
       "  72956.6015625,\n",
       "  73808.546875,\n",
       "  72973.0703125,\n",
       "  73720.390625,\n",
       "  73024.2734375,\n",
       "  73761.6015625,\n",
       "  72984.0859375,\n",
       "  73796.8828125,\n",
       "  72982.7109375,\n",
       "  73794.703125,\n",
       "  72973.09375,\n",
       "  73861.5234375,\n",
       "  72985.5546875,\n",
       "  73841.640625,\n",
       "  72976.15625,\n",
       "  73809.875,\n",
       "  72974.953125]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': [66411.4375,\n",
       "  66502.03125,\n",
       "  66141.5234375,\n",
       "  66772.3984375,\n",
       "  66222.6328125,\n",
       "  66806.703125,\n",
       "  66134.6796875,\n",
       "  66805.4921875,\n",
       "  66259.609375,\n",
       "  66872.9609375,\n",
       "  66180.40625,\n",
       "  66825.6796875,\n",
       "  66142.2890625,\n",
       "  66891.125,\n",
       "  66095.484375,\n",
       "  66899.25,\n",
       "  66100.6953125,\n",
       "  66911.515625,\n",
       "  66097.734375,\n",
       "  66892.28125,\n",
       "  66111.7421875,\n",
       "  66873.4765625,\n",
       "  66200.28125,\n",
       "  66996.453125,\n",
       "  66154.9140625,\n",
       "  66964.25,\n",
       "  66181.953125,\n",
       "  66922.5625,\n",
       "  66182.3046875,\n",
       "  66890.9296875,\n",
       "  66128.15625,\n",
       "  66932.3671875,\n",
       "  66159.96875,\n",
       "  66955.359375,\n",
       "  66139.9375,\n",
       "  66993.34375,\n",
       "  66128.0390625,\n",
       "  66945.2109375,\n",
       "  66146.5390625,\n",
       "  66951.3828125,\n",
       "  66152.4453125,\n",
       "  66945.421875,\n",
       "  66143.171875,\n",
       "  66968.890625,\n",
       "  66130.71875,\n",
       "  66942.234375,\n",
       "  66174.953125,\n",
       "  66846.140625,\n",
       "  66197.546875,\n",
       "  66928.0703125,\n",
       "  66126.8828125,\n",
       "  66941.9296875,\n",
       "  66142.0859375,\n",
       "  66958.3125,\n",
       "  66126.2109375,\n",
       "  66955.53125,\n",
       "  66161.0390625,\n",
       "  66893.8203125,\n",
       "  66187.515625,\n",
       "  66918.9453125,\n",
       "  66159.9296875,\n",
       "  66958.265625,\n",
       "  66165.984375,\n",
       "  66894.0234375,\n",
       "  66128.640625,\n",
       "  66941.8046875,\n",
       "  66157.5625,\n",
       "  66841.0078125,\n",
       "  66200.4375,\n",
       "  67057.703125,\n",
       "  66153.1328125,\n",
       "  66972.921875,\n",
       "  66156.9609375,\n",
       "  67038.4296875,\n",
       "  66167.7890625,\n",
       "  66947.21875,\n",
       "  66203.1484375,\n",
       "  66875.3046875,\n",
       "  66237.484375,\n",
       "  66940.6953125,\n",
       "  66158.203125,\n",
       "  67051.53125,\n",
       "  66148.5625,\n",
       "  67021.5625,\n",
       "  66136.0078125,\n",
       "  66988.2265625,\n",
       "  66167.234375,\n",
       "  66934.140625,\n",
       "  66212.3515625,\n",
       "  66875.9453125,\n",
       "  66151.9296875,\n",
       "  66938.3984375,\n",
       "  66169.6796875,\n",
       "  66893.1171875,\n",
       "  66149.21875,\n",
       "  66972.640625,\n",
       "  66177.3984375,\n",
       "  66940.375,\n",
       "  66160.109375,\n",
       "  66937.7890625,\n",
       "  66194.2890625,\n",
       "  66878.875,\n",
       "  66168.625,\n",
       "  66949.9453125,\n",
       "  66147.96875,\n",
       "  66986.7890625,\n",
       "  66121.71875,\n",
       "  66977.8203125,\n",
       "  66126.15625,\n",
       "  67019.9765625,\n",
       "  66124.375,\n",
       "  67000.296875,\n",
       "  66125.421875,\n",
       "  66976.8828125,\n",
       "  66130.59375,\n",
       "  66990.8203125,\n",
       "  66128.7578125,\n",
       "  66962.125,\n",
       "  66133.21875,\n",
       "  66973.8671875,\n",
       "  66128.7109375,\n",
       "  66904.8203125,\n",
       "  66181.1796875,\n",
       "  66850.40625,\n",
       "  66223.40625,\n",
       "  66951.3203125,\n",
       "  66167.671875,\n",
       "  66923.4453125,\n",
       "  66131.1484375,\n",
       "  66938.0703125,\n",
       "  66134.7734375,\n",
       "  66964.96875,\n",
       "  66155.9609375,\n",
       "  66864.328125,\n",
       "  66208.7890625,\n",
       "  66934.625,\n",
       "  66156.875,\n",
       "  66987.078125,\n",
       "  66155.6484375,\n",
       "  66937.15625,\n",
       "  66169.3515625,\n",
       "  66867.9765625,\n",
       "  66194.8828125,\n",
       "  66890.0078125,\n",
       "  66161.1875,\n",
       "  66937.1015625,\n",
       "  66127.875,\n",
       "  66983.96875,\n",
       "  66133.7109375,\n",
       "  66934.4453125,\n",
       "  66144.21875,\n",
       "  66928.6484375,\n",
       "  66142.3671875,\n",
       "  66908.40625,\n",
       "  66182.6484375,\n",
       "  66947.0078125,\n",
       "  66172.3984375,\n",
       "  66922.6015625,\n",
       "  66156.46875,\n",
       "  66924.5390625],\n",
       " 'model_2': [66964.4453125,\n",
       "  66369.1171875,\n",
       "  66431.8515625,\n",
       "  66664.8359375,\n",
       "  66385.1953125,\n",
       "  66628.765625,\n",
       "  66500.1875,\n",
       "  66645.453125,\n",
       "  66365.2578125,\n",
       "  66544.6953125,\n",
       "  66454.5390625,\n",
       "  66654.1875,\n",
       "  66512.6875,\n",
       "  66511.8984375,\n",
       "  66656.2265625,\n",
       "  66448.3515625,\n",
       "  66618.0546875,\n",
       "  66385.921875,\n",
       "  66612.234375,\n",
       "  66464.5625,\n",
       "  66546.515625,\n",
       "  66532.1484375,\n",
       "  66395.9921875,\n",
       "  66299.03125,\n",
       "  66628.359375,\n",
       "  66457.2421875,\n",
       "  66516.1640625,\n",
       "  66560.8515625,\n",
       "  66511.6171875,\n",
       "  66618.6484375,\n",
       "  66617.4140625,\n",
       "  66522.890625,\n",
       "  66532.1875,\n",
       "  66483.2578125,\n",
       "  66586.015625,\n",
       "  66351.203125,\n",
       "  66634.46875,\n",
       "  66503.78125,\n",
       "  66569.1953125,\n",
       "  66491.96875,\n",
       "  66545.1875,\n",
       "  66500.703125,\n",
       "  66569.421875,\n",
       "  66445.4921875,\n",
       "  66621.0703125,\n",
       "  66514.5625,\n",
       "  66492.0078125,\n",
       "  66655.390625,\n",
       "  66462.1484375,\n",
       "  66552.4140625,\n",
       "  66617.6328125,\n",
       "  66519.6796875,\n",
       "  66564.65625,\n",
       "  66491.9375,\n",
       "  66624.90625,\n",
       "  66494.1015625,\n",
       "  66505.8515625,\n",
       "  66585.421875,\n",
       "  66465.2578125,\n",
       "  66559.3125,\n",
       "  66516.3203125,\n",
       "  66506.5390625,\n",
       "  66501.296875,\n",
       "  66596.5078125,\n",
       "  66584.84375,\n",
       "  66523.1484375,\n",
       "  66507.4140625,\n",
       "  66663.15625,\n",
       "  66449.65625,\n",
       "  66401.2421875,\n",
       "  66603.3828125,\n",
       "  66557.3046875,\n",
       "  66589.0859375,\n",
       "  66433.1171875,\n",
       "  66530.7734375,\n",
       "  66563.28125,\n",
       "  66468.7109375,\n",
       "  66652.46875,\n",
       "  66430.1796875,\n",
       "  66581.375,\n",
       "  66553.6875,\n",
       "  66396.0546875,\n",
       "  66568.6484375,\n",
       "  66427.8671875,\n",
       "  66643.015625,\n",
       "  66495.828125,\n",
       "  66526.9765625,\n",
       "  66568.890625,\n",
       "  66447.703125,\n",
       "  66637.75,\n",
       "  66541.265625,\n",
       "  66547.9609375,\n",
       "  66502.234375,\n",
       "  66610.6796875,\n",
       "  66543.7265625,\n",
       "  66495.8046875,\n",
       "  66478.484375,\n",
       "  66545.6796875,\n",
       "  66514.078125,\n",
       "  66549.40625,\n",
       "  66450.7734375,\n",
       "  66613.75,\n",
       "  66489.03125,\n",
       "  66526.734375,\n",
       "  66537.6171875,\n",
       "  66476.703125,\n",
       "  66656.3984375,\n",
       "  66485.6796875,\n",
       "  66627.2578125,\n",
       "  66378.5859375,\n",
       "  66655.1953125,\n",
       "  66431.8046875,\n",
       "  66635.6015625,\n",
       "  66471.859375,\n",
       "  66604.953125,\n",
       "  66440.484375,\n",
       "  66610.90625,\n",
       "  66484.953125,\n",
       "  66578.40625,\n",
       "  66451.3359375,\n",
       "  66603.328125,\n",
       "  66574.1484375,\n",
       "  66474.2578125,\n",
       "  66643.78125,\n",
       "  66421.59375,\n",
       "  66535.984375,\n",
       "  66514.7421875,\n",
       "  66573.1328125,\n",
       "  66608.8125,\n",
       "  66537.5546875,\n",
       "  66591.421875,\n",
       "  66486.375,\n",
       "  66515.7265625,\n",
       "  66623.46875,\n",
       "  66433.6015625,\n",
       "  66543.8203125,\n",
       "  66528.3984375,\n",
       "  66472.203125,\n",
       "  66532.1875,\n",
       "  66540.8828125,\n",
       "  66497.6640625,\n",
       "  66632.21875,\n",
       "  66459.265625,\n",
       "  66608.2109375,\n",
       "  66518.140625,\n",
       "  66547.7421875,\n",
       "  66624.984375,\n",
       "  66456.84375,\n",
       "  66586.7421875,\n",
       "  66532.40625,\n",
       "  66548.1796875,\n",
       "  66538.1328125,\n",
       "  66551.890625,\n",
       "  66566.7265625,\n",
       "  66465.2421875,\n",
       "  66522.40625,\n",
       "  66485.046875,\n",
       "  66552.7109375,\n",
       "  66520.734375,\n",
       "  66553.5625],\n",
       " 'model_3': [66130.4609375,\n",
       "  67272.40625,\n",
       "  83638.9765625,\n",
       "  66143.9375,\n",
       "  67226.1796875,\n",
       "  66144.4609375,\n",
       "  67097.296875,\n",
       "  66138.5078125,\n",
       "  67189.1328125,\n",
       "  66148.8828125,\n",
       "  67069.921875,\n",
       "  66124.4140625,\n",
       "  67010.8203125,\n",
       "  66169.4765625,\n",
       "  66823.8828125,\n",
       "  66220.0703125,\n",
       "  66886.453125,\n",
       "  66285.109375,\n",
       "  66911.9375,\n",
       "  66213.7265625,\n",
       "  67023.796875,\n",
       "  66173.3828125,\n",
       "  67217.671875,\n",
       "  66329.671875,\n",
       "  66756.359375,\n",
       "  66147.7109375,\n",
       "  66910.296875,\n",
       "  66114.046875,\n",
       "  66920.890625,\n",
       "  66103.6484375,\n",
       "  66837.515625,\n",
       "  66136.953125,\n",
       "  66929.0078125,\n",
       "  66154.40625,\n",
       "  66870.2109375,\n",
       "  66278.859375,\n",
       "  66825.6484375,\n",
       "  66143.1640625,\n",
       "  66899.78125,\n",
       "  66150.453125,\n",
       "  66937.296875,\n",
       "  66148.7421875,\n",
       "  66912.3125,\n",
       "  66184.9765625,\n",
       "  66851.859375,\n",
       "  66140.34375,\n",
       "  67008.9375,\n",
       "  66107.9140625,\n",
       "  67025.9140625,\n",
       "  66127.2734375,\n",
       "  66868.2265625,\n",
       "  66143.2265625,\n",
       "  66927.4296875,\n",
       "  66157.609375,\n",
       "  66862.1875,\n",
       "  66157.5078125,\n",
       "  67010.0859375,\n",
       "  66126.6875,\n",
       "  67041.1953125,\n",
       "  66131.9140625,\n",
       "  66983.3984375,\n",
       "  66150.2734375,\n",
       "  67002.3125,\n",
       "  66122.9765625,\n",
       "  66923.9765625,\n",
       "  66149.3046875,\n",
       "  67007.3515625,\n",
       "  66113.515625,\n",
       "  67039.9140625,\n",
       "  66198.546875,\n",
       "  66834.2578125,\n",
       "  66111.1484375,\n",
       "  66849.2421875,\n",
       "  66174.9296875,\n",
       "  66932.71875,\n",
       "  66119.21875,\n",
       "  66986.6796875,\n",
       "  66103.90625,\n",
       "  67005.7421875,\n",
       "  66113.6484375,\n",
       "  66905.9609375,\n",
       "  66212.625,\n",
       "  66907.3125,\n",
       "  66192.53125,\n",
       "  66824.890625,\n",
       "  66144.9375,\n",
       "  66944.3046875,\n",
       "  66120.828125,\n",
       "  67017.1875,\n",
       "  66109.921875,\n",
       "  66948.9765625,\n",
       "  66134.7890625,\n",
       "  66983.046875,\n",
       "  66118.0234375,\n",
       "  66947.4296875,\n",
       "  66157.71875,\n",
       "  67013.453125,\n",
       "  66138.1875,\n",
       "  66973.484375,\n",
       "  66137.3515625,\n",
       "  67034.4765625,\n",
       "  66125.3359375,\n",
       "  67002.09375,\n",
       "  66148.375,\n",
       "  66952.8203125,\n",
       "  66170.7109375,\n",
       "  66836.1796875,\n",
       "  66166.15625,\n",
       "  66864.890625,\n",
       "  66262.1171875,\n",
       "  66835.65625,\n",
       "  66205.703125,\n",
       "  66860.9609375,\n",
       "  66175.5703125,\n",
       "  66892.953125,\n",
       "  66199.1328125,\n",
       "  66891.8125,\n",
       "  66169.5859375,\n",
       "  66934.046875,\n",
       "  66195.421875,\n",
       "  66907.0234375,\n",
       "  66131.046875,\n",
       "  67012.921875,\n",
       "  66117.015625,\n",
       "  67040.078125,\n",
       "  66135.2421875,\n",
       "  66954.421875,\n",
       "  66124.3828125,\n",
       "  66886.265625,\n",
       "  66140.7109375,\n",
       "  66903.4453125,\n",
       "  66166.3046875,\n",
       "  66980.3515625,\n",
       "  66122.1015625,\n",
       "  67031.984375,\n",
       "  66138.375,\n",
       "  66949.6171875,\n",
       "  66167.8203125,\n",
       "  66945.0234375,\n",
       "  66139.2421875,\n",
       "  66976.015625,\n",
       "  66116.859375,\n",
       "  66994.75,\n",
       "  66120.734375,\n",
       "  66950.2109375,\n",
       "  66136.578125,\n",
       "  66863.8984375,\n",
       "  66185.8828125,\n",
       "  66904.359375,\n",
       "  66147.1875,\n",
       "  66938.859375,\n",
       "  66145.859375,\n",
       "  66936.7109375,\n",
       "  66136.6171875,\n",
       "  67002.7578125,\n",
       "  66148.609375,\n",
       "  66982.8515625,\n",
       "  66139.5703125,\n",
       "  66951.5234375,\n",
       "  66138.3984375]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_iter_mse(train_mse_dict[\"model_1\"],\n",
    "                 test_mse_dict[\"model_1\"],\n",
    "                 iteration_dict[\"model_1\"],\n",
    "                 mse_mean = mean_squared_error(y_test, np.ones(shape = (len(y_test),))*np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jetzt mit dem ursprünglichen EnKF-Algorithmus wie für inverse Probleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: \n",
    "$C^{ww}$ ist singuläre Matrix und kann nicht invertiert werden. Mit der Pseudoinversen kommt der Error \"SVD did not converge\" und dieser Error für kleinere Gamma-Diagonalmatrizen später. Obwohl sich der MSE verringert, ist er dennoch mit $10^{23}$ viel zu groß, als dass das so Sinn ergeben würde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "weights_dict = {}\n",
    "y_pred_dict = {}\n",
    "jacobian_dict = {}\n",
    "weights_vector_dict = {}\n",
    "train_mse_dict = {}\n",
    "test_mse_dict = {}\n",
    "iteration_dict = {}\n",
    "\n",
    "# init_model already has weights and biases following the Glorot distribution\n",
    "# it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "# only used to determine shapes and shape_elements via its weights\n",
    "init_model = nn_model_structure(layers = layers,\n",
    "                                neurons = neurons,\n",
    "                                n_cols = n_cols,\n",
    "                                classification = False)\n",
    "init_model = nn_model_compile(init_model,\n",
    "                              optimizer = \"sgd\")\n",
    "weights = init_model.get_weights()\n",
    "# shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "shapes = [np.array(params.shape) for params in weights]\n",
    "# shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(particles):\n",
    "    # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "    model = nn_model_structure(layers = layers,\n",
    "                               neurons = neurons,\n",
    "                               n_cols = n_cols,\n",
    "                               classification = False)\n",
    "    model = nn_model_compile(model,\n",
    "                             optimizer = \"sgd\")\n",
    "    # for every particle write the model in a dictionary\n",
    "    model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "    \n",
    "    # for every particles write the weights and biases in a dictionary\n",
    "    weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                    .get_weights()\n",
    "    \n",
    "    train_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "    test_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "    iteration_dict[\"model_{}\".format(str(i+1))] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-2c54f7d48e96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# compute the matrix with the updates for each particle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mweights_vector_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights_vector_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_theta_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_w_w\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_w_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master_thesis\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[1;34m(a, rcond, hermitian)\u001b[0m\n\u001b[0;32m   2001\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2002\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2003\u001b[1;33m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2005\u001b[0m     \u001b[1;31m# discard small singular values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master_thesis\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m         \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DdD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->ddd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1661\u001b[1;33m         \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1662\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master_thesis\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVD did not converge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "# loop over all epochs\n",
    "for epoch in range(epochs):\n",
    "    # shuffle the data\n",
    "    if shuffle:\n",
    "        indices = y_train.sample(frac=1).index\n",
    "        X_batches = [np.array(X_train)[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "        y_batches = [np.array(i) for i in y_batches]\n",
    "    # loop over all batches\n",
    "    for b in range(num_batches):    \n",
    "        for i in range(particles):\n",
    "            # set new weights for model\n",
    "            model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "            \n",
    "            # for every particle write the predictions on the training batches in a dictionary\n",
    "            y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                            .predict(X_batches[b])\n",
    "\n",
    "            # for every particle write the training accuracy of the current iteration in a dictionary\n",
    "            train_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "            \n",
    "            # for every particle write the test accuracy of the current iteration in a dictionary\n",
    "            test_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "            \n",
    "            # for every particle write the current iteration in a dictionary\n",
    "            iteration_dict[\"model_{}\".format(str(i+1))].append(\"Epoch: {}, Batch: {}.\".format(epoch+1, b+1))\n",
    "            \n",
    "        # compute the mean of the parameters\n",
    "        weights_mean = np.mean(list(weights_dict.values()), axis = 0)\n",
    "        mean_array = np.array([])\n",
    "        for i in range(weights_mean.shape[0]):\n",
    "            mean_array = np.append(mean_array, np.reshape(weights_mean[i], (1, -1)))\n",
    "            \n",
    "        # compute the mean of the predictions\n",
    "        y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "                                       \n",
    "        # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "        for i in range(particles):\n",
    "            weights_array = np.array([])\n",
    "            for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "            weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "            \n",
    "        # compute the \n",
    "        weight_diff_dict = {}\n",
    "        pred_diff_theta_dict = {}\n",
    "        pred_diff_w_dict = {}\n",
    "        c_theta_w_dict = {}\n",
    "        c_w_w_dict = {}\n",
    "        for i in range(particles):\n",
    "            weight_diff_dict[\"model_{}\".format(str(i+1))] = weights_vector_dict[\"model_{}\".format(str(i+1))] - mean_array\n",
    "            pred_diff_theta_dict[\"model_{}\".format(str(i+1))] = y_pred_dict[\"model_{}\".format(str(i+1))] - y_pred_mean\n",
    "            pred_diff_w_dict[\"model_{}\".format(str(i+1))] = y_pred_dict[\"model_{}\".format(str(i+1))] - y_pred_mean\n",
    "        for i in range(particles):\n",
    "            weight_diff_dict[\"model_{}\".format(str(i+1))] = np.transpose(np.tile(weight_diff_dict[\"model_{}\".format(str(i+1))], (pred_diff_theta_dict[\"model_{}\".format(str(i+1))].shape[0], 1)))\n",
    "            pred_diff_theta_dict[\"model_{}\".format(str(i+1))] = np.transpose(np.tile(pred_diff_theta_dict[\"model_{}\".format(str(i+1))], (1, weight_diff_dict[\"model_{}\".format(str(i+1))].shape[0])))\n",
    "            pred_diff_w_dict[\"model_{}\".format(str(i+1))] = np.transpose(np.tile(pred_diff_w_dict[\"model_{}\".format(str(i+1))], (1, pred_diff_w_dict[\"model_{}\".format(str(i+1))].shape[0])))\n",
    "            c_theta_w_dict[\"model_{}\".format(str(i+1))] = np.multiply(weight_diff_dict[\"model_{}\".format(str(i+1))], pred_diff_theta_dict[\"model_{}\".format(str(i+1))])\n",
    "            c_w_w_dict[\"model_{}\".format(str(i+1))] = np.multiply(pred_diff_w_dict[\"model_{}\".format(str(i+1))], pred_diff_w_dict[\"model_{}\".format(str(i+1))])\n",
    "        c_theta_w = np.mean(list(c_theta_w_dict.values()), axis = 0)\n",
    "        c_w_w = np.mean(list(c_w_w_dict.values()), axis = 0)\n",
    "          \n",
    "        # matrix with particle parameters as row vectors\n",
    "        # weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "        for i in range(particles):\n",
    "            print(i)\n",
    "        # compute the matrix with the updates for each particle\n",
    "            weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_vector_dict[\"model_{}\".format(str(i+1))] + np.dot(np.dot(c_theta_w, np.linalg.pinv(c_w_w + np.diag(np.ones(c_w_w.shape[0])*0.1))), y_batches[b] - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "            \n",
    "        for i in range(particles):\n",
    "            # write the updates back into the dictionary\n",
    "            # weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "            # reshape the updates, so that they are of the original matrx and vector shape\n",
    "            for l in range(len(shape_elements)-1):\n",
    "                start = shape_elements[l]\n",
    "                end = shape_elements[l+1]\n",
    "                weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': [73296.65625,\n",
       "  2.4969754563337172e+29,\n",
       "  8.685839227209173e+28,\n",
       "  2.6281990650024244e+28,\n",
       "  1.6774792581632795e+28,\n",
       "  9.368100763638523e+27,\n",
       "  7.570069760314682e+27,\n",
       "  6.838308968707702e+27,\n",
       "  5.201792343830968e+27,\n",
       "  4.159821659147523e+27,\n",
       "  2.860386963522214e+27,\n",
       "  2.1973047282672284e+27,\n",
       "  1.90986549607535e+27,\n",
       "  1.8805995152414808e+27,\n",
       "  1.7100934558630842e+27,\n",
       "  1.645441307233547e+27,\n",
       "  1.1585233380601748e+27,\n",
       "  1.085109871439341e+27,\n",
       "  1.0589205861560378e+27,\n",
       "  8.862726384297547e+26,\n",
       "  7.515354061060913e+26,\n",
       "  6.1594777888062986e+26,\n",
       "  5.396617852726381e+26,\n",
       "  5.053409538407148e+26,\n",
       "  4.993676029617425e+26,\n",
       "  4.749634091024521e+26,\n",
       "  4.568943436669077e+26,\n",
       "  4.3524173994062816e+26,\n",
       "  3.944121593297372e+26,\n",
       "  3.6925559656665655e+26,\n",
       "  3.505103472803462e+26,\n",
       "  3.1865112316459505e+26,\n",
       "  1.8741434499635876e+26,\n",
       "  1.5034430306141019e+26,\n",
       "  1.3392295614676172e+26,\n",
       "  1.3210573049457245e+26,\n",
       "  1.2269427545514213e+26,\n",
       "  1.179322945893742e+26,\n",
       "  1.1416724033695378e+26,\n",
       "  9.42108055048798e+25,\n",
       "  8.802920933205936e+25,\n",
       "  8.514881480855387e+25,\n",
       "  7.661064708031704e+25,\n",
       "  7.3004031912745715e+25,\n",
       "  5.791103503884508e+25,\n",
       "  5.4856720000526635e+25,\n",
       "  5.183162921650697e+25,\n",
       "  4.666097918253007e+25,\n",
       "  4.644813142603557e+25,\n",
       "  4.172845355611467e+25,\n",
       "  3.894414812248914e+25,\n",
       "  3.5705384090177674e+25,\n",
       "  3.1773432920750372e+25,\n",
       "  3.041642355724103e+25,\n",
       "  3.012851138742459e+25,\n",
       "  2.802793682873411e+25,\n",
       "  2.7886076755121264e+25,\n",
       "  2.7108375860031724e+25,\n",
       "  2.2822237981017162e+25,\n",
       "  2.0971669838914657e+25,\n",
       "  1.919588710312998e+25,\n",
       "  1.6294488655653563e+25,\n",
       "  1.5498774514976047e+25,\n",
       "  1.4898710000708807e+25,\n",
       "  1.4316770565415492e+25,\n",
       "  1.2470463621194013e+25,\n",
       "  1.2062277527095482e+25,\n",
       "  1.0032601876330799e+25,\n",
       "  9.258308440748125e+24,\n",
       "  8.581144030242559e+24,\n",
       "  7.922309342277986e+24,\n",
       "  7.193586858547155e+24,\n",
       "  6.979466276711571e+24,\n",
       "  6.73948163030239e+24,\n",
       "  5.78358115223555e+24,\n",
       "  5.162540960574246e+24,\n",
       "  4.657174536391651e+24,\n",
       "  4.7060071031800264e+24,\n",
       "  4.7148736460112053e+24,\n",
       "  3.980390878212982e+24,\n",
       "  3.894641188386343e+24,\n",
       "  3.7689514153363616e+24,\n",
       "  3.1414712923807e+24,\n",
       "  2.9133683667676205e+24,\n",
       "  2.3805667342310252e+24,\n",
       "  2.3642165779134432e+24,\n",
       "  2.1028867427679707e+24,\n",
       "  1.8688335892696155e+24,\n",
       "  1.7178520330578855e+24,\n",
       "  1.5652254019742695e+24,\n",
       "  1.4697616278953776e+24,\n",
       "  1.380748593749949e+24,\n",
       "  1.2190200797330263e+24,\n",
       "  1.2455596121931356e+24,\n",
       "  1.0879100624019178e+24,\n",
       "  9.533821372128083e+23,\n",
       "  8.819894185950683e+23,\n",
       "  8.954062543745543e+23,\n",
       "  5.506925243298962e+23,\n",
       "  5.611140700404137e+23,\n",
       "  4.8247293392321045e+23,\n",
       "  4.9360741746913915e+23,\n",
       "  4.7976086622760794e+23,\n",
       "  3.9033166344781335e+23,\n",
       "  3.9434624421324545e+23,\n",
       "  3.587760577515359e+23,\n",
       "  3.5545333797525894e+23,\n",
       "  3.442606318933476e+23,\n",
       "  2.9534701832607813e+23,\n",
       "  2.889231558751909e+23,\n",
       "  2.498096993562528e+23,\n",
       "  2.3464388165427818e+23,\n",
       "  2.1344707751850962e+23,\n",
       "  1.9693695334216342e+23,\n",
       "  1.7360065115301772e+23,\n",
       "  1.608755862906943e+23,\n",
       "  1.5326468306442326e+23,\n",
       "  9.501757544221056e+22,\n",
       "  8.50320142044196e+22,\n",
       "  7.78529251176201e+22,\n",
       "  7.4040083097496056e+22,\n",
       "  5.8767039191993375e+22,\n",
       "  4.730325244131134e+22,\n",
       "  4.585251239694611e+22,\n",
       "  3.821435788932985e+22,\n",
       "  nan],\n",
       " 'model_2': [73241.9375,\n",
       "  2.4400316501260005e+29,\n",
       "  8.589581342242248e+28,\n",
       "  2.614513410816744e+28,\n",
       "  1.6703886248892507e+28,\n",
       "  9.338659760096883e+27,\n",
       "  7.547657408986983e+27,\n",
       "  6.816695877907228e+27,\n",
       "  5.19043977480615e+27,\n",
       "  4.1510415992642476e+27,\n",
       "  2.8551359871411684e+27,\n",
       "  2.1940091067579957e+27,\n",
       "  1.9067838567973723e+27,\n",
       "  1.877238813619156e+27,\n",
       "  1.707765181613077e+27,\n",
       "  1.6431192310895484e+27,\n",
       "  1.157158943081507e+27,\n",
       "  1.0839149651452225e+27,\n",
       "  1.0577094467271344e+27,\n",
       "  8.852728986879359e+26,\n",
       "  7.508267559857557e+26,\n",
       "  6.154600100738328e+26,\n",
       "  5.392086594512115e+26,\n",
       "  5.049197039930476e+26,\n",
       "  4.988695408717523e+26,\n",
       "  4.745758430094635e+26,\n",
       "  4.565438186360191e+26,\n",
       "  4.349327200839054e+26,\n",
       "  3.94122803702197e+26,\n",
       "  3.690055693974815e+26,\n",
       "  3.502806484231404e+26,\n",
       "  3.184592032392522e+26,\n",
       "  1.8707202876658294e+26,\n",
       "  1.5020928211816267e+26,\n",
       "  1.3385784836355357e+26,\n",
       "  1.3203536538930328e+26,\n",
       "  1.226512484245902e+26,\n",
       "  1.1788909231475357e+26,\n",
       "  1.1411886375062048e+26,\n",
       "  9.417120034535355e+25,\n",
       "  8.800057998525696e+25,\n",
       "  8.512250975150476e+25,\n",
       "  7.658198545171251e+25,\n",
       "  7.298426161478472e+25,\n",
       "  5.789741673003266e+25,\n",
       "  5.4841031044691945e+25,\n",
       "  5.181737910671003e+25,\n",
       "  4.664711184267266e+25,\n",
       "  4.643710488476551e+25,\n",
       "  4.171977897471401e+25,\n",
       "  3.893748423619251e+25,\n",
       "  3.5698614135102622e+25,\n",
       "  3.176384983720408e+25,\n",
       "  3.0409715859927228e+25,\n",
       "  3.01230834329809e+25,\n",
       "  2.802264953071398e+25,\n",
       "  2.7881142251081546e+25,\n",
       "  2.7103591235787606e+25,\n",
       "  2.2817886855258776e+25,\n",
       "  2.096705815289623e+25,\n",
       "  1.919300941105448e+25,\n",
       "  1.6292158601292753e+25,\n",
       "  1.5496622010526946e+25,\n",
       "  1.489538728093253e+25,\n",
       "  1.4314863633246872e+25,\n",
       "  1.2468871436596151e+25,\n",
       "  1.2060828304764192e+25,\n",
       "  1.0031469707413275e+25,\n",
       "  9.257148025253738e+24,\n",
       "  8.579959403396576e+24,\n",
       "  7.921535731948395e+24,\n",
       "  7.192548076271504e+24,\n",
       "  6.978322578579001e+24,\n",
       "  6.738854441003883e+24,\n",
       "  5.782646132895314e+24,\n",
       "  5.162072874443375e+24,\n",
       "  4.6567860018445985e+24,\n",
       "  4.7056424917541944e+24,\n",
       "  4.714511916889135e+24,\n",
       "  3.9800043612785626e+24,\n",
       "  3.894026969454764e+24,\n",
       "  3.768385619107976e+24,\n",
       "  3.141237825776017e+24,\n",
       "  2.913089647993882e+24,\n",
       "  2.380389760780068e+24,\n",
       "  2.364077218526574e+24,\n",
       "  2.102776926994657e+24,\n",
       "  1.8687423643555635e+24,\n",
       "  1.7177671492121088e+24,\n",
       "  1.5651196214262219e+24,\n",
       "  1.4697031171290188e+24,\n",
       "  1.3806922447114114e+24,\n",
       "  1.2189563808198968e+24,\n",
       "  1.2455064336887356e+24,\n",
       "  1.0878633690809812e+24,\n",
       "  9.53339767347514e+23,\n",
       "  8.8196232493971e+23,\n",
       "  8.953793048343841e+23,\n",
       "  5.5067411361461954e+23,\n",
       "  5.6110055924153156e+23,\n",
       "  4.8245848637560585e+23,\n",
       "  4.9359617648446923e+23,\n",
       "  4.797501296460963e+23,\n",
       "  3.9031836882171336e+23,\n",
       "  3.943364083516593e+23,\n",
       "  3.587636998741584e+23,\n",
       "  3.554428175665294e+23,\n",
       "  3.4425274158680044e+23,\n",
       "  2.953374526804696e+23,\n",
       "  2.8891622033176474e+23,\n",
       "  2.4980377261914318e+23,\n",
       "  2.346371082404386e+23,\n",
       "  2.1344111475260298e+23,\n",
       "  1.969270454229832e+23,\n",
       "  1.7359476044470512e+23,\n",
       "  1.608719834109924e+23,\n",
       "  1.5326185480385727e+23,\n",
       "  9.501599017514172e+22,\n",
       "  8.503009567097834e+22,\n",
       "  7.785170013852145e+22,\n",
       "  7.4039123830775426e+22,\n",
       "  5.876643120604368e+22,\n",
       "  4.730263995176202e+22,\n",
       "  4.585205302978412e+22,\n",
       "  3.821396607616227e+22,\n",
       "  nan],\n",
       " 'model_3': [72797.0390625,\n",
       "  2.49164314899592e+29,\n",
       "  8.687552501769158e+28,\n",
       "  2.6293265300002095e+28,\n",
       "  1.6781281113180258e+28,\n",
       "  9.371939457293286e+27,\n",
       "  7.571721407992066e+27,\n",
       "  6.836685064933405e+27,\n",
       "  5.205169426162031e+27,\n",
       "  4.161383581861732e+27,\n",
       "  2.8610953184946447e+27,\n",
       "  2.1982481685461342e+27,\n",
       "  1.9100725423308332e+27,\n",
       "  1.8803183868617975e+27,\n",
       "  1.7107064780621417e+27,\n",
       "  1.6458548094487033e+27,\n",
       "  1.1588236510536948e+27,\n",
       "  1.0854653033041533e+27,\n",
       "  1.0591712405145114e+27,\n",
       "  8.863797033323585e+26,\n",
       "  7.517425999355272e+26,\n",
       "  6.1618002338851786e+26,\n",
       "  5.3977652402077655e+26,\n",
       "  5.054334458155004e+26,\n",
       "  4.9933701826006826e+26,\n",
       "  4.750457922614853e+26,\n",
       "  4.569974240727916e+26,\n",
       "  4.353655544868509e+26,\n",
       "  3.9448882399810755e+26,\n",
       "  3.693462807605229e+26,\n",
       "  3.50597637273303e+26,\n",
       "  3.187415491040444e+26,\n",
       "  1.8711447472469654e+26,\n",
       "  1.5026912335593778e+26,\n",
       "  1.339258799556974e+26,\n",
       "  1.320994862717035e+26,\n",
       "  1.2271837612627443e+26,\n",
       "  1.1795105492809716e+26,\n",
       "  1.141746282579553e+26,\n",
       "  9.42124564884744e+25,\n",
       "  8.804139340652005e+25,\n",
       "  8.516202267731065e+25,\n",
       "  7.661312816739495e+25,\n",
       "  7.3016866234935e+25,\n",
       "  5.792114846628349e+25,\n",
       "  5.4861470037125616e+25,\n",
       "  5.183633774793178e+25,\n",
       "  4.666272239984504e+25,\n",
       "  4.645394215041879e+25,\n",
       "  4.173467472055353e+25,\n",
       "  3.895172973430343e+25,\n",
       "  3.571061604796558e+25,\n",
       "  3.1772309975204885e+25,\n",
       "  3.0418584132140664e+25,\n",
       "  3.013244746144132e+25,\n",
       "  2.80308883077859e+25,\n",
       "  2.7889500931989946e+25,\n",
       "  2.711158328765754e+25,\n",
       "  2.2823838236065557e+25,\n",
       "  2.0972020327052058e+25,\n",
       "  1.9197935844643666e+25,\n",
       "  1.6296030111705223e+25,\n",
       "  1.5500250254501943e+25,\n",
       "  1.4898248832106964e+25,\n",
       "  1.4318120636497387e+25,\n",
       "  1.2471540449879316e+25,\n",
       "  1.2063416613542034e+25,\n",
       "  1.0033456191165712e+25,\n",
       "  9.258838208179492e+24,\n",
       "  8.58140689634561e+24,\n",
       "  7.922979766132915e+24,\n",
       "  7.19362317557455e+24,\n",
       "  6.979288150339109e+24,\n",
       "  6.739991221607426e+24,\n",
       "  5.783364979453436e+24,\n",
       "  5.162833802636416e+24,\n",
       "  4.6574512375527567e+24,\n",
       "  4.70633337996583e+24,\n",
       "  4.7152100108601744e+24,\n",
       "  3.980493199996516e+24,\n",
       "  3.894414927541064e+24,\n",
       "  3.768762624439982e+24,\n",
       "  3.1416079135789957e+24,\n",
       "  2.913388542893951e+24,\n",
       "  2.3806281273011455e+24,\n",
       "  2.364332302409468e+24,\n",
       "  2.1029978555779772e+24,\n",
       "  1.8689305787911905e+24,\n",
       "  1.7179315846417033e+24,\n",
       "  1.565248892749926e+24,\n",
       "  1.4698416118247597e+24,\n",
       "  1.3808174808098494e+24,\n",
       "  1.2190513527288388e+24,\n",
       "  1.2456110613152787e+24,\n",
       "  1.087948324984352e+24,\n",
       "  9.534080779466619e+23,\n",
       "  8.820296987901355e+23,\n",
       "  8.954489124702248e+23,\n",
       "  5.507056388120111e+23,\n",
       "  5.611359755490012e+23,\n",
       "  4.824851476853999e+23,\n",
       "  4.936257921556188e+23,\n",
       "  4.797785203381472e+23,\n",
       "  3.903364913066139e+23,\n",
       "  3.94356836679569e+23,\n",
       "  3.5877944445845566e+23,\n",
       "  3.554592827267671e+23,\n",
       "  3.442695670350083e+23,\n",
       "  2.9534928814029032e+23,\n",
       "  2.889290465835035e+23,\n",
       "  2.4981396876869954e+23,\n",
       "  2.3464573713732466e+23,\n",
       "  2.134485366847889e+23,\n",
       "  1.969321615121599e+23,\n",
       "  1.7359980447628777e+23,\n",
       "  1.6087717155776314e+23,\n",
       "  1.5326697089303397e+23,\n",
       "  9.501845814773752e+22,\n",
       "  8.503190611802854e+22,\n",
       "  7.785351058557165e+22,\n",
       "  7.404093878142526e+22,\n",
       "  5.8767791293131146e+22,\n",
       "  4.730354517528712e+22,\n",
       "  4.585297626770773e+22,\n",
       "  3.821466413410451e+22,\n",
       "  nan]}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "init_model.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
