{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import mnist_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = mnist_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train_small = X_train[:1000, :]\n",
    "X_val_small = X_val[:500, :]\n",
    "y_train_small = y_train[:1000]\n",
    "y_val_small = y_val[:500]\n",
    "\n",
    "n_cols = X_train_small.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_small\n",
    "X_test = X_val_small\n",
    "y_train = y_train_small\n",
    "y_test = y_val_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 5\n",
    "particles = 10\n",
    "early_stopping = 0.001\n",
    "batch_normal = False\n",
    "shuffle = True # noch einbauen!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 5\n",
    "neurons = [128, 128, 64, 32, 10]\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "h_0 = 40\n",
    "epsilon = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "num_batches = int(np.ceil(n / batch_size))\n",
    "batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "batch_indices[-1] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = [X_train[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "y_batches = [y_train[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "weights_dict = {}\n",
    "y_pred_dict = {}\n",
    "jacobian_dict = {}\n",
    "weights_vector_dict = {}\n",
    "\n",
    "# init_model already has weights and biases following the Glorot distribution\n",
    "# it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "# only used to determine shapes and shape_elements via its weights\n",
    "init_model = nn_model_structure(layers = layers,\n",
    "                                neurons = neurons,\n",
    "                                n_cols = n_cols)\n",
    "init_model = nn_model_compile(init_model,\n",
    "                              optimizer = \"sgd\")\n",
    "weights = init_model.get_weights()\n",
    "# shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "shapes = [np.array(params.shape) for params in weights]\n",
    "# shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(particles):\n",
    "    # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "    model = nn_model_structure(layers = layers,\n",
    "                               neurons = neurons,\n",
    "                               n_cols = n_cols)\n",
    "    model = nn_model_compile(model,\n",
    "                             optimizer = \"sgd\")\n",
    "    # for every particle write the model in a dictionary\n",
    "    model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "    \n",
    "    # for every particles write the weights and biases in a dictionary\n",
    "    weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                    .get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 563us/step - loss: 2.3359 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3586 - accuracy: 0.0960\n",
      "0.09600000083446503\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3362 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3503 - accuracy: 0.1080\n",
      "0.1080000028014183\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.4043 - accuracy: 0.0880\n",
      "0.08799999952316284\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3688 - accuracy: 0.0780\n",
      "0.07800000160932541\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3208 - accuracy: 0.1360\n",
      "0.13600000739097595\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.4364 - accuracy: 0.0980\n",
      "0.09799999743700027\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3174 - accuracy: 0.1340\n",
      "0.1340000033378601\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3575 - accuracy: 0.1100\n",
      "0.10999999940395355\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_val_small, y_val_small)[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# loop over all epochs\n",
    "for epoch in range(epochs):\n",
    "    # loop over all batches\n",
    "    for b in range(len(X_batches)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bei b=6 geht was schief -> vorher steigen die Accuracies (zumindest für manche Partikel), dann wieder die 8,4 %\n",
    "\n",
    "da wird der Loss zu groß und dadurch kommen nan\n",
    "\n",
    "da werden die Gewichte und Bias zu groß\n",
    "\n",
    "kleineres $h_t$ hilft (Gewichte und Bias werden langsamer groß), aber Accuracy steigt weniger (vllt auch nur langsamer)\n",
    "\n",
    "#### Lösungsidee: 1) Batch Normalization, 2) (muss sowieso auch noch gemacht werden) Mittelwerte der Partikel\n",
    "\n",
    "### Nach dem ersten Schleifendurchlauf erhalten wir nicht mehr die Wahrscheinlichkeiten, sondern nur noch einen 0-1-Vektor. \n",
    "Zusätzliches .fit hilft nicht. Immer neue Modelle in erster particles-Schleife helfen nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-c9029a93f673>:5: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "[[0.08969521 0.09125192 0.14471631 0.10483738 0.10281324 0.10316657\n",
      "  0.10425069 0.07176778 0.0806197  0.10688114]\n",
      " [0.08218075 0.08765528 0.13450104 0.09481126 0.10923961 0.11760543\n",
      "  0.10356963 0.0544965  0.09163456 0.12430603]\n",
      " [0.09672759 0.08863358 0.14680548 0.08474655 0.10148374 0.10474286\n",
      "  0.119863   0.05183246 0.09142287 0.1137419 ]\n",
      " [0.08609666 0.07721667 0.12806283 0.10249868 0.10793719 0.12640207\n",
      "  0.10267585 0.06010416 0.08524907 0.12375674]\n",
      " [0.09441364 0.08408081 0.12376191 0.09253851 0.11749007 0.10970289\n",
      "  0.09296862 0.06722209 0.09668078 0.12114068]\n",
      " [0.11641724 0.07979588 0.1366833  0.07699235 0.1265276  0.10056099\n",
      "  0.09591322 0.0598855  0.09302006 0.11420383]\n",
      " [0.08666999 0.07766679 0.12446859 0.10231008 0.1156855  0.11812299\n",
      "  0.10312534 0.05735904 0.09939921 0.1151925 ]\n",
      " [0.11322234 0.07653631 0.13658349 0.08500778 0.11121038 0.10405912\n",
      "  0.11110285 0.0693581  0.074049   0.11887062]\n",
      " [0.0876643  0.07814819 0.1154469  0.10631866 0.12375236 0.12625404\n",
      "  0.09453799 0.05743    0.09926029 0.11118723]\n",
      " [0.09447707 0.08218956 0.13651836 0.09271032 0.11265277 0.11789489\n",
      "  0.09868063 0.05424833 0.08861724 0.12201068]\n",
      " [0.10194685 0.08494965 0.13078508 0.09665012 0.11507867 0.1058277\n",
      "  0.10039841 0.06554501 0.08533792 0.11348057]\n",
      " [0.0888986  0.08378709 0.11970357 0.08859584 0.1391006  0.11220165\n",
      "  0.09307609 0.0584623  0.09732818 0.11884596]\n",
      " [0.11619008 0.07792874 0.12554246 0.09733515 0.11452651 0.10128712\n",
      "  0.11212891 0.06926872 0.07944666 0.10634566]\n",
      " [0.090078   0.08568014 0.12922768 0.08898152 0.13834563 0.10909875\n",
      "  0.08590859 0.06216286 0.10010318 0.11041357]\n",
      " [0.0914378  0.07767277 0.12000427 0.10313689 0.12374265 0.12177391\n",
      "  0.09693069 0.06102969 0.08294992 0.1213215 ]\n",
      " [0.10932982 0.07484151 0.13677174 0.0908327  0.11078116 0.11906993\n",
      "  0.10138429 0.05775612 0.09595686 0.10327592]\n",
      " [0.0993933  0.07533195 0.12805963 0.10477633 0.11410651 0.10896789\n",
      "  0.10279979 0.071441   0.08606622 0.10905743]\n",
      " [0.09575646 0.07740287 0.14887169 0.08965785 0.10639632 0.11198272\n",
      "  0.10644312 0.06337093 0.07656625 0.12355176]\n",
      " [0.09485646 0.07399223 0.12990174 0.10377029 0.10140124 0.10918351\n",
      "  0.11855698 0.06808821 0.07569093 0.12455838]\n",
      " [0.08697233 0.08669916 0.13738647 0.09967421 0.11022383 0.11766002\n",
      "  0.10314736 0.06013347 0.08571466 0.11238857]\n",
      " [0.11127733 0.08225277 0.12870553 0.0773958  0.12496585 0.10204082\n",
      "  0.10026702 0.05629287 0.09995455 0.11684751]\n",
      " [0.08169679 0.08443157 0.14166965 0.09198778 0.10475116 0.11657844\n",
      "  0.10500371 0.05581625 0.08985763 0.12820704]\n",
      " [0.08556648 0.07773004 0.14072454 0.09963709 0.10498191 0.1228465\n",
      "  0.10486159 0.05936356 0.08362377 0.12066449]\n",
      " [0.08898006 0.07913359 0.12862347 0.0996918  0.10973271 0.11978734\n",
      "  0.10329191 0.06276605 0.08371019 0.12428293]\n",
      " [0.08585548 0.09426007 0.13486941 0.10205589 0.11470485 0.11648805\n",
      "  0.09955087 0.05039081 0.09562391 0.10620065]\n",
      " [0.07620579 0.08437406 0.17136756 0.08721997 0.10377037 0.12079646\n",
      "  0.10011128 0.05030623 0.07277451 0.13307376]\n",
      " [0.10060739 0.07615557 0.12952282 0.11074898 0.10915305 0.12081268\n",
      "  0.10285968 0.05944731 0.08660653 0.10408603]\n",
      " [0.11402887 0.08023586 0.13359919 0.08912174 0.11574811 0.10409736\n",
      "  0.10695598 0.06444466 0.08239388 0.10937433]\n",
      " [0.10014559 0.08423938 0.12318147 0.09003171 0.12561335 0.0989551\n",
      "  0.09763967 0.06763408 0.09313747 0.11942215]\n",
      " [0.08675388 0.08434564 0.12663017 0.09391937 0.12018526 0.1197844\n",
      "  0.09586517 0.05911923 0.09414522 0.11925166]\n",
      " [0.09848984 0.08184379 0.13285457 0.10337308 0.10704046 0.11891568\n",
      "  0.10782117 0.05473893 0.0781287  0.11679374]\n",
      " [0.10108037 0.07748828 0.15579407 0.08667456 0.10149661 0.11455266\n",
      "  0.10406157 0.0596041  0.07584609 0.12340175]\n",
      " [0.0845892  0.07848818 0.12784585 0.10404897 0.10969879 0.1183573\n",
      "  0.10310754 0.06541056 0.08772922 0.12072425]\n",
      " [0.09004109 0.0843265  0.15249647 0.09374942 0.10339192 0.11678825\n",
      "  0.10395771 0.05622501 0.08056424 0.11845945]\n",
      " [0.11622839 0.0836372  0.13746788 0.07371448 0.121884   0.09424824\n",
      "  0.09862687 0.05536232 0.10505123 0.11377949]\n",
      " [0.09297535 0.08089114 0.1385855  0.08788236 0.11473455 0.10746001\n",
      "  0.10908534 0.05766131 0.0872685  0.12345589]\n",
      " [0.09633619 0.07928162 0.12088477 0.09233955 0.12193996 0.10771713\n",
      "  0.10237564 0.06584657 0.09394792 0.11933064]\n",
      " [0.09192632 0.09211913 0.15135704 0.07833111 0.10944071 0.10128634\n",
      "  0.09937669 0.05290745 0.10103647 0.12221872]\n",
      " [0.09012013 0.08741987 0.1468038  0.09237593 0.11052891 0.11085184\n",
      "  0.09832569 0.05808319 0.10605264 0.09943799]\n",
      " [0.09461794 0.08101629 0.13308795 0.09002136 0.10595796 0.11337765\n",
      "  0.10506996 0.06281903 0.09825823 0.11577353]\n",
      " [0.09811464 0.07623659 0.12311687 0.09542728 0.11575906 0.11777799\n",
      "  0.10682087 0.06284495 0.0838073  0.12009448]\n",
      " [0.09670194 0.07738101 0.141021   0.08792581 0.11033706 0.11422381\n",
      "  0.1082807  0.06260826 0.07329859 0.12822188]\n",
      " [0.10291702 0.07629911 0.12946595 0.1014543  0.10583812 0.12425189\n",
      "  0.11360961 0.06021031 0.07986528 0.10608838]\n",
      " [0.10231369 0.08090916 0.12713219 0.09866435 0.11045624 0.11265934\n",
      "  0.10740131 0.068395   0.08494788 0.10712077]\n",
      " [0.1001219  0.08539841 0.13099857 0.09366985 0.10929315 0.10131584\n",
      "  0.10390135 0.06709018 0.09692731 0.11128356]\n",
      " [0.11083058 0.0783041  0.12361839 0.08702336 0.11132347 0.11596894\n",
      "  0.10483322 0.05900557 0.09350519 0.11558722]\n",
      " [0.1076507  0.0757135  0.12982297 0.09103731 0.10948107 0.11023587\n",
      "  0.11106357 0.06762502 0.090078   0.10729197]\n",
      " [0.10074636 0.07503857 0.13928522 0.09191873 0.11069535 0.11119838\n",
      "  0.10881928 0.06428882 0.08161674 0.11639242]\n",
      " [0.10723248 0.07559297 0.12392908 0.10006761 0.11274286 0.11415181\n",
      "  0.11052064 0.06306757 0.0817799  0.11091505]\n",
      " [0.13116494 0.07714099 0.12578715 0.0873651  0.1217873  0.09655588\n",
      "  0.1122065  0.06909684 0.07196474 0.10693055]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 4.4409525e-35 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for b in range(6):    \n",
    "    for i in range(particles):\n",
    "        # for every particle write the predictions on the training batches in a dictionary\n",
    "        y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .predict(X_batches[b])\n",
    "\n",
    "        # for every particle write the Jacobian in a dictionary\n",
    "        jacobian_dict[\"model_{}\".format(str(i+1))] = (-1) * np.multiply(np.array(y_batches[b]), \n",
    "                                                                        np.array(1 / (y_pred_dict[\"model_{}\".format(str(i+1))] + delta)))\n",
    "    print(y_pred_dict[\"model_1\"])\n",
    "    # bis hier hin alles gut     \n",
    "    # compute the mean of the predictions\n",
    "    y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "    # bis hier ok\n",
    "    # compute the matrix D elementwise\n",
    "    d = np.zeros(shape = (particles, particles))\n",
    "    for k in range(particles):\n",
    "        y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "        for j in range(particles):\n",
    "            d[k][j] = np.sum(np.multiply(y_pred_centered, jacobian_dict[\"model_{}\".format(str(j+1))]))\n",
    "                                    # d sieht recht einfach aus, aber das wird wohl stimmen\n",
    "    # compute the scalar h_t\n",
    "    h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "    # bis hier wohl ok\n",
    "    # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "    for i in range(particles):\n",
    "        weights_array = np.array([])\n",
    "        for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "            weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "    # der Teil ist jetzt gedebugged    \n",
    "    # matrix with particle parameters as row vectors\n",
    "    weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "    # compute the matrix with the updates for each particle\n",
    "    weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "    for i in range(particles):\n",
    "        # write the updates back into the dictionary\n",
    "        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "        # reshape the updates, so that they are of the original matrx and vector shape\n",
    "        for l in range(len(shape_elements)-1):\n",
    "            start = shape_elements[l]\n",
    "            end = shape_elements[l+1]\n",
    "            weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "        # set new weights for model\n",
    "        model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 626us/step - loss: 140049878154722201731282705055744.0000 - accuracy: 0.1200\n",
      "0.11999999731779099\n",
      "16/16 [==============================] - 0s 563us/step - loss: 179745883034061673870524282654687232.0000 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 8175820246955383353036903546880000.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n",
      "16/16 [==============================] - 0s 626us/step - loss: 8485743487550635446378998892855296.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2311773640460428488363986581979136.0000 - accuracy: 0.1300\n",
      "0.12999999523162842\n",
      "16/16 [==============================] - 0s 563us/step - loss: 4387703919701491145761185035452416.0000 - accuracy: 0.1300\n",
      "0.12999999523162842\n",
      "16/16 [==============================] - 0s 563us/step - loss: 101793432585561392074827178621009920.0000 - accuracy: 0.0920\n",
      "0.09200000017881393\n",
      "16/16 [==============================] - 0s 563us/step - loss: 179750953636462586788130269467508736.0000 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 90219232495872700198302620057600.0000 - accuracy: 0.0960\n",
      "0.09600000083446503\n",
      "16/16 [==============================] - 0s 626us/step - loss: 7433656005333188954840617638166528.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_val_small, y_val_small)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a380072608>,\n",
       " 'model_2': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a380115508>,\n",
       " 'model_3': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a380146648>,\n",
       " 'model_4': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a3801768c8>,\n",
       " 'model_5': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a381175b08>,\n",
       " 'model_6': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a3811a6dc8>,\n",
       " 'model_7': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a3811dc0c8>,\n",
       " 'model_8': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a381208388>,\n",
       " 'model_9': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a38123b588>,\n",
       " 'model_10': <tensorflow.python.keras.engine.sequential.Sequential at 0x1a38126d7c8>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 109351.54  ,   18089.766 , -486908.7   , ...,   25869.604 ,\n",
       "          151569.33  , -398260.28  ],\n",
       "        [ 270257.06  ,   67228.93  , -110691.4   , ..., -166657.47  ,\n",
       "         -100774.586 , -493891.16  ],\n",
       "        [  24114.545 ,  112240.53  ,  -40360.992 , ...,    3877.2693,\n",
       "           72167.03  ,   61415.766 ],\n",
       "        ...,\n",
       "        [ 160075.53  , -139677.66  ,  266539.5   , ...,  -64734.17  ,\n",
       "         -215182.47  ,  -34313.73  ],\n",
       "        [   7043.6914,  -15887.845 ,  -42710.277 , ...,   26442.281 ,\n",
       "         -106416.53  , -131934.45  ],\n",
       "        [  37600.117 , -168354.61  , -123748.75  , ...,   31504.328 ,\n",
       "          -90382.51  ,  -68723.74  ]], dtype=float32),\n",
       " array([ 503676.8  , -197197.03 ,   37364.664,  -69890.555, -543318.1  ,\n",
       "         485067.25 ,    6026.515,  465090.38 ,  190716.33 ,   51536.516,\n",
       "         268588.28 , -291804.44 , -216240.05 ,  -92722.016,  765121.06 ,\n",
       "        -290379.03 ,  341754.8  ,   79792.984, -150192.84 ,  551449.7  ,\n",
       "        -413822.2  , -520934.16 ,   25461.633,  434683.8  ,   87098.8  ,\n",
       "         335588.44 ,  131691.67 , -615127.75 ,  128094.164,  332790.22 ,\n",
       "        -384212.84 ,  929717.9  , -456521.44 , -359708.06 , -564951.7  ,\n",
       "        -272214.62 , -279312.62 ,  262921.3  ,   87102.28 ,  160874.88 ,\n",
       "        -269305.9  ,   45392.633,  363064.6  ,  587464.4  ,  314151.   ,\n",
       "         343514.97 , -156871.11 ,   20997.938, -519693.72 ,  381493.8  ,\n",
       "        -843174.9  ,  -54225.785,  -94362.54 ,  499264.28 , -640717.75 ,\n",
       "        -138416.08 ,   33188.7  ,  -55608.258, -423349.12 ,  353976.97 ,\n",
       "        -411139.53 ,  633652.   , -126627.   , -129844.18 , -138318.33 ,\n",
       "         -80554.54 ,   66454.734, -636033.56 , -645076.4  ,  318516.88 ,\n",
       "        -595312.1  ,  -88164.49 , -154402.83 , -331872.6  ,   25966.303,\n",
       "         351404.5  ,  149615.78 ,  -92977.695,  149579.11 , -195275.33 ,\n",
       "         136871.62 , -268476.56 ,  353235.25 ,  601005.2  , -404413.12 ,\n",
       "         506441.06 , -375642.62 , -251238.6  , -238089.12 , -115555.34 ,\n",
       "         370568.44 ,  543257.75 ,  398045.8  , -139064.5  , -105525.664,\n",
       "        -229941.61 ,  652078.94 , -228939.38 , -229244.38 ,  404549.16 ,\n",
       "         130991.23 ,  299135.34 , -539882.7  ,  153222.78 ,  654518.   ,\n",
       "         438624.62 , -154739.73 ,  490419.88 ,  158280.53 , -380481.03 ,\n",
       "         757351.44 ,  -29491.975,  412145.28 ,  241112.27 ,  -96482.81 ,\n",
       "        -279853.9  ,   10450.511,  -52351.74 ,  -68508.016, -144720.78 ,\n",
       "        -499098.56 , -336256.2  ,   74328.516,  174768.2  , -202423.1  ,\n",
       "          51951.492, -570116.56 ,  158316.19 ], dtype=float32),\n",
       " array([[ 650977.25 ,  214993.25 , -250574.27 , ..., -238327.11 ,\n",
       "          180865.66 ,  -81782.42 ],\n",
       "        [-651361.06 ,  -98799.79 ,  349988.72 , ...,  -91984.02 ,\n",
       "         -402111.34 ,  233650.1  ],\n",
       "        [ 192973.5  , -140305.62 , -386890.22 , ...,   47327.137,\n",
       "         -755496.1  , -284492.97 ],\n",
       "        ...,\n",
       "        [-351911.75 ,  -88544.95 ,  -53033.926, ...,  -99975.92 ,\n",
       "         -204535.61 ,  197493.53 ],\n",
       "        [ 361337.78 , -276420.5  ,  424216.75 , ...,  269905.22 ,\n",
       "          389690.06 , -320844.6  ],\n",
       "        [ 774070.25 ,   86659.73 ,  750024.5  , ..., -356983.8  ,\n",
       "          -87327.   , -258560.06 ]], dtype=float32),\n",
       " array([ 1.60612969e+05, -1.79669219e+05,  5.78382500e+05,  8.13302125e+05,\n",
       "         4.43586094e+05,  1.17950406e+05, -5.55120781e+04, -4.55918156e+05,\n",
       "         3.14102781e+05,  1.45949969e+05,  3.80661406e+05,  5.55867938e+05,\n",
       "         3.58230719e+05, -1.26937211e+05,  1.13747203e+05,  2.89517594e+05,\n",
       "         3.77685750e+05, -2.55341250e+05,  4.07071719e+05, -4.85619344e+05,\n",
       "        -1.76760234e+05, -3.62063672e+04,  5.62484375e+05, -8.56418438e+05,\n",
       "        -4.97423438e+05, -3.88702938e+05, -1.29136750e+05, -1.16056625e+05,\n",
       "         1.65479062e+05, -3.26931562e+05, -2.36395234e+05, -7.29419375e+04,\n",
       "        -5.22018344e+05,  6.83392688e+05, -4.88821000e+05, -1.01559375e+05,\n",
       "         3.68868656e+05,  5.53286125e+05,  4.52097906e+05,  2.22016547e+05,\n",
       "         1.18182070e+05,  6.26942875e+05, -6.69528812e+05, -3.36055000e+05,\n",
       "        -1.59337672e+05, -3.47968844e+05, -5.68772578e+04,  9.74410859e+04,\n",
       "        -3.86672656e+05,  8.12913574e+03, -2.78517406e+05, -6.42641062e+05,\n",
       "        -2.97480156e+05, -5.51961375e+05,  1.15622984e+05, -1.67307246e+04,\n",
       "        -3.10098062e+05,  5.22242188e+05, -6.85578594e+04, -3.27289031e+05,\n",
       "        -4.20439406e+05, -4.80224336e+04, -6.45001438e+05, -3.54402000e+05,\n",
       "         2.03075969e+05,  6.19913812e+05, -2.93154125e+05,  7.00165062e+05,\n",
       "         2.80620688e+05, -7.74864250e+05,  7.25662659e+02,  4.63761812e+05,\n",
       "        -5.06827594e+05, -4.07010062e+05,  3.58574875e+05,  3.12241188e+05,\n",
       "         1.15449492e+05, -1.85686703e+05,  7.55741172e+04, -8.31428875e+05,\n",
       "         5.13863375e+05,  3.70821906e+05,  9.44155859e+04, -5.65638562e+05,\n",
       "        -3.28393500e+05, -2.65573375e+05, -3.80185094e+05,  1.51457641e+05,\n",
       "        -1.29952039e+05, -6.51217750e+05,  6.81028188e+05, -1.46155938e+05,\n",
       "        -9.32454609e+04, -3.54965031e+05,  5.11205500e+05,  4.26550000e+05,\n",
       "        -8.40923594e+04, -8.21165039e+03, -7.35513359e+04,  6.58378625e+05,\n",
       "         3.03999316e+04, -2.77104469e+05,  9.35410625e+04,  4.21313062e+05,\n",
       "         5.34994812e+05,  2.18900656e+05,  1.32928438e+05,  2.01748109e+05,\n",
       "        -1.65265203e+05,  4.33442844e+05, -4.85327906e+05, -4.06193531e+05,\n",
       "        -4.26968906e+05,  2.95498340e+04, -5.16381062e+05, -2.69862688e+05,\n",
       "         1.07262070e+04, -3.33859656e+05,  5.70321062e+05, -3.38502938e+05,\n",
       "        -4.13906094e+04, -1.53160812e+05,  2.82898562e+05, -3.92458469e+05,\n",
       "        -1.66046875e+05,  8.47595188e+05,  7.09641438e+05, -3.38042281e+05],\n",
       "       dtype=float32),\n",
       " array([[-441344.1  , -398920.28 , -590963.25 , ..., -401102.12 ,\n",
       "          117066.01 , -652890.94 ],\n",
       "        [ 369206.97 ,  224967.28 ,  444878.78 , ...,  798020.94 ,\n",
       "         -254316.81 , -200114.56 ],\n",
       "        [  57868.344, -717908.9  ,    8824.236, ...,  107850.63 ,\n",
       "         -299134.1  ,  123408.9  ],\n",
       "        ...,\n",
       "        [  38419.87 , -487522.72 ,  129858.29 , ...,  194875.44 ,\n",
       "          117920.16 ,  124132.14 ],\n",
       "        [ 523305.78 ,  188543.31 ,  445716.06 , ...,  426107.6  ,\n",
       "          810411.9  ,   84285.266],\n",
       "        [  96886.41 , -500362.66 ,  443467.25 , ..., -494643.12 ,\n",
       "          601536.5  ,  124924.664]], dtype=float32),\n",
       " array([  -52784.055 ,  -721818.9   ,   191029.17  , -1069806.4   ,\n",
       "          345472.1   ,   514364.4   ,  -701682.8   ,  -431572.72  ,\n",
       "         -427522.3   ,   269330.7   ,   681736.56  ,   258770.84  ,\n",
       "          450982.5   ,   482842.5   ,   872327.8   ,   462767.9   ,\n",
       "          436280.25  ,  -111236.984 ,  -561929.    ,   606694.56  ,\n",
       "         -515273.72  ,  -449799.44  ,    64951.918 ,   462633.2   ,\n",
       "         -728249.56  ,  -247234.98  ,  -126094.1   ,  -327098.56  ,\n",
       "          -48306.79  ,    30076.29  ,  -424569.16  ,  -582733.94  ,\n",
       "          481493.4   ,   459167.28  ,  -516176.4   ,  -704748.25  ,\n",
       "         -138010.25  ,  -117290.97  ,  -168998.03  ,  -335960.75  ,\n",
       "          299448.16  ,   -19803.848 ,   637099.9   ,  1102343.9   ,\n",
       "          -69124.195 ,    52512.93  ,  -422279.97  ,   412700.6   ,\n",
       "          323622.78  ,   412685.75  ,   716515.25  ,  -557821.1   ,\n",
       "          -22923.973 ,     3174.8196,   -27496.648 ,   137091.72  ,\n",
       "          391926.22  ,  -135285.42  ,  -101735.66  ,  -195290.53  ,\n",
       "         -231927.78  ,   211492.7   ,   296578.97  ,   473646.8   ],\n",
       "       dtype=float32),\n",
       " array([[   94296.25 ,  -295080.12 ,  -555193.   , ...,  1340440.6  ,\n",
       "         -1029445.3  ,  -482211.3  ],\n",
       "        [   31964.543,  -514449.38 ,   -53107.93 , ...,  -624973.7  ,\n",
       "          -743244.56 ,   195647.06 ],\n",
       "        [ -179359.16 ,  -567715.9  ,  -243365.   , ...,  -417212.66 ,\n",
       "          -375032.38 ,  -413838.28 ],\n",
       "        ...,\n",
       "        [ -833232.94 ,   220390.56 ,  -325981.97 , ...,   180971.11 ,\n",
       "           402804.   ,   -63204.375],\n",
       "        [ -207608.2  ,   206931.14 ,  -253115.34 , ...,  -233158.77 ,\n",
       "            91714.76 ,  -748035.7  ],\n",
       "        [  -78256.664,  -198425.12 ,   806163.94 , ...,   -72549.52 ,\n",
       "          -261859.84 ,  -286525.25 ]], dtype=float32),\n",
       " array([-2288322.  , -1113546.  ,  1212620.  ,   352655.16,    74365.49,\n",
       "         -108303.07,  -527152.  ,  -261358.27,  -193729.05,  -571688.1 ,\n",
       "         -714627.94,  -337449.25,  -896755.3 ,  -534336.5 ,   -70951.99,\n",
       "         -145319.19,  -226353.05,   112042.15,   522478.62,   408530.66,\n",
       "         -150833.77, -1171884.6 ,  -464540.4 ,   310617.44,   589439.94,\n",
       "         1103175.6 , -1465605.  ,   -74195.65,  -533631.2 ,   943283.1 ,\n",
       "          362307.75,  -827822.7 ], dtype=float32),\n",
       " array([[  -53645.887 ,   158211.56  ,  1108660.1   ,  -469788.6   ,\n",
       "          -802824.2   ,   699714.3   ,  -291863.75  ,  -883179.    ,\n",
       "           808924.    ,  1323323.2   ],\n",
       "        [ -420457.56  ,   306571.62  ,  -647775.44  ,   203288.8   ,\n",
       "          -915145.4   ,   265408.6   ,  -697637.94  ,  -231840.92  ,\n",
       "          -104344.18  ,  -965295.6   ],\n",
       "        [-1234332.9   ,  -904218.44  ,  1887334.5   ,  -235727.47  ,\n",
       "         -1039949.4   ,  -976143.    ,  1737445.    ,   835538.3   ,\n",
       "           526328.2   ,    99635.836 ],\n",
       "        [  824978.06  ,   386373.    , -1108945.    ,   110821.09  ,\n",
       "           785366.3   , -1219546.2   ,   114094.    ,  -923296.9   ,\n",
       "           410089.28  ,    39494.348 ],\n",
       "        [ -668992.    ,  -676811.7   , -1219741.1   ,  -132234.08  ,\n",
       "          -614726.7   ,   162893.17  ,   -98830.805 ,   950638.7   ,\n",
       "          -695563.9   ,  1130040.6   ],\n",
       "        [  823120.56  ,   785604.    ,  -616536.06  ,   611204.2   ,\n",
       "           253058.34  ,   752869.56  ,   412766.06  ,   571364.44  ,\n",
       "          -554286.6   ,   576296.6   ],\n",
       "        [ -145056.38  , -1769891.    ,  -430492.16  ,  -554777.06  ,\n",
       "          1000131.44  ,   856314.4   ,  -438527.5   ,   295751.16  ,\n",
       "           278508.2   , -1192714.1   ],\n",
       "        [-1122441.    ,  1322680.8   ,   958845.75  ,  -269918.9   ,\n",
       "         -1103538.    ,  -379737.84  , -1341615.4   , -1116159.2   ,\n",
       "            80517.47  ,   475603.72  ],\n",
       "        [ -676845.75  , -1496649.9   ,  2222733.2   ,  -845210.06  ,\n",
       "           881863.94  ,  -658305.9   ,  -471596.06  ,  -879887.3   ,\n",
       "          -734850.2   ,   940262.56  ],\n",
       "        [  281895.66  ,   209351.95  ,  -863430.    ,  -277048.34  ,\n",
       "           915895.3   ,  -753879.56  ,  -464764.62  ,  -732205.    ,\n",
       "           866552.8   ,  -314932.4   ],\n",
       "        [-1438185.1   ,  -357971.5   , -2268282.5   ,   207244.3   ,\n",
       "           421665.62  ,  1200964.8   ,  -999650.6   ,    10223.808 ,\n",
       "           231360.62  ,   530731.1   ],\n",
       "        [-1895573.4   ,   549428.2   ,   688602.7   ,  1735207.9   ,\n",
       "          -219983.14  ,   808414.    , -1406176.    , -1114710.8   ,\n",
       "           464000.12  ,    47870.508 ],\n",
       "        [ -697715.25  ,  -430746.25  ,   474820.5   ,  -700843.2   ,\n",
       "           681125.7   ,   385896.3   ,  -309084.5   ,  -698079.    ,\n",
       "          -194028.22  , -2040183.    ],\n",
       "        [ -230899.77  ,  -339818.25  ,   519423.94  ,   863674.7   ,\n",
       "          -981233.44  , -1110257.9   ,   398810.5   ,  -557977.44  ,\n",
       "          1114595.8   ,   384039.72  ],\n",
       "        [-1287590.    , -1733015.2   ,  -450373.28  ,  1345155.9   ,\n",
       "           625507.56  ,  -729149.06  ,  -794839.    ,   707602.5   ,\n",
       "          -452850.97  ,   130032.14  ],\n",
       "        [-1047946.94  ,  -161385.86  ,  -471524.8   ,  -830635.1   ,\n",
       "           769347.4   , -1275178.8   ,  -450196.56  , -1524522.6   ,\n",
       "          -338543.06  ,  -546132.5   ],\n",
       "        [  267499.53  ,   378601.25  ,   857727.25  ,   620274.25  ,\n",
       "           796786.6   ,   235099.38  ,  1560744.4   ,  1047049.25  ,\n",
       "           -59325.96  ,   345182.97  ],\n",
       "        [  816017.3   ,   345254.22  ,   -62270.605 ,  -797472.94  ,\n",
       "          -196635.4   ,   438125.28  ,   854619.3   ,   626623.7   ,\n",
       "          -317160.66  ,   758067.6   ],\n",
       "        [  183253.56  ,  -565379.94  ,   531420.7   ,  -460101.62  ,\n",
       "           654456.25  ,  -664399.1   ,   853052.44  ,   565968.56  ,\n",
       "          -523437.1   ,  -254507.03  ],\n",
       "        [ 1255899.8   ,   174466.36  ,   378918.12  ,  1268314.2   ,\n",
       "          -132150.38  ,   -15794.376 , -1850911.9   ,   -72700.93  ,\n",
       "          -572119.5   , -1317137.1   ],\n",
       "        [  702730.2   ,   642228.56  ,  -539413.44  ,  -218263.98  ,\n",
       "          -100964.99  ,  1380319.6   ,  -990199.94  ,  -681065.3   ,\n",
       "         -1285442.    ,   892103.25  ],\n",
       "        [ -273769.9   ,    46887.242 ,  -626160.2   , -1147151.2   ,\n",
       "           297486.9   ,   956299.5   ,   657250.94  ,  1031928.4   ,\n",
       "          -111695.76  ,  -655404.06  ],\n",
       "        [-1630911.2   ,   248207.6   ,   157791.17  ,  1339766.9   ,\n",
       "           611419.2   ,   637307.4   , -1189703.    ,   -43599.23  ,\n",
       "          -112359.    , -1452264.4   ],\n",
       "        [ -816305.2   ,   512908.75  ,  -181614.08  ,   433690.97  ,\n",
       "           221655.62  ,   -87280.09  ,  -538705.1   ,   167563.36  ,\n",
       "             3870.4766,  -807046.8   ],\n",
       "        [ -883426.75  ,   658266.44  ,   779124.4   ,   352169.56  ,\n",
       "           431724.12  ,  -797669.3   ,   884208.94  ,  -320352.28  ,\n",
       "           556321.44  ,  1357893.9   ],\n",
       "        [   -7857.499 ,  -403522.44  ,  -360904.97  ,   998441.8   ,\n",
       "           516686.38  , -1265437.1   ,  -742431.6   ,   937747.4   ,\n",
       "          1189844.9   , -1267578.2   ],\n",
       "        [ -771395.3   ,   888789.9   ,   507350.38  ,  -458797.3   ,\n",
       "          1339138.4   ,  -289558.1   ,  1459296.6   ,  -666392.2   ,\n",
       "          -582331.    ,   966024.3   ],\n",
       "        [ -886494.5   ,   436927.4   , -1321778.9   ,   293827.5   ,\n",
       "           755038.1   ,   710098.1   ,  -426706.44  ,  -262401.97  ,\n",
       "            47665.99  ,  -732355.8   ],\n",
       "        [  109840.02  ,   419012.53  ,  -148680.69  ,  -597055.56  ,\n",
       "           764377.75  ,  -716163.2   ,   100039.62  ,  1143997.9   ,\n",
       "          -838785.3   ,  -262928.3   ],\n",
       "        [ 1652013.8   ,   247584.02  ,  -504600.78  ,   -16213.009 ,\n",
       "          -334358.34  ,  2242333.5   ,  2054452.    ,  -440909.5   ,\n",
       "         -1959275.8   ,  1129276.    ],\n",
       "        [  505745.88  ,   762417.56  , -1147818.4   ,   412785.97  ,\n",
       "           -44320.363 ,   153082.22  , -1455464.2   ,  -442501.38  ,\n",
       "          -714851.8   ,   -85064.26  ],\n",
       "        [-1916991.8   , -1003929.25  ,   411729.22  , -1690219.8   ,\n",
       "           399378.34  ,   852684.6   , -1158981.    ,  -764765.1   ,\n",
       "           605561.56  ,  -563752.4   ]], dtype=float32),\n",
       " array([ 1735230.1 ,  -565231.44,  -606586.94,  -585480.  ,  2238889.2 ,\n",
       "        -2030346.4 , -1622896.8 , -2542892.2 ,   677200.3 ,  1308973.8 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[\"model_1\"].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "init_model.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 563us/step - loss: 2.3020 - accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.30204439163208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model.evaluate(X_test, y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dict[\"model_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.99502486,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [-200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.99502486,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ],\n",
       "       [  -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ],\n",
       "       [-200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        , -200.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [-200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ],\n",
       "       [-200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "        -200.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        , -200.        ,\n",
       "          -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ],\n",
       "       [  -0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "          -0.        ,   -0.        , -200.        ,   -0.        ,\n",
       "          -0.        ,   -0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_dict[\"model_1\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
