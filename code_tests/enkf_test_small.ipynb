{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import mnist_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = mnist_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train_small = X_train[:1000, :]\n",
    "X_val_small = X_val[:500, :]\n",
    "y_train_small = y_train[:1000]\n",
    "y_val_small = y_val[:500]\n",
    "\n",
    "n_cols = X_train_small.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_small\n",
    "X_test = X_val_small\n",
    "y_train = y_train_small\n",
    "y_test = y_val_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 5\n",
    "particles = 10\n",
    "early_stopping = 0.001\n",
    "batch_normal = False\n",
    "shuffle = True # noch einbauen!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 5\n",
    "neurons = [128, 128, 64, 32, 10]\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.005\n",
    "h_0 = 40\n",
    "epsilon = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "num_batches = int(np.ceil(n / batch_size))\n",
    "batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "batch_indices[-1] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = [X_train[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "y_batches = [y_train[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "weights_dict = {}\n",
    "y_pred_dict = {}\n",
    "jacobian_dict = {}\n",
    "weights_vector_dict = {}\n",
    "\n",
    "# init_model already has weights and biases following the Glorot distribution\n",
    "# it can already be used to predict and evaluate, but it is very bad (<10% accuracy)\n",
    "# only used to determine shapes and shape_elements via its weights\n",
    "init_model = nn_model_structure(layers = layers,\n",
    "                                neurons = neurons,\n",
    "                                n_cols = n_cols)\n",
    "init_model = nn_model_compile(init_model,\n",
    "                              optimizer = \"sgd\")\n",
    "weights = init_model.get_weights()\n",
    "# shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "shapes = [np.array(params.shape) for params in weights]\n",
    "# shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(particles):\n",
    "    # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "    model = nn_model_structure(layers = layers,\n",
    "                               neurons = neurons,\n",
    "                               n_cols = n_cols)\n",
    "    model = nn_model_compile(model,\n",
    "                             optimizer = \"sgd\")\n",
    "    # for every particle write the model in a dictionary\n",
    "    model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "    \n",
    "    # for every particles write the weights and biases in a dictionary\n",
    "    weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                    .get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 626us/step - loss: 2.3359 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 626us/step - loss: 2.3586 - accuracy: 0.0960\n",
      "0.09600000083446503\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3362 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3503 - accuracy: 0.1080\n",
      "0.1080000028014183\n",
      "16/16 [==============================] - 0s 626us/step - loss: 2.4043 - accuracy: 0.0880\n",
      "0.08799999952316284\n",
      "16/16 [==============================] - 0s 626us/step - loss: 2.3688 - accuracy: 0.0780\n",
      "0.07800000160932541\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3208 - accuracy: 0.1360\n",
      "0.13600000739097595\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.4364 - accuracy: 0.0980\n",
      "0.09799999743700027\n",
      "16/16 [==============================] - 0s 500us/step - loss: 2.3174 - accuracy: 0.1340\n",
      "0.1340000033378601\n",
      "16/16 [==============================] - 0s 563us/step - loss: 2.3575 - accuracy: 0.1100\n",
      "0.10999999940395355\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_val_small, y_val_small)[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# loop over all epochs\n",
    "for epoch in range(epochs):\n",
    "    # loop over all batches\n",
    "    for b in range(len(X_batches)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bei b=6 geht was schief -> vorher steigen die Accuracies (zumindest für manche Partikel), dann wieder die 8,4 %\n",
    "\n",
    "da wird der Loss zu groß und dadurch kommen nan\n",
    "\n",
    "da werden die Gewichte und Bias zu groß\n",
    "\n",
    "kleineres $h_t$ hilft (Gewichte und Bias werden langsamer groß), aber Accuracy steigt weniger (vllt auch nur langsamer)\n",
    "\n",
    "#### Lösungsidee: 1) Batch Normalization, 2) (muss sowieso auch noch gemacht werden) Mittelwerte der Partikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(6):    \n",
    "    for i in range(particles):\n",
    "        # for every particle write the predictions on the training batches in a dictionary\n",
    "        y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .predict(X_batches[b])\n",
    "\n",
    "        # for every particle write the Jacobian in a dictionary\n",
    "        jacobian_dict[\"model_{}\".format(str(i+1))] = (-1) * np.multiply(np.array(y_batches[b]), \n",
    "                                                                        np.array(1 / (y_pred_dict[\"model_{}\".format(str(i+1))] + delta)))\n",
    "    # bis hier hin alles gut     \n",
    "    # compute the mean of the predictions\n",
    "    y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "    # bis hier ok\n",
    "    # compute the matrix D elementwise\n",
    "    d = np.zeros(shape = (particles, particles))\n",
    "    for k in range(particles):\n",
    "        y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "        for j in range(particles):\n",
    "            d[k][j] = np.sum(np.multiply(y_pred_centered, jacobian_dict[\"model_{}\".format(str(j+1))]))\n",
    "                                    # d sieht recht einfach aus, aber das wird wohl stimmen\n",
    "    # compute the scalar h_t\n",
    "    h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "    # bis hier wohl ok\n",
    "    # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "    for i in range(particles):\n",
    "        weights_array = np.array([])\n",
    "        for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "            weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "    # der Teil ist jetzt gedebugged    \n",
    "    # matrix with particle parameters as row vectors\n",
    "    weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "    # compute the matrix with the updates for each particle\n",
    "    weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "    for i in range(particles):\n",
    "        # write the updates back into the dictionary\n",
    "        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "        # reshape the updates, so that they are of the original matrx and vector shape\n",
    "        for l in range(len(shape_elements)-1):\n",
    "            start = shape_elements[l]\n",
    "            end = shape_elements[l+1]\n",
    "            weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "        # set new weights for model\n",
    "        model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 563us/step - loss: 140049878154722201731282705055744.0000 - accuracy: 0.1200\n",
      "0.11999999731779099\n",
      "16/16 [==============================] - 0s 626us/step - loss: 179745883034061673870524282654687232.0000 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 626us/step - loss: 8175820246955383353036903546880000.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n",
      "16/16 [==============================] - 0s 626us/step - loss: 8485743487550635446378998892855296.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n",
      "16/16 [==============================] - 0s 688us/step - loss: 2311773640460428488363986581979136.0000 - accuracy: 0.1300\n",
      "0.12999999523162842\n",
      "16/16 [==============================] - 0s 563us/step - loss: 4387703919701491145761185035452416.0000 - accuracy: 0.1300\n",
      "0.12999999523162842\n",
      "16/16 [==============================] - 0s 563us/step - loss: 101793432585561392074827178621009920.0000 - accuracy: 0.0920\n",
      "0.09200000017881393\n",
      "16/16 [==============================] - 0s 626us/step - loss: 179750953636462586788130269467508736.0000 - accuracy: 0.0900\n",
      "0.09000000357627869\n",
      "16/16 [==============================] - 0s 563us/step - loss: 90219232495872700198302620057600.0000 - accuracy: 0.0960\n",
      "0.09600000083446503\n",
      "16/16 [==============================] - 0s 626us/step - loss: 7433656005333188954840617638166528.0000 - accuracy: 0.1000\n",
      "0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "for i in range(particles):\n",
    "    print(model_dict[\"model_{}\".format(str(i+1))].evaluate(X_val_small, y_val_small)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': <tensorflow.python.keras.engine.sequential.Sequential at 0x24902e9be88>,\n",
       " 'model_2': <tensorflow.python.keras.engine.sequential.Sequential at 0x24902fc16c8>,\n",
       " 'model_3': <tensorflow.python.keras.engine.sequential.Sequential at 0x24902ff1808>,\n",
       " 'model_4': <tensorflow.python.keras.engine.sequential.Sequential at 0x249030097c8>,\n",
       " 'model_5': <tensorflow.python.keras.engine.sequential.Sequential at 0x2490302fc08>,\n",
       " 'model_6': <tensorflow.python.keras.engine.sequential.Sequential at 0x24904036148>,\n",
       " 'model_7': <tensorflow.python.keras.engine.sequential.Sequential at 0x24904065108>,\n",
       " 'model_8': <tensorflow.python.keras.engine.sequential.Sequential at 0x24904097948>,\n",
       " 'model_9': <tensorflow.python.keras.engine.sequential.Sequential at 0x249040c6208>,\n",
       " 'model_10': <tensorflow.python.keras.engine.sequential.Sequential at 0x249040e76c8>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 109351.54  ,   18089.766 , -486908.7   , ...,   25869.604 ,\n",
       "          151569.33  , -398260.28  ],\n",
       "        [ 270257.06  ,   67228.93  , -110691.4   , ..., -166657.47  ,\n",
       "         -100774.586 , -493891.16  ],\n",
       "        [  24114.545 ,  112240.53  ,  -40360.992 , ...,    3877.2693,\n",
       "           72167.03  ,   61415.766 ],\n",
       "        ...,\n",
       "        [ 160075.53  , -139677.66  ,  266539.5   , ...,  -64734.17  ,\n",
       "         -215182.47  ,  -34313.73  ],\n",
       "        [   7043.6914,  -15887.845 ,  -42710.277 , ...,   26442.281 ,\n",
       "         -106416.53  , -131934.45  ],\n",
       "        [  37600.117 , -168354.61  , -123748.75  , ...,   31504.328 ,\n",
       "          -90382.51  ,  -68723.74  ]], dtype=float32),\n",
       " array([ 503676.8  , -197197.03 ,   37364.664,  -69890.555, -543318.1  ,\n",
       "         485067.25 ,    6026.515,  465090.38 ,  190716.33 ,   51536.516,\n",
       "         268588.28 , -291804.44 , -216240.05 ,  -92722.016,  765121.06 ,\n",
       "        -290379.03 ,  341754.8  ,   79792.984, -150192.84 ,  551449.7  ,\n",
       "        -413822.2  , -520934.16 ,   25461.633,  434683.8  ,   87098.8  ,\n",
       "         335588.44 ,  131691.67 , -615127.75 ,  128094.164,  332790.22 ,\n",
       "        -384212.84 ,  929717.9  , -456521.44 , -359708.06 , -564951.7  ,\n",
       "        -272214.62 , -279312.62 ,  262921.3  ,   87102.28 ,  160874.88 ,\n",
       "        -269305.9  ,   45392.633,  363064.6  ,  587464.4  ,  314151.   ,\n",
       "         343514.97 , -156871.11 ,   20997.938, -519693.72 ,  381493.8  ,\n",
       "        -843174.9  ,  -54225.785,  -94362.54 ,  499264.28 , -640717.75 ,\n",
       "        -138416.08 ,   33188.7  ,  -55608.258, -423349.12 ,  353976.97 ,\n",
       "        -411139.53 ,  633652.   , -126627.   , -129844.18 , -138318.33 ,\n",
       "         -80554.54 ,   66454.734, -636033.56 , -645076.4  ,  318516.88 ,\n",
       "        -595312.1  ,  -88164.49 , -154402.83 , -331872.6  ,   25966.303,\n",
       "         351404.5  ,  149615.78 ,  -92977.695,  149579.11 , -195275.33 ,\n",
       "         136871.62 , -268476.56 ,  353235.25 ,  601005.2  , -404413.12 ,\n",
       "         506441.06 , -375642.62 , -251238.6  , -238089.12 , -115555.34 ,\n",
       "         370568.44 ,  543257.75 ,  398045.8  , -139064.5  , -105525.664,\n",
       "        -229941.61 ,  652078.94 , -228939.38 , -229244.38 ,  404549.16 ,\n",
       "         130991.23 ,  299135.34 , -539882.7  ,  153222.78 ,  654518.   ,\n",
       "         438624.62 , -154739.73 ,  490419.88 ,  158280.53 , -380481.03 ,\n",
       "         757351.44 ,  -29491.975,  412145.28 ,  241112.27 ,  -96482.81 ,\n",
       "        -279853.9  ,   10450.511,  -52351.74 ,  -68508.016, -144720.78 ,\n",
       "        -499098.56 , -336256.2  ,   74328.516,  174768.2  , -202423.1  ,\n",
       "          51951.492, -570116.56 ,  158316.19 ], dtype=float32),\n",
       " array([[ 650977.25 ,  214993.25 , -250574.27 , ..., -238327.11 ,\n",
       "          180865.66 ,  -81782.42 ],\n",
       "        [-651361.06 ,  -98799.79 ,  349988.72 , ...,  -91984.02 ,\n",
       "         -402111.34 ,  233650.1  ],\n",
       "        [ 192973.5  , -140305.62 , -386890.22 , ...,   47327.137,\n",
       "         -755496.1  , -284492.97 ],\n",
       "        ...,\n",
       "        [-351911.75 ,  -88544.95 ,  -53033.926, ...,  -99975.92 ,\n",
       "         -204535.61 ,  197493.53 ],\n",
       "        [ 361337.78 , -276420.5  ,  424216.75 , ...,  269905.22 ,\n",
       "          389690.06 , -320844.6  ],\n",
       "        [ 774070.25 ,   86659.73 ,  750024.5  , ..., -356983.8  ,\n",
       "          -87327.   , -258560.06 ]], dtype=float32),\n",
       " array([ 1.60612969e+05, -1.79669219e+05,  5.78382500e+05,  8.13302125e+05,\n",
       "         4.43586094e+05,  1.17950406e+05, -5.55120781e+04, -4.55918156e+05,\n",
       "         3.14102781e+05,  1.45949969e+05,  3.80661406e+05,  5.55867938e+05,\n",
       "         3.58230719e+05, -1.26937211e+05,  1.13747203e+05,  2.89517594e+05,\n",
       "         3.77685750e+05, -2.55341250e+05,  4.07071719e+05, -4.85619344e+05,\n",
       "        -1.76760234e+05, -3.62063672e+04,  5.62484375e+05, -8.56418438e+05,\n",
       "        -4.97423438e+05, -3.88702938e+05, -1.29136750e+05, -1.16056625e+05,\n",
       "         1.65479062e+05, -3.26931562e+05, -2.36395234e+05, -7.29419375e+04,\n",
       "        -5.22018344e+05,  6.83392688e+05, -4.88821000e+05, -1.01559375e+05,\n",
       "         3.68868656e+05,  5.53286125e+05,  4.52097906e+05,  2.22016547e+05,\n",
       "         1.18182070e+05,  6.26942875e+05, -6.69528812e+05, -3.36055000e+05,\n",
       "        -1.59337672e+05, -3.47968844e+05, -5.68772578e+04,  9.74410859e+04,\n",
       "        -3.86672656e+05,  8.12913574e+03, -2.78517406e+05, -6.42641062e+05,\n",
       "        -2.97480156e+05, -5.51961375e+05,  1.15622984e+05, -1.67307246e+04,\n",
       "        -3.10098062e+05,  5.22242188e+05, -6.85578594e+04, -3.27289031e+05,\n",
       "        -4.20439406e+05, -4.80224336e+04, -6.45001438e+05, -3.54402000e+05,\n",
       "         2.03075969e+05,  6.19913812e+05, -2.93154125e+05,  7.00165062e+05,\n",
       "         2.80620688e+05, -7.74864250e+05,  7.25662659e+02,  4.63761812e+05,\n",
       "        -5.06827594e+05, -4.07010062e+05,  3.58574875e+05,  3.12241188e+05,\n",
       "         1.15449492e+05, -1.85686703e+05,  7.55741172e+04, -8.31428875e+05,\n",
       "         5.13863375e+05,  3.70821906e+05,  9.44155859e+04, -5.65638562e+05,\n",
       "        -3.28393500e+05, -2.65573375e+05, -3.80185094e+05,  1.51457641e+05,\n",
       "        -1.29952039e+05, -6.51217750e+05,  6.81028188e+05, -1.46155938e+05,\n",
       "        -9.32454609e+04, -3.54965031e+05,  5.11205500e+05,  4.26550000e+05,\n",
       "        -8.40923594e+04, -8.21165039e+03, -7.35513359e+04,  6.58378625e+05,\n",
       "         3.03999316e+04, -2.77104469e+05,  9.35410625e+04,  4.21313062e+05,\n",
       "         5.34994812e+05,  2.18900656e+05,  1.32928438e+05,  2.01748109e+05,\n",
       "        -1.65265203e+05,  4.33442844e+05, -4.85327906e+05, -4.06193531e+05,\n",
       "        -4.26968906e+05,  2.95498340e+04, -5.16381062e+05, -2.69862688e+05,\n",
       "         1.07262070e+04, -3.33859656e+05,  5.70321062e+05, -3.38502938e+05,\n",
       "        -4.13906094e+04, -1.53160812e+05,  2.82898562e+05, -3.92458469e+05,\n",
       "        -1.66046875e+05,  8.47595188e+05,  7.09641438e+05, -3.38042281e+05],\n",
       "       dtype=float32),\n",
       " array([[-441344.1  , -398920.28 , -590963.25 , ..., -401102.12 ,\n",
       "          117066.01 , -652890.94 ],\n",
       "        [ 369206.97 ,  224967.28 ,  444878.78 , ...,  798020.94 ,\n",
       "         -254316.81 , -200114.56 ],\n",
       "        [  57868.344, -717908.9  ,    8824.236, ...,  107850.63 ,\n",
       "         -299134.1  ,  123408.9  ],\n",
       "        ...,\n",
       "        [  38419.87 , -487522.72 ,  129858.29 , ...,  194875.44 ,\n",
       "          117920.16 ,  124132.14 ],\n",
       "        [ 523305.78 ,  188543.31 ,  445716.06 , ...,  426107.6  ,\n",
       "          810411.9  ,   84285.266],\n",
       "        [  96886.41 , -500362.66 ,  443467.25 , ..., -494643.12 ,\n",
       "          601536.5  ,  124924.664]], dtype=float32),\n",
       " array([  -52784.055 ,  -721818.9   ,   191029.17  , -1069806.4   ,\n",
       "          345472.1   ,   514364.4   ,  -701682.8   ,  -431572.72  ,\n",
       "         -427522.3   ,   269330.7   ,   681736.56  ,   258770.84  ,\n",
       "          450982.5   ,   482842.5   ,   872327.8   ,   462767.9   ,\n",
       "          436280.25  ,  -111236.984 ,  -561929.    ,   606694.56  ,\n",
       "         -515273.72  ,  -449799.44  ,    64951.918 ,   462633.2   ,\n",
       "         -728249.56  ,  -247234.98  ,  -126094.1   ,  -327098.56  ,\n",
       "          -48306.79  ,    30076.29  ,  -424569.16  ,  -582733.94  ,\n",
       "          481493.4   ,   459167.28  ,  -516176.4   ,  -704748.25  ,\n",
       "         -138010.25  ,  -117290.97  ,  -168998.03  ,  -335960.75  ,\n",
       "          299448.16  ,   -19803.848 ,   637099.9   ,  1102343.9   ,\n",
       "          -69124.195 ,    52512.93  ,  -422279.97  ,   412700.6   ,\n",
       "          323622.78  ,   412685.75  ,   716515.25  ,  -557821.1   ,\n",
       "          -22923.973 ,     3174.8196,   -27496.648 ,   137091.72  ,\n",
       "          391926.22  ,  -135285.42  ,  -101735.66  ,  -195290.53  ,\n",
       "         -231927.78  ,   211492.7   ,   296578.97  ,   473646.8   ],\n",
       "       dtype=float32),\n",
       " array([[   94296.25 ,  -295080.12 ,  -555193.   , ...,  1340440.6  ,\n",
       "         -1029445.3  ,  -482211.3  ],\n",
       "        [   31964.543,  -514449.38 ,   -53107.93 , ...,  -624973.7  ,\n",
       "          -743244.56 ,   195647.06 ],\n",
       "        [ -179359.16 ,  -567715.9  ,  -243365.   , ...,  -417212.66 ,\n",
       "          -375032.38 ,  -413838.28 ],\n",
       "        ...,\n",
       "        [ -833232.94 ,   220390.56 ,  -325981.97 , ...,   180971.11 ,\n",
       "           402804.   ,   -63204.375],\n",
       "        [ -207608.2  ,   206931.14 ,  -253115.34 , ...,  -233158.77 ,\n",
       "            91714.76 ,  -748035.7  ],\n",
       "        [  -78256.664,  -198425.12 ,   806163.94 , ...,   -72549.52 ,\n",
       "          -261859.84 ,  -286525.25 ]], dtype=float32),\n",
       " array([-2288322.  , -1113546.  ,  1212620.  ,   352655.16,    74365.49,\n",
       "         -108303.07,  -527152.  ,  -261358.27,  -193729.05,  -571688.1 ,\n",
       "         -714627.94,  -337449.25,  -896755.3 ,  -534336.5 ,   -70951.99,\n",
       "         -145319.19,  -226353.05,   112042.15,   522478.62,   408530.66,\n",
       "         -150833.77, -1171884.6 ,  -464540.4 ,   310617.44,   589439.94,\n",
       "         1103175.6 , -1465605.  ,   -74195.65,  -533631.2 ,   943283.1 ,\n",
       "          362307.75,  -827822.7 ], dtype=float32),\n",
       " array([[  -53645.887 ,   158211.56  ,  1108660.1   ,  -469788.6   ,\n",
       "          -802824.2   ,   699714.3   ,  -291863.75  ,  -883179.    ,\n",
       "           808924.    ,  1323323.2   ],\n",
       "        [ -420457.56  ,   306571.62  ,  -647775.44  ,   203288.8   ,\n",
       "          -915145.4   ,   265408.6   ,  -697637.94  ,  -231840.92  ,\n",
       "          -104344.18  ,  -965295.6   ],\n",
       "        [-1234332.9   ,  -904218.44  ,  1887334.5   ,  -235727.47  ,\n",
       "         -1039949.4   ,  -976143.    ,  1737445.    ,   835538.3   ,\n",
       "           526328.2   ,    99635.836 ],\n",
       "        [  824978.06  ,   386373.    , -1108945.    ,   110821.09  ,\n",
       "           785366.3   , -1219546.2   ,   114094.    ,  -923296.9   ,\n",
       "           410089.28  ,    39494.348 ],\n",
       "        [ -668992.    ,  -676811.7   , -1219741.1   ,  -132234.08  ,\n",
       "          -614726.7   ,   162893.17  ,   -98830.805 ,   950638.7   ,\n",
       "          -695563.9   ,  1130040.6   ],\n",
       "        [  823120.56  ,   785604.    ,  -616536.06  ,   611204.2   ,\n",
       "           253058.34  ,   752869.56  ,   412766.06  ,   571364.44  ,\n",
       "          -554286.6   ,   576296.6   ],\n",
       "        [ -145056.38  , -1769891.    ,  -430492.16  ,  -554777.06  ,\n",
       "          1000131.44  ,   856314.4   ,  -438527.5   ,   295751.16  ,\n",
       "           278508.2   , -1192714.1   ],\n",
       "        [-1122441.    ,  1322680.8   ,   958845.75  ,  -269918.9   ,\n",
       "         -1103538.    ,  -379737.84  , -1341615.4   , -1116159.2   ,\n",
       "            80517.47  ,   475603.72  ],\n",
       "        [ -676845.75  , -1496649.9   ,  2222733.2   ,  -845210.06  ,\n",
       "           881863.94  ,  -658305.9   ,  -471596.06  ,  -879887.3   ,\n",
       "          -734850.2   ,   940262.56  ],\n",
       "        [  281895.66  ,   209351.95  ,  -863430.    ,  -277048.34  ,\n",
       "           915895.3   ,  -753879.56  ,  -464764.62  ,  -732205.    ,\n",
       "           866552.8   ,  -314932.4   ],\n",
       "        [-1438185.1   ,  -357971.5   , -2268282.5   ,   207244.3   ,\n",
       "           421665.62  ,  1200964.8   ,  -999650.6   ,    10223.808 ,\n",
       "           231360.62  ,   530731.1   ],\n",
       "        [-1895573.4   ,   549428.2   ,   688602.7   ,  1735207.9   ,\n",
       "          -219983.14  ,   808414.    , -1406176.    , -1114710.8   ,\n",
       "           464000.12  ,    47870.508 ],\n",
       "        [ -697715.25  ,  -430746.25  ,   474820.5   ,  -700843.2   ,\n",
       "           681125.7   ,   385896.3   ,  -309084.5   ,  -698079.    ,\n",
       "          -194028.22  , -2040183.    ],\n",
       "        [ -230899.77  ,  -339818.25  ,   519423.94  ,   863674.7   ,\n",
       "          -981233.44  , -1110257.9   ,   398810.5   ,  -557977.44  ,\n",
       "          1114595.8   ,   384039.72  ],\n",
       "        [-1287590.    , -1733015.2   ,  -450373.28  ,  1345155.9   ,\n",
       "           625507.56  ,  -729149.06  ,  -794839.    ,   707602.5   ,\n",
       "          -452850.97  ,   130032.14  ],\n",
       "        [-1047946.94  ,  -161385.86  ,  -471524.8   ,  -830635.1   ,\n",
       "           769347.4   , -1275178.8   ,  -450196.56  , -1524522.6   ,\n",
       "          -338543.06  ,  -546132.5   ],\n",
       "        [  267499.53  ,   378601.25  ,   857727.25  ,   620274.25  ,\n",
       "           796786.6   ,   235099.38  ,  1560744.4   ,  1047049.25  ,\n",
       "           -59325.96  ,   345182.97  ],\n",
       "        [  816017.3   ,   345254.22  ,   -62270.605 ,  -797472.94  ,\n",
       "          -196635.4   ,   438125.28  ,   854619.3   ,   626623.7   ,\n",
       "          -317160.66  ,   758067.6   ],\n",
       "        [  183253.56  ,  -565379.94  ,   531420.7   ,  -460101.62  ,\n",
       "           654456.25  ,  -664399.1   ,   853052.44  ,   565968.56  ,\n",
       "          -523437.1   ,  -254507.03  ],\n",
       "        [ 1255899.8   ,   174466.36  ,   378918.12  ,  1268314.2   ,\n",
       "          -132150.38  ,   -15794.376 , -1850911.9   ,   -72700.93  ,\n",
       "          -572119.5   , -1317137.1   ],\n",
       "        [  702730.2   ,   642228.56  ,  -539413.44  ,  -218263.98  ,\n",
       "          -100964.99  ,  1380319.6   ,  -990199.94  ,  -681065.3   ,\n",
       "         -1285442.    ,   892103.25  ],\n",
       "        [ -273769.9   ,    46887.242 ,  -626160.2   , -1147151.2   ,\n",
       "           297486.9   ,   956299.5   ,   657250.94  ,  1031928.4   ,\n",
       "          -111695.76  ,  -655404.06  ],\n",
       "        [-1630911.2   ,   248207.6   ,   157791.17  ,  1339766.9   ,\n",
       "           611419.2   ,   637307.4   , -1189703.    ,   -43599.23  ,\n",
       "          -112359.    , -1452264.4   ],\n",
       "        [ -816305.2   ,   512908.75  ,  -181614.08  ,   433690.97  ,\n",
       "           221655.62  ,   -87280.09  ,  -538705.1   ,   167563.36  ,\n",
       "             3870.4766,  -807046.8   ],\n",
       "        [ -883426.75  ,   658266.44  ,   779124.4   ,   352169.56  ,\n",
       "           431724.12  ,  -797669.3   ,   884208.94  ,  -320352.28  ,\n",
       "           556321.44  ,  1357893.9   ],\n",
       "        [   -7857.499 ,  -403522.44  ,  -360904.97  ,   998441.8   ,\n",
       "           516686.38  , -1265437.1   ,  -742431.6   ,   937747.4   ,\n",
       "          1189844.9   , -1267578.2   ],\n",
       "        [ -771395.3   ,   888789.9   ,   507350.38  ,  -458797.3   ,\n",
       "          1339138.4   ,  -289558.1   ,  1459296.6   ,  -666392.2   ,\n",
       "          -582331.    ,   966024.3   ],\n",
       "        [ -886494.5   ,   436927.4   , -1321778.9   ,   293827.5   ,\n",
       "           755038.1   ,   710098.1   ,  -426706.44  ,  -262401.97  ,\n",
       "            47665.99  ,  -732355.8   ],\n",
       "        [  109840.02  ,   419012.53  ,  -148680.69  ,  -597055.56  ,\n",
       "           764377.75  ,  -716163.2   ,   100039.62  ,  1143997.9   ,\n",
       "          -838785.3   ,  -262928.3   ],\n",
       "        [ 1652013.8   ,   247584.02  ,  -504600.78  ,   -16213.009 ,\n",
       "          -334358.34  ,  2242333.5   ,  2054452.    ,  -440909.5   ,\n",
       "         -1959275.8   ,  1129276.    ],\n",
       "        [  505745.88  ,   762417.56  , -1147818.4   ,   412785.97  ,\n",
       "           -44320.363 ,   153082.22  , -1455464.2   ,  -442501.38  ,\n",
       "          -714851.8   ,   -85064.26  ],\n",
       "        [-1916991.8   , -1003929.25  ,   411729.22  , -1690219.8   ,\n",
       "           399378.34  ,   852684.6   , -1158981.    ,  -764765.1   ,\n",
       "           605561.56  ,  -563752.4   ]], dtype=float32),\n",
       " array([ 1735230.1 ,  -565231.44,  -606586.94,  -585480.  ,  2238889.2 ,\n",
       "        -2030346.4 , -1622896.8 , -2542892.2 ,   677200.3 ,  1308973.8 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[\"model_1\"].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "init_model.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 625us/step - loss: 2.3020 - accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.30204439163208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model.evaluate(X_test, y_test)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
