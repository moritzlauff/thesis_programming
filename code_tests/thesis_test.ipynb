{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import mnist_prep\n",
    "from model_functions import *\n",
    "from plotting_functions import *\n",
    "import no_gpu\n",
    "import reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = mnist_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train_small = X_train[:1000, :]\n",
    "X_val_small = X_val[:500, :]\n",
    "y_train_small = y_train[:1000]\n",
    "y_val_small = y_val[:500]\n",
    "\n",
    "n_cols = X_train_small.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.1568 - accuracy: 0.2940 - val_loss: 1.7982 - val_accuracy: 0.5340\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4155 - accuracy: 0.6480 - val_loss: 1.1691 - val_accuracy: 0.6720\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8097 - accuracy: 0.7850 - val_loss: 0.7404 - val_accuracy: 0.7840\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8910 - val_loss: 0.5924 - val_accuracy: 0.8240\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9490 - val_loss: 0.4954 - val_accuracy: 0.8440\n",
      "Overall calculation took 0.7360885143280029 seconds.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 127,658\n",
      "Trainable params: 127,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn_model_structure(layers = 5,\n",
    "                           neurons = [128, 128, 64, 32, 10],\n",
    "                           n_cols = X_train_small.shape[1])\n",
    "model = nn_model_compile(model)\n",
    "start_time = time.time()\n",
    "model = nn_model_fit(model,\n",
    "                     X_train = X_train_small,\n",
    "                     y_train = y_train_small,\n",
    "                     X_val = X_val_small,\n",
    "                     y_val = y_val_small,\n",
    "                     batch_size = 100,\n",
    "                     epochs = 5)\n",
    "end_time = time.time()\n",
    "print(\"Overall calculation took {} seconds.\".format(end_time - start_time))\n",
    "model.summary()\n",
    "nn_plot_acc(model)\n",
    "nn_save(model, \"../models/model_test_small.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 128) dtype=float32, numpy=\n",
       " array([[ 0.01743369, -0.0448595 ,  0.01700593, ..., -0.08100501,\n",
       "         -0.039437  , -0.01738876],\n",
       "        [-0.05974199, -0.0050594 ,  0.01806217, ..., -0.04069512,\n",
       "          0.04969868,  0.03359859],\n",
       "        [-0.04995032,  0.06309575, -0.00772937, ..., -0.05693629,\n",
       "          0.03480571, -0.04803716],\n",
       "        ...,\n",
       "        [ 0.06142421, -0.00991699,  0.04870585, ..., -0.05468635,\n",
       "          0.06899758,  0.00282843],\n",
       "        [-0.04510133,  0.04147224, -0.05598278, ...,  0.01716213,\n",
       "         -0.0297642 ,  0.09859083],\n",
       "        [-0.09908427,  0.00187593,  0.08837842, ...,  0.04840584,\n",
       "          0.01531912,  0.0097312 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.04327018, -0.07381417,  0.03087016,  0.02236053,  0.05741594,\n",
       "         0.03686374, -0.05570047, -0.0665051 , -0.09683846,  0.03811099,\n",
       "         0.07938883,  0.08393009,  0.02294064,  0.13181856,  0.05242262,\n",
       "         0.02187915, -0.0436435 , -0.12017711, -0.02128334,  0.03553337,\n",
       "        -0.0911384 , -0.03909251, -0.13030748, -0.05337098, -0.05235633,\n",
       "         0.10695072,  0.14173238,  0.00402107, -0.05241122, -0.11447047,\n",
       "        -0.01809708, -0.03537253, -0.1739625 ,  0.02134349,  0.15191346,\n",
       "         0.14329249,  0.03818284,  0.06775615, -0.08983541,  0.04202675,\n",
       "        -0.03450064,  0.07800161,  0.00508885, -0.0147282 ,  0.01784457,\n",
       "        -0.02617013,  0.10562268, -0.12363829,  0.10856588, -0.02022347,\n",
       "        -0.02508698,  0.15968347,  0.13872388, -0.09556812, -0.00168106,\n",
       "         0.05418412,  0.11359297, -0.04186633, -0.04000417, -0.00739445,\n",
       "         0.08543832,  0.01068621,  0.09000213, -0.05904119, -0.04563366,\n",
       "         0.04666693, -0.01818488, -0.01689103,  0.06498472,  0.10340773,\n",
       "         0.07476798,  0.17572816,  0.05961983,  0.14682806,  0.00808831,\n",
       "        -0.06485845,  0.05775486,  0.010726  , -0.01939983,  0.0636711 ,\n",
       "         0.17601398, -0.10545054,  0.00535826, -0.09190309,  0.0005494 ,\n",
       "        -0.01296744,  0.07364033,  0.05118484,  0.01660477, -0.0563148 ,\n",
       "        -0.12710151,  0.00401108,  0.1330709 ,  0.16139537,  0.11767759,\n",
       "        -0.0288452 , -0.08373822, -0.05902249,  0.02106162, -0.00323038,\n",
       "         0.04487242,  0.03129515, -0.11435542, -0.01646486, -0.01241108,\n",
       "         0.1135411 ,  0.12704238,  0.00516982,  0.04891621,  0.08354839,\n",
       "         0.0914337 ,  0.050294  , -0.05746085,  0.06583142,  0.14802825,\n",
       "         0.00617989, -0.11214785,  0.10039781,  0.07984505,  0.06680597,\n",
       "        -0.15708777, -0.05905578,  0.00197384,  0.00407194, -0.05430405,\n",
       "         0.05797872,  0.05597561, -0.16371468], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
       " array([[-0.04069831, -0.05826744, -0.15703239, ..., -0.09304805,\n",
       "          0.10855281,  0.01347789],\n",
       "        [-0.05459177, -0.04238902,  0.08384012, ..., -0.00274851,\n",
       "          0.07175799,  0.04016467],\n",
       "        [ 0.09990751, -0.01254692, -0.05407349, ..., -0.1295839 ,\n",
       "         -0.06255186,  0.18670903],\n",
       "        ...,\n",
       "        [-0.00492845,  0.20625271, -0.08680175, ...,  0.17511767,\n",
       "         -0.18371178,  0.03111107],\n",
       "        [-0.0091341 , -0.13605481, -0.1485603 , ..., -0.16052541,\n",
       "         -0.07436312,  0.20648299],\n",
       "        [-0.02283663,  0.10861998, -0.02621484, ...,  0.00579365,\n",
       "         -0.00170853,  0.14473651]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.07759679, -0.0312438 ,  0.0306848 , -0.09805813,  0.17818445,\n",
       "         0.12927254,  0.02007904, -0.03485857, -0.13368836, -0.09024267,\n",
       "         0.08005079,  0.08218154,  0.06619187, -0.06171843,  0.01891852,\n",
       "         0.0056756 ,  0.03758317, -0.02614867, -0.04223014, -0.02196964,\n",
       "         0.06889293, -0.06180291,  0.09367862,  0.15930893,  0.04886315,\n",
       "         0.15971443, -0.03242179, -0.01755979, -0.06770247,  0.06008764,\n",
       "        -0.06652515,  0.1369896 ,  0.02915315,  0.09243153,  0.09076985,\n",
       "         0.15669806,  0.08830021,  0.01271273,  0.10950909,  0.01190754,\n",
       "         0.10379919, -0.13793854,  0.00542413, -0.04743098,  0.05941083,\n",
       "         0.15191786, -0.00636312,  0.15812999,  0.02884976, -0.11592016,\n",
       "         0.05089141,  0.11169519, -0.1119395 , -0.10676566, -0.13321432,\n",
       "        -0.01916115,  0.03296002, -0.00824663,  0.01504586, -0.13314101,\n",
       "         0.01935694,  0.01099178,  0.06395628,  0.06694518, -0.04475188,\n",
       "         0.0988598 , -0.1364427 ,  0.08357047, -0.01395689, -0.01602619,\n",
       "         0.03819034,  0.00222377, -0.02063309, -0.01682515,  0.028184  ,\n",
       "        -0.15148762, -0.05933097, -0.1409049 , -0.06604766,  0.13202262,\n",
       "         0.11309382, -0.11916798, -0.00476628,  0.12158865,  0.03831815,\n",
       "        -0.18614592,  0.10189454, -0.06776603,  0.1655774 ,  0.01895723,\n",
       "        -0.09725928, -0.15970553, -0.06819125, -0.08229217,  0.04525027,\n",
       "        -0.16310489, -0.15449427,  0.0501531 ,  0.0266764 , -0.01512172,\n",
       "        -0.00764576,  0.2102602 ,  0.16916642,  0.12905838, -0.00132116,\n",
       "         0.06990791,  0.01905858, -0.07905954, -0.01051007, -0.00681491,\n",
       "         0.10765459,  0.08758812, -0.04951473,  0.05499668,  0.02922528,\n",
       "        -0.01953277, -0.0914811 ,  0.10364472, -0.11771661,  0.04128715,\n",
       "         0.02453898, -0.11208474,  0.07619918,  0.12038936,  0.00219269,\n",
       "         0.16965489,  0.03021845,  0.06082185], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(128, 64) dtype=float32, numpy=\n",
       " array([[ 0.01894527, -0.07425016, -0.07955975, ...,  0.09159794,\n",
       "          0.06249255,  0.10218284],\n",
       "        [ 0.09947377, -0.07687735,  0.00344833, ...,  0.19825351,\n",
       "          0.18372543,  0.21428682],\n",
       "        [-0.02668845,  0.05525308, -0.16485927, ...,  0.01757524,\n",
       "          0.08137172,  0.03863652],\n",
       "        ...,\n",
       "        [-0.08357276, -0.03918286,  0.04077024, ...,  0.0379348 ,\n",
       "          0.04419068,  0.13178518],\n",
       "        [-0.10282669,  0.11699543, -0.04877362, ..., -0.03025568,\n",
       "         -0.02949811, -0.20977013],\n",
       "        [-0.01113071,  0.04364127, -0.06157317, ..., -0.0005098 ,\n",
       "         -0.01540132, -0.03710819]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.02773258,  0.05797679,  0.1820031 ,  0.13891134, -0.17827867,\n",
       "         0.12692247,  0.01348429, -0.0790986 ,  0.09622042, -0.00563049,\n",
       "         0.04080888,  0.1954565 , -0.05738338, -0.01849997, -0.03245921,\n",
       "        -0.02189456,  0.07258543,  0.09935026,  0.00079114, -0.02981433,\n",
       "         0.06929859, -0.01001375,  0.03558384,  0.0060396 , -0.09730136,\n",
       "        -0.06334068,  0.01239703, -0.16610387,  0.14965928,  0.26370263,\n",
       "         0.09608041,  0.01796602,  0.15830575,  0.11258607,  0.18129702,\n",
       "         0.13978054,  0.054971  ,  0.14414626, -0.03940261,  0.19041924,\n",
       "         0.21109082,  0.08635418,  0.02214587,  0.01437186,  0.08159892,\n",
       "        -0.23532617, -0.06426726, -0.0816457 ,  0.13542643, -0.23190361,\n",
       "        -0.0869854 , -0.16960673, -0.01254823,  0.07593887,  0.16776407,\n",
       "         0.10011992,  0.01467081, -0.00916372, -0.10472014,  0.07035168,\n",
       "         0.1103182 ,  0.14976698,  0.07068202,  0.0483396 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 32) dtype=float32, numpy=\n",
       " array([[-0.01637782, -0.18865348,  0.09807748, ...,  0.04848767,\n",
       "         -0.07862548,  0.06766471],\n",
       "        [-0.18648717, -0.30618426, -0.19078232, ...,  0.25299668,\n",
       "         -0.05375993, -0.02751007],\n",
       "        [ 0.1440039 , -0.07032172,  0.07578315, ..., -0.03026351,\n",
       "          0.05226006,  0.00739245],\n",
       "        ...,\n",
       "        [-0.01119083,  0.09492674,  0.0387049 , ..., -0.21100262,\n",
       "          0.22169553,  0.138075  ],\n",
       "        [ 0.13350436,  0.01400113,  0.06266444, ...,  0.31609684,\n",
       "         -0.290876  ,  0.20679441],\n",
       "        [ 0.25370187,  0.10270812,  0.08846495, ..., -0.10429973,\n",
       "         -0.07816409,  0.35430065]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([ 2.41208866e-01, -3.09109569e-01, -2.77246952e-01, -1.21745124e-01,\n",
       "        -2.69510776e-01, -6.07358217e-02, -1.67884663e-01, -3.86445731e-01,\n",
       "         1.86055586e-01, -1.46113008e-01,  1.08465046e-01, -2.82506458e-02,\n",
       "        -6.08432218e-02, -4.63404618e-02,  1.92167237e-01,  2.70753384e-01,\n",
       "        -3.63654077e-01,  6.24095119e-05,  1.65524453e-01, -4.86762859e-02,\n",
       "        -1.08853661e-01,  3.30173254e-01,  3.53712171e-01,  1.40472963e-01,\n",
       "        -1.41738623e-01, -1.32539630e-01,  1.77510113e-01,  5.94849922e-02,\n",
       "        -1.00811332e-01,  2.57282685e-02,  9.03707445e-02,  2.25909188e-01],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_4/kernel:0' shape=(32, 10) dtype=float32, numpy=\n",
       " array([[-4.33582574e-01,  2.26597130e-01, -6.99404702e-02,\n",
       "         -1.70646012e-01,  4.49947953e-01, -3.33830059e-01,\n",
       "         -7.64201358e-02, -2.31736943e-01, -5.87623790e-02,\n",
       "         -1.08366273e-01],\n",
       "        [ 1.24753475e-01, -3.79317462e-01, -4.70657915e-01,\n",
       "         -1.86248049e-01, -2.83604890e-01,  1.65797248e-02,\n",
       "         -1.90044835e-01,  1.05268334e-03, -1.96531549e-01,\n",
       "         -2.95485586e-01],\n",
       "        [-9.96717513e-02,  1.58358589e-01, -4.80849203e-03,\n",
       "         -1.80857852e-01, -3.31243485e-01,  3.37870628e-01,\n",
       "          3.11209470e-01, -1.61760151e-01, -3.27636093e-01,\n",
       "          2.75217235e-01],\n",
       "        [ 2.56105632e-01, -1.71755537e-01,  2.51689367e-02,\n",
       "         -5.35665527e-02,  2.48780325e-01,  4.05869773e-03,\n",
       "          2.79668421e-01,  1.86506271e-01, -3.64593714e-02,\n",
       "         -2.90627748e-01],\n",
       "        [ 2.08230376e-01, -7.91864023e-02, -1.61570504e-01,\n",
       "         -9.14812088e-02, -9.54118669e-02, -2.72391528e-01,\n",
       "          6.20306609e-03,  7.86487237e-02, -4.67378423e-02,\n",
       "          9.47310776e-02],\n",
       "        [-2.02950656e-01,  1.35852054e-01,  4.14360106e-01,\n",
       "         -1.66333720e-01, -2.50582188e-01, -2.12935224e-01,\n",
       "         -1.37740031e-01, -2.61050940e-01, -2.55948573e-01,\n",
       "         -4.53768522e-02],\n",
       "        [ 3.74068111e-01,  9.77853388e-02, -2.98107982e-01,\n",
       "          3.26684177e-01,  2.41779730e-01, -2.06945106e-01,\n",
       "          8.34232271e-02,  1.44173488e-01, -9.10312384e-02,\n",
       "         -3.80288623e-02],\n",
       "        [ 1.97329268e-01, -4.58448716e-02, -3.17525595e-01,\n",
       "          6.41257018e-02,  2.39740282e-01,  4.15339842e-02,\n",
       "          7.93288946e-02, -1.10474117e-01, -2.48339757e-01,\n",
       "          2.05169126e-01],\n",
       "        [ 5.06172441e-02,  4.24827427e-01, -1.57435700e-01,\n",
       "          3.85765761e-01, -1.73651233e-01, -2.27579087e-01,\n",
       "          1.62893936e-01, -2.47739255e-01, -3.91345352e-01,\n",
       "          8.72989818e-02],\n",
       "        [ 3.41899186e-01,  1.26651093e-01, -1.18073024e-01,\n",
       "          9.30789709e-02,  3.46920639e-01,  3.40811819e-01,\n",
       "          1.77113324e-01,  1.29882812e-01, -4.69424903e-01,\n",
       "          4.42392439e-01],\n",
       "        [ 6.77344948e-02, -4.06342626e-01,  1.29615352e-01,\n",
       "         -9.38809291e-02,  2.48954996e-01, -4.65178609e-01,\n",
       "         -3.44651669e-01,  1.37015551e-01, -1.17000295e-02,\n",
       "          1.57963112e-01],\n",
       "        [-1.23364404e-02,  2.23561078e-01, -3.42797577e-01,\n",
       "         -1.11231312e-01,  2.30235141e-02, -1.62895590e-01,\n",
       "         -5.13484888e-02, -4.04094219e-01, -3.17183107e-01,\n",
       "         -2.11864442e-01],\n",
       "        [ 1.03852466e-01, -1.27520218e-01,  6.39911592e-02,\n",
       "          2.61835754e-01, -2.36869469e-01,  3.41944307e-01,\n",
       "          2.87768900e-01, -4.48141955e-02, -7.98451453e-02,\n",
       "         -1.96203530e-01],\n",
       "        [-1.76358625e-01, -4.40168053e-01,  1.24743298e-01,\n",
       "          2.28649825e-01, -7.93091804e-02,  3.11527908e-01,\n",
       "         -1.44798055e-01, -2.86413506e-02,  3.52342337e-01,\n",
       "         -2.00995564e-01],\n",
       "        [ 2.17830449e-01,  1.62769064e-01, -1.09513581e-01,\n",
       "         -2.95879602e-01, -8.35249871e-02,  1.03874587e-01,\n",
       "         -1.47283673e-01,  3.75481606e-01,  1.74181685e-02,\n",
       "          2.59821862e-01],\n",
       "        [ 2.30185866e-01, -3.32223088e-01,  8.88324976e-02,\n",
       "          3.08818638e-01,  2.29394417e-02, -4.11258973e-02,\n",
       "          7.39221089e-03, -8.85947887e-03,  4.80982929e-01,\n",
       "         -3.43519509e-01],\n",
       "        [ 1.70801029e-01, -3.79242226e-02, -2.54848182e-01,\n",
       "          2.62758702e-01, -2.38549352e-01, -5.28527260e-01,\n",
       "         -5.17832935e-02, -3.01911235e-01, -4.09378856e-01,\n",
       "          4.02641948e-04],\n",
       "        [ 2.42269672e-02, -1.04195951e-02,  4.73801434e-01,\n",
       "          3.87409478e-01,  4.31632042e-01,  1.68041557e-01,\n",
       "         -9.12118331e-02,  1.63337830e-02, -2.84255333e-02,\n",
       "         -4.89727817e-02],\n",
       "        [ 2.21480444e-01,  1.40134767e-01, -2.00217783e-01,\n",
       "          1.98412806e-01, -4.76063788e-02,  1.86591208e-01,\n",
       "         -1.78967699e-01,  7.87411854e-02, -3.51955742e-01,\n",
       "          9.76131111e-02],\n",
       "        [ 1.02075368e-01,  4.08098660e-02, -2.68667847e-01,\n",
       "         -3.68486233e-02, -3.51780087e-01, -2.50015229e-01,\n",
       "         -3.84892166e-01,  7.28398860e-02, -7.77053684e-02,\n",
       "         -9.55051407e-02],\n",
       "        [ 3.68851751e-01, -8.05135369e-02, -3.26147944e-01,\n",
       "          6.47863820e-02, -2.10202858e-01, -2.69368947e-01,\n",
       "          5.78240938e-02,  9.47378650e-02, -3.15383077e-02,\n",
       "          9.53549240e-03],\n",
       "        [ 9.17244852e-02,  2.26242170e-01,  2.32626066e-01,\n",
       "         -1.81227922e-01,  4.07763049e-02,  2.16293968e-02,\n",
       "          3.41043413e-01, -2.33351886e-01,  2.90004879e-01,\n",
       "          4.67551738e-01],\n",
       "        [-8.13337043e-02,  9.55095366e-02, -4.50681120e-01,\n",
       "          2.56307274e-01, -3.17178033e-02,  3.68070871e-01,\n",
       "          2.36254245e-01, -2.00145960e-01,  2.25943583e-03,\n",
       "          1.80455193e-01],\n",
       "        [-3.06367129e-01, -1.77429155e-01,  2.24848300e-01,\n",
       "         -2.67355647e-02, -1.81314826e-01, -2.43945364e-02,\n",
       "          1.14930592e-01, -5.81485182e-02, -2.71781892e-01,\n",
       "          1.81707874e-01],\n",
       "        [-3.80314022e-01, -5.06178439e-01, -3.53255987e-01,\n",
       "         -2.67928720e-01, -3.08190972e-01, -1.18305728e-01,\n",
       "          8.33813623e-02, -1.56410813e-01,  1.09017147e-02,\n",
       "          3.96740943e-01],\n",
       "        [-5.00810519e-02,  5.48155513e-03,  2.67093897e-01,\n",
       "         -9.99763906e-02, -1.29389793e-01, -4.07423228e-01,\n",
       "         -1.14164837e-02,  3.10791343e-01,  3.82473543e-02,\n",
       "         -2.21920788e-01],\n",
       "        [ 1.26264423e-01,  2.73154050e-01, -1.10121094e-01,\n",
       "         -2.75261104e-01,  1.24773279e-01, -3.31026107e-01,\n",
       "         -2.02004120e-01, -3.04571018e-02,  3.27277094e-01,\n",
       "         -1.82038143e-01],\n",
       "        [-3.18551749e-01, -2.27230296e-01, -2.97404468e-01,\n",
       "         -3.31734419e-01,  1.43133178e-01,  2.02984408e-01,\n",
       "          9.23728049e-02,  4.08270568e-01, -8.95861536e-02,\n",
       "         -7.68872947e-02],\n",
       "        [-2.76617974e-01,  5.61129153e-02, -1.83826640e-01,\n",
       "          5.59081845e-02, -3.12386423e-01, -1.60579607e-01,\n",
       "          2.09403813e-01, -2.47259587e-01, -2.22073689e-01,\n",
       "         -6.17079772e-02],\n",
       "        [ 4.15610373e-01,  3.11790794e-01,  3.27767357e-02,\n",
       "          7.50745982e-02, -1.85578018e-01, -2.44626507e-01,\n",
       "         -2.26199329e-01,  2.54269183e-01,  1.36683837e-01,\n",
       "          1.95775747e-01],\n",
       "        [-2.95735866e-01, -8.25980976e-02,  3.25061560e-01,\n",
       "          3.96928877e-01, -4.79571551e-01,  6.69260994e-02,\n",
       "         -1.30223483e-01,  3.83039773e-01, -1.71872228e-02,\n",
       "         -3.45719367e-01],\n",
       "        [ 2.99279671e-02, -1.49155989e-01,  2.95762181e-01,\n",
       "         -5.12153685e-01,  1.90594390e-01, -9.53023881e-03,\n",
       "         -1.57087445e-01, -4.23935205e-01,  8.12434312e-03,\n",
       "         -9.18528736e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.55713755,  0.46454746,  0.2824863 ,  0.36116007,  0.25320807,\n",
       "        -0.04130504, -0.03157982,  0.0028604 , -0.18785632, -0.13406429],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.1567821502685547,\n",
       "  1.415523886680603,\n",
       "  0.8096575140953064,\n",
       "  0.4288073778152466,\n",
       "  0.22122031450271606],\n",
       " 'accuracy': [0.2939999997615814,\n",
       "  0.6480000019073486,\n",
       "  0.7850000262260437,\n",
       "  0.890999972820282,\n",
       "  0.9490000009536743],\n",
       " 'val_loss': [1.7981798648834229,\n",
       "  1.1691062450408936,\n",
       "  0.7404221296310425,\n",
       "  0.5924199223518372,\n",
       "  0.49540990591049194],\n",
       " 'val_accuracy': [0.5339999794960022,\n",
       "  0.671999990940094,\n",
       "  0.7839999794960022,\n",
       "  0.8240000009536743,\n",
       "  0.843999981880188]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import Optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Optimizer(object):\n",
    "  \"\"\"Abstract optimizer base class.\n",
    "\n",
    "  Note: this is the parent class of all optimizers, not an actual optimizer\n",
    "  that can be used for training models.\n",
    "\n",
    "  All Keras optimizers support the following keyword arguments:\n",
    "\n",
    "      clipnorm: float >= 0. Gradients will be clipped\n",
    "          when their L2 norm exceeds this value.\n",
    "      clipvalue: float >= 0. Gradients will be clipped\n",
    "          when their absolute value exceeds this value.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    allowed_kwargs = {'clipnorm', 'clipvalue'}\n",
    "    for k in kwargs:\n",
    "      if k not in allowed_kwargs:\n",
    "        raise TypeError('Unexpected keyword argument '\n",
    "                        'passed to optimizer: ' + str(k))\n",
    "      # checks that clipnorm >= 0 and clipvalue >= 0\n",
    "      if kwargs[k] < 0:\n",
    "        raise ValueError('Expected {} >= 0, received: {}'.format(k, kwargs[k]))\n",
    "    self.__dict__.update(kwargs)\n",
    "    self.updates = [] # opt.updates initialisiert\n",
    "    self.weights = [] # opt.weights initialisiert\n",
    "\n",
    "  # Set this to False, indicating `apply_gradients` does not take the\n",
    "  # `experimental_aggregate_gradients` argument.\n",
    "  _HAS_AGGREGATE_GRAD = False\n",
    "\n",
    "  def _create_all_weights(self, params):\n",
    "    \"\"\"Creates and sets all optimizer weights.\n",
    "\n",
    "    Args:\n",
    "      params: list or tuple of `Variable` objects that will be minimized\n",
    "        using this optimizer.\n",
    "\n",
    "    Returns:\n",
    "      Specific weight values that are used in `get_updates`\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def get_updates(self, loss, params):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def get_gradients(self, loss, params):\n",
    "    \"\"\"Returns gradients of `loss` with respect to `params`.\n",
    "\n",
    "    Arguments:\n",
    "        loss: Loss tensor.\n",
    "        params: List of variables.\n",
    "\n",
    "    Returns:\n",
    "        List of gradient tensors.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: In case any gradient cannot be computed (e.g. if gradient\n",
    "          function not implemented).\n",
    "    \"\"\"\n",
    "    grads = K.gradients(loss, params)\n",
    "    if any(g is None for g in grads):\n",
    "      raise ValueError('An operation has `None` for gradient. '\n",
    "                       'Please make sure that all of your ops have a '\n",
    "                       'gradient defined (i.e. are differentiable). '\n",
    "                       'Common ops without gradient: '\n",
    "                       'K.argmax, K.round, K.eval.')\n",
    "    if hasattr(self, 'clipnorm'):\n",
    "      grads = [clip_ops.clip_by_norm(g, self.clipnorm) for g in grads]\n",
    "    if hasattr(self, 'clipvalue'):\n",
    "      grads = [\n",
    "          clip_ops.clip_by_value(g, -self.clipvalue, self.clipvalue)\n",
    "          for g in grads\n",
    "      ]\n",
    "    return grads\n",
    "\n",
    "  def set_weights(self, weights):\n",
    "    \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n",
    "\n",
    "    Should only be called after computing the gradients\n",
    "    (otherwise the optimizer has no weights).\n",
    "\n",
    "    Arguments:\n",
    "        weights: a list of Numpy arrays. The number of arrays and their shape\n",
    "          must match number of the dimensions of the weights of the optimizer\n",
    "          (i.e. it should match the output of `get_weights`).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: in case of incompatible weight shapes.\n",
    "    \"\"\"\n",
    "    params = self.weights\n",
    "    if len(params) != len(weights):\n",
    "      raise ValueError('Length of the specified weight list (' +\n",
    "                       str(len(weights)) +\n",
    "                       ') does not match the number of weights '\n",
    "                       'of the optimizer (' + str(len(params)) + ')')\n",
    "    weight_value_tuples = []\n",
    "    param_values = K.batch_get_value(params)\n",
    "    for pv, p, w in zip(param_values, params, weights):\n",
    "      if pv.shape != w.shape:\n",
    "        raise ValueError('Optimizer weight shape ' + str(pv.shape) +\n",
    "                         ' not compatible with '\n",
    "                         'provided weight shape ' + str(w.shape))\n",
    "      weight_value_tuples.append((p, w))\n",
    "    K.batch_set_value(weight_value_tuples)\n",
    "\n",
    "  def get_weights(self):\n",
    "    \"\"\"Returns the current value of the weights of the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        A list of numpy arrays.\n",
    "    \"\"\"\n",
    "    return K.batch_get_value(self.weights)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {}\n",
    "    if hasattr(self, 'clipnorm'):\n",
    "      config['clipnorm'] = self.clipnorm\n",
    "    if hasattr(self, 'clipvalue'):\n",
    "      config['clipvalue'] = self.clipvalue\n",
    "    return config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_test(Optimizer):\n",
    "  \"\"\"Stochastic gradient descent optimizer.\n",
    "\n",
    "  Includes support for momentum,\n",
    "  learning rate decay, and Nesterov momentum.\n",
    "\n",
    "  Arguments:\n",
    "      lr: float >= 0. Learning rate.\n",
    "      momentum: float >= 0. Parameter that accelerates SGD in the relevant\n",
    "        direction and dampens oscillations.\n",
    "      decay: float >= 0. Learning rate decay over each update.\n",
    "      nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, **kwargs):\n",
    "    super(SGD_test, self).__init__(**kwargs)\n",
    "    with K.name_scope(self.__class__.__name__):\n",
    "      self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "      self.lr = K.variable(lr, name='lr')\n",
    "      self.momentum = K.variable(momentum, name='momentum')\n",
    "      self.decay = K.variable(decay, name='decay')\n",
    "    self.initial_decay = decay\n",
    "    self.nesterov = nesterov\n",
    "\n",
    "  def _create_all_weights(self, params):\n",
    "    shapes = [K.int_shape(p) for p in params]\n",
    "    moments = [K.zeros(shape) for shape in shapes]\n",
    "    self.weights = [self.iterations] + moments\n",
    "    return moments\n",
    "\n",
    "  def get_updates(self, loss, params):\n",
    "    grads = self.get_gradients(loss, params)\n",
    "    self.updates = [state_ops.assign_add(self.iterations, 1)]\n",
    "\n",
    "    lr = self.lr\n",
    "    if self.initial_decay > 0:\n",
    "      lr = lr * (  # pylint: disable=g-no-augmented-assignment\n",
    "          1. /\n",
    "          (1. +\n",
    "           self.decay * math_ops.cast(self.iterations, K.dtype(self.decay))))\n",
    "    # momentum\n",
    "    moments = self._create_all_weights(params)\n",
    "    for p, g, m in zip(params, grads, moments):\n",
    "      v = self.momentum * m - lr * g  # velocity\n",
    "      self.updates.append(state_ops.assign(m, v))\n",
    "\n",
    "      if self.nesterov:\n",
    "        new_p = p + self.momentum * v - lr * g\n",
    "      else:\n",
    "        new_p = p + v\n",
    "\n",
    "      # Apply constraints.\n",
    "      if getattr(p, 'constraint', None) is not None:\n",
    "        new_p = p.constraint(new_p)\n",
    "\n",
    "      self.updates.append(state_ops.assign(p, new_p))\n",
    "    return self.updates\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\n",
    "        'lr': float(K.get_value(self.lr)),\n",
    "        'momentum': float(K.get_value(self.momentum)),\n",
    "        'decay': float(K.get_value(self.decay)),\n",
    "        'nesterov': self.nesterov\n",
    "    }\n",
    "    base_config = super(SGD, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-91daa078dbd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSGD_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-705f6d3b2c16>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lr, momentum, decay, nesterov, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "SGD_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(SGD_test(), Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_test = SGD_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model_structure(layers = 5,\n",
    "                           neurons = [128, 128, 64, 32, 10],\n",
    "                           n_cols = X_train_small.shape[1])\n",
    "model = nn_model_compile(model, optimizer = sgd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model_fit(model,\n",
    "                     X_train = X_train_small,\n",
    "                     y_train = y_train_small,\n",
    "                     X_val = X_val_small,\n",
    "                     y_val = y_val_small,\n",
    "                     batch_size = 100,\n",
    "                     epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "if K.backend() == 'tensorflow': \n",
    "    import tensorflow as tf\n",
    "\n",
    "class COCOB(Optimizer):\n",
    "    \"\"\"Coin Betting Optimizer from the paper:\n",
    "        https://arxiv.org/pdf/1705.07795.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=100, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize COCOB Optimizer\n",
    "        Args:\n",
    "            alpha: Refer to paper.\n",
    "        \"\"\"\n",
    "        super(COCOB, self).__init__(**kwargs)\n",
    "        self._alpha = alpha\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "    \n",
    "    def get_updates(self, params, loss, contraints=None):\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        shapes = [K.int_shape(p) for p in params]\n",
    "        L = [K.variable(np.full(fill_value=1e-8, shape=shape)) for shape in shapes]\n",
    "        reward = [K.zeros(shape) for shape in shapes]\n",
    "        tilde_w = [K.zeros(shape) for shape in shapes]\n",
    "        gradients_sum = [K.zeros(shape) for shape in shapes]\n",
    "        gradients_norm_sum = [K.zeros(shape) for shape in shapes]\n",
    "    \n",
    "        for p, g, li, ri, twi, gsi, gns in zip(params, grads, L, reward, tilde_w,gradients_sum, gradients_norm_sum):\n",
    "            grad_sum_update = gsi + g\n",
    "            grad_norm_sum_update = gns + K.abs(g)\n",
    "            l_update = K.maximum(li, K.abs(g))\n",
    "            reward_update = K.maximum(ri - g * twi, 0)\n",
    "            new_w = - grad_sum_update / (l_update * (K.maximum(grad_norm_sum_update + l_update, self._alpha * l_update))) * (reward_update + l_update)\n",
    "            param_update = p - twi + new_w\n",
    "            tilde_w_update = new_w            \n",
    "            self.updates.append(K.update(gsi, grad_sum_update))\n",
    "            self.updates.append(K.update(gns, grad_norm_sum_update))\n",
    "            self.updates.append(K.update(li, l_update))\n",
    "            self.updates.append(K.update(ri, reward_update))\n",
    "            self.updates.append(K.update(p, param_update))\n",
    "            self.updates.append(K.update(twi, tilde_w_update))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):        \n",
    "        config = {'alpha': float(K.get_value(self._alpha)) }\n",
    "        base_config = super(COCOB, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-673b05f336b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCOCOB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-27eec8a8efa9>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, alpha, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpaper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \"\"\"\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOCOB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "COCOB()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = nn_model_structure(layers = 5,\n",
    "                           neurons = [128, 128, 64, 32, 10],\n",
    "                           n_cols = X_train_small.shape[1])\n",
    "model = nn_model_compile(model, optimizer = COCOB())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
