{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "inputs = range(10) \n",
    "def processInput(i):\n",
    "    return i * i\n",
    " \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "     \n",
    "results = Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in inputs)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[1., 1.],\n",
      "       [1., 1.]]), 1], [array([[2., 2.],\n",
      "       [2., 2.]]), 2], [array([[3., 3.],\n",
      "       [3., 3.]]), 3], [array([[4., 4.],\n",
      "       [4., 4.]]), 4]]\n",
      "<class 'list'>\n",
      "4\n",
      "[array([[1., 1.],\n",
      "       [1., 1.]]), 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4}\n",
    "\n",
    "def test_function(val):\n",
    "    return [np.ones((2,2))*val, val]\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "     \n",
    "results = Parallel(n_jobs=num_cores)(delayed(test_function)(val) for val in list(d.values()))\n",
    "\n",
    "print(results)\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = {\n",
    "    \"a\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"b\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"c\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"d\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"e\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"f\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"g\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    \"h\": np.random.randint(0, 100, size = (10000,10000)),\n",
    "    }\n",
    "\n",
    "def test_function(val):\n",
    "    return val**2\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with for loop: 3.647850751876831 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(len(d)):\n",
    "    a = list(d.values())[i]**2\n",
    "end_time = time.time()\n",
    "print(\"Time with for loop: {} seconds\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with parallelization: 10.8079092502594 seconds\n"
     ]
    }
   ],
   "source": [
    "# hier geht die CPU-Auslastung richtig hoch\n",
    "start_time = time.time()\n",
    "results = Parallel(n_jobs=num_cores, backend = \"threading\")(delayed(test_function)(val) for val in list(d.values()))\n",
    "end_time = time.time()\n",
    "print(\"Time with parallelization: {} seconds\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je nachdem, was sonst noch so läuft, kann die Zeit mit der for-Schleife auch mal geringer sein als mit der Parallelisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with parallelization: 33.828524589538574 seconds\n"
     ]
    }
   ],
   "source": [
    "# das gleiche, aber ohne backend = \"threading\"\n",
    "# CPU-Auslastung sinkt wieder auf Normalniveau\n",
    "start_time = time.time()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(test_function)(val) for val in list(d.values()))\n",
    "end_time = time.time()\n",
    "print(\"Time with parallelization: {} seconds\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "X_test = X_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "model_dict = {}\n",
    "for i in range(100):\n",
    "    tf.python.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, \"relu\", input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dense(128, \"relu\"))\n",
    "    model.add(Dense(64, \"relu\"))\n",
    "    model.add(Dense(32, \"relu\"))\n",
    "    model.add(Dense(10, \"softmax\"))\n",
    "    \n",
    "    model.compile(\"adam\", \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    model_dict[\"model_{}\".format(str(i+1))] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fct(model):\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation took 44.139549255371094 seconds.\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# darum geht es!! \n",
    "# hier habe ich eine CPU-Auslastung von maximal 30-40%\n",
    "# alle 100 Modelle sind voneinander unabhängig und können daher parallel berechnet werden\n",
    "# ohne das backend = \"threading\" kommt der Error mit dem pickle.\n",
    "start_time = time.time()\n",
    "results = Parallel(n_jobs=num_cores, backend = \"threading\")(delayed(eval_fct)(model) for model in list(model_dict.values()))\n",
    "end_time = time.time()\n",
    "print(\"Calculation took {} seconds.\".format(str(end_time-start_time)))\n",
    "print(results[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
