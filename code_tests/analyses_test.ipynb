{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../python/functions\")\n",
    "sys.path.insert(2, \"../python/architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../python/architecture\\reproducible.py:14: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_prep_functions import wine_prep\n",
    "from plotting_functions import nn_plot_mse\n",
    "from saving_functions import *\n",
    "from model_functions import nn_load, nn_save, nn_model_structure, nn_model_compile\n",
    "import reproducible\n",
    "import no_gpu\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = wine_prep()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use samller dataset for increased speed\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:500]\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 4\n",
    "neurons = [32, 32, 16, 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def enkf_regressor_analysis(X_train,\n",
    "                            X_test,\n",
    "                            y_train,\n",
    "                            y_test,\n",
    "                            layers,\n",
    "                            neurons,\n",
    "                            setting_dict,\n",
    "                            analysis_dict,\n",
    "                            save_all = False,\n",
    "                            file_var = \"file.pckl\",\n",
    "                            file_model = \"file.h5\",\n",
    "                            verbose = 0\n",
    "                            ):\n",
    "\n",
    "    \"\"\" Ensemble Kalman Filter algorithm analysis for regression problems.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train (np.ndarray): Training data X.\n",
    "    X_test (np.ndarray): Test data X.\n",
    "    y_train (pd.DataFrame): Training data y.\n",
    "    y_test (pd.DataFrame): Test data y.\n",
    "    layers (int): Number of layers.\n",
    "    neurons (list): Number of neurons in each layer.\n",
    "    setting_dict (dict): Dictionary containing\n",
    "        particles (int): Number of particles in the ensemble.\n",
    "        epochs (int): Number of epochs.\n",
    "        batch_size (None or int): Size of the batches. Must be between 0 and the number of observations in the training set.\n",
    "        h_0 (int or float): Starting step size.\n",
    "        delta (float): Constant for numerical stability in the jacobian.\n",
    "        epsilon (float): Constant for numerical stability in the step size.\n",
    "        randomization (bool): Whether or not to add noise to the particles and randomize them around their mean.\n",
    "        shuffle (bool): Whether or not to shuffle the data prior to each epoch.\n",
    "        early_stopping (bool): Whether or not to stop the calculation when the changes get small.\n",
    "        early_stopping_diff (bool): Minimum change before early stopping is applied.\n",
    "    analysis_dict (dict): Dictionary containing\n",
    "        disjoint_batch (bool): Whether or not to use disjoint batches. If False then each batch is sampled with replacement.\n",
    "        multiple_updates_same_batch (int or None): Number of consecutive updates on the same batch.\n",
    "        batch_particle_connection (dict): Dictionary containing\n",
    "            connect (bool): Whether or not to connect particles and batches.\n",
    "            shuffle (str or None): Whether or not and how to shuffle the connection. None = no shuffle. \"batch\" = shuffle the batch for fixed particle sets. \"full\" = shuffle the particle sets and their corresponding batch.\n",
    "            update_all (bool): Whether or not to update after all particles have seen some data.\n",
    "        batch_evaluation (dict): Dictionary containing\n",
    "            mean_model (bool): Whether or not evaluate the mean model after every batch on that batch. Warning: the computational costs are very high.\n",
    "            particles (bool): Whether or not evaluate every particle model after every batch on that batch. Warning: the computational costs are incredibly high.\n",
    "            file (str): Path and name of the file to save evaluations into \n",
    "        tikhonov (dict): Dictionary containing\n",
    "            regularize (bool): Whether or not to use Tikhonov regularization.\n",
    "            lambda (None or float): Lambda parameter in Tikhonov regularization.\n",
    "            reg_mse_stop (bool): Whether or not to stop when MSE + Tikhonov regularization starts to rise again.\n",
    "    save_all (bool): Whether or not to save all important variables and models.\n",
    "    file_var (str): Path and name of the file to save variables into.\n",
    "    file_model (str): Path and name of the file to save the final model into.\n",
    "    verbose (int): If 0, then don't print anything throughout the training process. If 1, then print training and test accuracy after each epoch.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    mean_model (tensorflow.python.keras.engine.sequential.Sequential): The final model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    particles = setting_dict[\"particles\"]\n",
    "    epochs = setting_dict[\"epochs\"]\n",
    "    batch_size = setting_dict[\"batch_size\"]\n",
    "    h_0 = setting_dict[\"h_0\"]\n",
    "    delta = None\n",
    "    epsilon = setting_dict[\"epsilon\"]\n",
    "    randomization = setting_dict[\"randomization\"]\n",
    "    shuffle = setting_dict[\"shuffle\"]\n",
    "    early_stopping = setting_dict[\"early_stopping\"]\n",
    "    early_stopping_diff = setting_dict[\"early_stopping_diff\"]\n",
    "    \n",
    "    disjoint_batch = analysis_dict[\"disjoint_batch\"]\n",
    "    batch_evaluation = analysis_dict[\"batch_evaluation\"]\n",
    "    batch_particle_connection = analysis_dict[\"batch_particle_connection\"][\"connect\"]\n",
    "    batch_particle_shuffle = analysis_dict[\"batch_particle_connection\"][\"shuffle\"]\n",
    "    update_all = analysis_dict[\"batch_particle_connection\"][\"update_all\"]\n",
    "    mult_updates_batch = analysis_dict[\"multiple_updates_same_batch\"]\n",
    "    tik_regularize = analysis_dict[\"tikhonov\"][\"regularize\"]\n",
    "    tik_lambda = analysis_dict[\"tikhonov\"][\"lambda\"]\n",
    "    reg_mse_stop = analysis_dict[\"tikhonov\"][\"reg_mse_stop\"]\n",
    "    \n",
    "    if tik_lambda is None:\n",
    "        tik_lambda = 0\n",
    "    \n",
    "    if mult_updates_batch is None:\n",
    "        mult_updates_batch = 1\n",
    "\n",
    "    if batch_size == None:\n",
    "        batch_size = len(X_train)\n",
    "\n",
    "    n_cols = X_train.shape[1]\n",
    "    \n",
    "    if disjoint_batch:\n",
    "        n = len(X_train)\n",
    "        num_batches = int(np.ceil(n / batch_size))\n",
    "        batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "        batch_indices[-1] = n\n",
    "    else:\n",
    "        n = len(X_train)\n",
    "        num_batches = int(np.ceil(n / batch_size))\n",
    "        last_batch_size = n % batch_size\n",
    "        \n",
    "    if batch_particle_connection:\n",
    "        batch_particle_dict = {}\n",
    "        batch_particle_indices = np.arange(particles) + 1\n",
    "        np.random.shuffle(batch_particle_indices)\n",
    "        if particles == num_batches:\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[i]\n",
    "        elif particles > num_batches:\n",
    "            base_batches = particles // num_batches\n",
    "            add_batches = particles % num_batches\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[:base_batches]\n",
    "                batch_particle_indices = batch_particle_indices[base_batches:]\n",
    "            for i in range(add_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = np.concatenate([batch_particle_dict[\"batch_{}\".format(str(i+1))], np.array([batch_particle_indices[i]])])\n",
    "        elif num_batches > particles:\n",
    "            num_reps = int(np.ceil(num_batches / particles))\n",
    "            particles_repeated = np.tile(batch_particle_indices, num_reps)\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = particles_repeated[i]\n",
    "    else:\n",
    "        batch_particle_dict = None\n",
    "\n",
    "    model_dict = {}\n",
    "    weights_dict = {}\n",
    "    y_pred_dict = {}\n",
    "    jacobian_dict = {}\n",
    "    weights_vector_dict = {}\n",
    "    train_mse_dict = {}\n",
    "    test_mse_dict = {}\n",
    "    \n",
    "    if batch_evaluation[\"mean_model\"]:\n",
    "        train_batch_mse_mean_dict = {}\n",
    "    if batch_evaluation[\"particles\"]:\n",
    "        train_batch_mse_particle_dict = {}\n",
    "\n",
    "    # init_model already has weights and biases following the Glorot distribution\n",
    "    # it can already be used to predict and evaluate, but it is very bad\n",
    "    # only used to determine shapes and shape_elements via its weights\n",
    "    init_model = nn_model_structure(layers = layers,\n",
    "                                    neurons = neurons,\n",
    "                                    n_cols = n_cols,\n",
    "                                    classification = False)\n",
    "    init_model = nn_model_compile(init_model,\n",
    "                                  optimizer = \"sgd\")\n",
    "    weights = init_model.get_weights()\n",
    "    # shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "    shapes = [np.array(params.shape) for params in weights]\n",
    "    # shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "    shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])\n",
    "\n",
    "    for i in range(particles):\n",
    "        \n",
    "        # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization\n",
    "        model = nn_model_structure(layers = layers,\n",
    "                                   neurons = neurons,\n",
    "                                   n_cols = n_cols,\n",
    "                                   classification = False)\n",
    "        model = nn_model_compile(model,\n",
    "                                 optimizer = \"sgd\")\n",
    "        # for every particle write the model in a dictionary\n",
    "        model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "\n",
    "        # for every particles write the weights and biases in a dictionary\n",
    "        weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .get_weights()\n",
    "        \n",
    "        # for every particle write the predictions on the training batches in a dictionary\n",
    "        y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .predict(X_train[:batch_size,:])\n",
    "\n",
    "        # for every particle write the Jacobian in a dictionary\n",
    "        jacobian_dict[\"model_{}\".format(str(i+1))] = 1/len(y_train[:batch_size]) * (-2)*(y_train[:batch_size] - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "\n",
    "        train_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        test_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        \n",
    "        if batch_evaluation[\"particles\"]:\n",
    "            train_batch_mse_particle_dict[\"particle_{}\".format(str(i+1))] = {}\n",
    "\n",
    "    # mean_model as the model with the mean of the weights of all particle models\n",
    "    mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "    mean_model = init_model\n",
    "    mean_model.set_weights(mean_weights)\n",
    "\n",
    "    mean_model_train_mse = np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1])\n",
    "    mean_model_test_mse = np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "    if tik_regularize:\n",
    "        mean_weights_raveled = [arr.ravel() for arr in mean_weights]\n",
    "        mean_model_train_mse_reg = mean_model_train_mse + tik_lambda * np.sum(np.hstack(mean_weights_raveled)**2)\n",
    "        mean_model_test_mse_reg = mean_model_test_mse + tik_lambda * np.sum(np.hstack(mean_weights_raveled)**2)\n",
    "\n",
    "    # loop over all epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # early stopping\n",
    "        if early_stopping:\n",
    "            if epoch == 0:\n",
    "                train_mse_old = 0\n",
    "                test_mse_old = 0\n",
    "            else:\n",
    "                train_mse_new = mean_model_train_mse[epoch]\n",
    "                test_mse_new = mean_model_test_mse[epoch]\n",
    "                if np.absolute(test_mse_new - test_mse_old) <= early_stopping_diff and np.absolute(train_mse_new - train_mse_old) <= early_stopping_diff:\n",
    "                    print(\"STOP: Early Stopping after epoch {} because improvement in training MSE is only {} and in test mse only {}.\"\\\n",
    "                                                                         .format(epoch, train_mse_new - train_mse_old, test_mse_new - test_mse_old))\n",
    "                    break\n",
    "                test_mse_old = test_mse_new\n",
    "                                                                            \n",
    "        # Tikhonov regularization stopping\n",
    "        if tik_regularize and reg_mse_stop:\n",
    "            if epoch >= 1:\n",
    "                if mean_model_train_mse_reg[epoch] > mean_model_train_mse_reg[epoch-1] and mean_model_test_mse_reg[epoch] > mean_model_test_mse_reg[epoch-1]:\n",
    "                    print(\"Training and test MSEs containing Tikhonov regularization start to rise. Algorithm is stopped after epoch {}.\".format(epoch))\n",
    "                    break\n",
    "                \n",
    "        # shuffle the data\n",
    "        if shuffle:\n",
    "            indices = y_train.sample(frac=1).index\n",
    "        else:\n",
    "            indices = y_train.index\n",
    "            \n",
    "        if disjoint_batch:\n",
    "            X_batches = [np.array(X_train)[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [np.array(i) for i in y_batches]\n",
    "        else:\n",
    "            if last_batch_size != 0:\n",
    "                indices = [np.random.choice(len(X_train), size = batch_size, replace = True) for i in range(num_batches-1)]\n",
    "                indices.append(np.random.choice(len(X_train), size = last_batch_size, replace = True))\n",
    "            else:\n",
    "                indices = [np.random.choice(len(X_train), size = batch_size, replace = True) for i in range(num_batches)]\n",
    "            X_batches = [X_train[indices[i]] for i in range(len(indices))]\n",
    "            y_batches = [y_train[indices[i]] for i in range(len(indices))]\n",
    "            \n",
    "        if batch_particle_connection and batch_particle_shuffle == \"batch\":\n",
    "            shuffled_indices = np.hstack(list(batch_particle_dict.values()))\n",
    "            np.random.shuffle(shuffled_indices)\n",
    "            batch_particle_values = list(batch_particle_dict.values())\n",
    "            for i in range(len(batch_particle_values)):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = shuffled_indices[i*len(batch_particle_values[i]):(i+1)*len(batch_particle_values[i])]\n",
    "        elif batch_particle_connection and batch_particle_shuffle == \"full\":\n",
    "            batch_particle_dict = {}\n",
    "            batch_particle_indices = np.arange(particles) + 1\n",
    "            np.random.shuffle(batch_particle_indices)\n",
    "            if particles == num_batches:\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[i]\n",
    "            elif particles > num_batches:\n",
    "                base_batches = particles // num_batches\n",
    "                add_batches = particles % num_batches\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[:base_batches]\n",
    "                    batch_particle_indices = batch_particle_indices[base_batches:]\n",
    "                for i in range(add_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = np.concatenate([batch_particle_dict[\"batch_{}\".format(str(i+1))], np.array([batch_particle_indices[i]])])\n",
    "            elif num_batches > particles:\n",
    "                num_reps = int(np.ceil(num_batches / particles))\n",
    "                particles_repeated = np.tile(batch_particle_indices, num_reps)\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = particles_repeated[i]\n",
    "            \n",
    "        if batch_evaluation[\"mean_model\"]:\n",
    "            train_batch_mse_mean_dict[\"Epoch_{}\".format(str(epoch+1))] = {}\n",
    "        if batch_evaluation[\"particles\"]:\n",
    "            train_batch_mse_particle_dict[\"particle_{}\".format(str(i+1))][\"Epoch_{}\".format(str(epoch+1))] = {}\n",
    "                    \n",
    "        # loop over all batches\n",
    "        for b in range(num_batches):\n",
    "            for mult_updates in range(mult_updates_batch):\n",
    "                batch_particles = []\n",
    "                y_pred_batch_dict = {}\n",
    "                jacobian_batch_dict = {}\n",
    "                for i in range(particles):\n",
    "                    if batch_particle_connection: \n",
    "                        if num_batches == particles or num_batches > particles:\n",
    "                            if batch_particle_dict[\"batch_{}\".format(str(b+1))] != i+1:\n",
    "                                continue\n",
    "                        else:\n",
    "                            if i+1 not in batch_particle_dict[\"batch_{}\".format(str(b+1))]:\n",
    "                                continue\n",
    "                    if batch_particle_connection:\n",
    "                        batch_particles.append(i+1)\n",
    "                    \n",
    "                    # set new weights for model\n",
    "                    model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "\n",
    "                    # for every particle write the predictions on the training batches in a dictionary\n",
    "                    y_pred_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                    .predict(X_batches[b])\n",
    "                    y_pred_batch_dict[\"model_{}\".format(i+1)] = y_pred_dict[\"model_{}\".format(i+1)]\n",
    "\n",
    "                    # for every particle write the Jacobian in a dictionary\n",
    "                    jacobian_dict[\"model_{}\".format(str(i+1))] = 1/len(y_batches[b]) * (-2)*(y_batches[b] - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "                    jacobian_batch_dict[\"model_{}\".format(i+1)] = jacobian_dict[\"model_{}\".format(i+1)]\n",
    "\n",
    "                    if batch_evaluation[\"mean_model\"]:\n",
    "                        train_batch_mse_mean_dict[\"Epoch_{}\".format(str(epoch+1))][\"Batch_{}\".format(str(b+1))] = mean_model.evaluate(X_batches[b], y_batches[b], verbose = 0)[1]\n",
    "                    if batch_evaluation[\"particles\"]:\n",
    "                        train_batch_mse_particle_dict[\"particle_{}\".format(str(i+1))][\"Epoch_{}\".format(str(epoch+1))][\"Batch_{}\".format(str(b+1))] = model_dict[\"model_{}\".format(str(i+1))].evaluate(X_batches[b], y_batches[b], verbose = 0)[1]\n",
    "\n",
    "                        \n",
    "                if not batch_particle_connection:        \n",
    "                    # compute the mean of the predictions\n",
    "                    y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "                    # compute the matrix D elementwise\n",
    "                    d = np.zeros(shape = (particles, particles))\n",
    "                    for k in range(particles):\n",
    "                        y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                        for j in range(particles):\n",
    "                            d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_dict[\"model_{}\".format(str(j+1))])\n",
    "                    d = np.transpose(d)\n",
    "\n",
    "                    # compute the scalar h_t\n",
    "                    h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "                    # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "                    for i in range(particles):\n",
    "                        weights_array = np.array([])\n",
    "                        for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                            weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "                    # matrix with particle parameters as row vectors\n",
    "                    weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "                    # compute the matrix with the updates for each particle\n",
    "                    weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "                    for i in range(particles):\n",
    "                        # write the updates back into the dictionary\n",
    "                        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                        # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                        for l in range(len(shape_elements)-1):\n",
    "                            start = shape_elements[l]\n",
    "                            end = shape_elements[l+1]\n",
    "                            weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                \n",
    "                elif batch_particle_connection and not update_all:\n",
    "                    # compute the mean of the predictions\n",
    "                    y_pred_mean = np.mean(list(y_pred_batch_dict.values()), axis = 0)\n",
    "                    \n",
    "                    # compute the matrix D elementwise\n",
    "                    d = np.zeros(shape = (len(batch_particles), len(batch_particles)))\n",
    "                    for k in range(len(batch_particles)):\n",
    "                        y_pred_centered = y_pred_batch_dict[\"model_{}\".format(batch_particles[k])] - y_pred_mean\n",
    "                        for j in range(len(batch_particles)):\n",
    "                            d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_batch_dict[\"model_{}\".format(batch_particles[j])])\n",
    "                    d = np.transpose(d)\n",
    "\n",
    "                    # compute the scalar h_t\n",
    "                    h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "                    # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "                    for i in range(particles):\n",
    "                        weights_array = np.array([])\n",
    "                        for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                            weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                        weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "                    # matrix with particle parameters as row vectors\n",
    "                    weights_vector_batch_dict = {}\n",
    "                    for i in range(len(batch_particles)):\n",
    "                        weights_vector_batch_dict[\"model_{}\".format(batch_particles[i])] = weights_vector_dict[\"model_{}\".format(batch_particles[i])]\n",
    "                        weights_all_ptcls = np.array(list(weights_vector_batch_dict.values()))\n",
    "\n",
    "                    # compute the matrix with the updates for each particle\n",
    "                    weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "                    for i in range(len(batch_particles)):\n",
    "                        # write the updates back into the dictionary\n",
    "                        weights_vector_dict[\"model_{}\".format(batch_particles[i])] = weights_all_ptcls[i]\n",
    "                        # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                        for l in range(len(shape_elements)-1):\n",
    "                            start = shape_elements[l]\n",
    "                            end = shape_elements[l+1]\n",
    "                            weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "\n",
    "        if batch_particle_connection and update_all:\n",
    "            # compute the mean of the predictions\n",
    "            y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "            # compute the matrix D elementwise\n",
    "            d = np.zeros(shape = (particles, particles))\n",
    "            for k in range(particles):\n",
    "                y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                for j in range(particles):\n",
    "                    d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_dict[\"model_{}\".format(str(j+1))])\n",
    "            d = np.transpose(d)\n",
    "\n",
    "            # compute the scalar h_t\n",
    "            h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "            # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "            for i in range(particles):\n",
    "                weights_array = np.array([])\n",
    "                for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                    weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "            # matrix with particle parameters as row vectors\n",
    "            weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "            # compute the matrix with the updates for each particle\n",
    "            weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "            for i in range(particles):\n",
    "                # write the updates back into the dictionary\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                for l in range(len(shape_elements)-1):\n",
    "                    start = shape_elements[l]\n",
    "                    end = shape_elements[l+1]\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                                                            \n",
    "        for i in range(particles):\n",
    "            # for every particle write the training MSE of the current iteration in a dictionary\n",
    "            train_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the test MSE of the current iteration in a dictionary\n",
    "            test_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "        # update the mean_model\n",
    "        mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "        mean_model.set_weights(mean_weights)\n",
    "\n",
    "        mean_model_train_mse = np.append(mean_model_train_mse, np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1]))\n",
    "        mean_model_test_mse = np.append(mean_model_test_mse, np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1]))\n",
    "        if tik_regularize and reg_mse_stop:\n",
    "            mean_weights_raveled = [arr.ravel() for arr in mean_weights]\n",
    "            mean_model_train_mse_reg = np.append(mean_model_train_mse_reg, mean_model_train_mse[-1] + tik_lambda * np.sum(np.hstack(mean_weights_raveled)**2))\n",
    "            mean_model_test_mse_reg = np.append(mean_model_test_mse_reg, mean_model_test_mse[-1] + tik_lambda * np.sum(np.hstack(mean_weights_raveled)**2))\n",
    "        \n",
    "\n",
    "        if verbose == 1:\n",
    "            print(\"Epoch {}. Training MSE: {}, Test MSE: {}.\".format(epoch+1,\n",
    "                                                                     np.round(mean_model_train_mse[-1], 3),\n",
    "                                                                     np.round(mean_model_test_mse[-1], 3)))\n",
    "            \n",
    "    mean_model.history.history = {\"mse\": mean_model_train_mse[1:],\n",
    "                                  \"val_mse\": mean_model_test_mse[1:]}\n",
    "        \n",
    "    if save_all:\n",
    "        param_dict = param_to_dict(X_train,\n",
    "                                   X_test,\n",
    "                                   y_train,\n",
    "                                   y_test,\n",
    "                                   layers,\n",
    "                                   neurons,\n",
    "                                   particles,\n",
    "                                   epochs,\n",
    "                                   batch_size,\n",
    "                                   h_0,\n",
    "                                   delta,\n",
    "                                   epsilon,\n",
    "                                   randomization,\n",
    "                                   shuffle,\n",
    "                                   early_stopping,\n",
    "                                   early_stopping_diff\n",
    "                                   )\n",
    "        results_dict = results_to_dict(mean_model_train_mse,\n",
    "                                       mean_model_test_mse,\n",
    "                                       train_mse_dict,\n",
    "                                       test_mse_dict,\n",
    "                                       weights_dict,\n",
    "                                       y_pred_dict,\n",
    "                                       False\n",
    "                                       )\n",
    "\n",
    "        saving_dict = {}\n",
    "        saving_dict[\"parameters\"] = param_dict\n",
    "        saving_dict[\"results\"] = results_dict\n",
    "        saving_dict[\"analysis\"] = analysis_dict\n",
    "\n",
    "        save_objects(obj_dict = saving_dict,\n",
    "                     file = file_var)\n",
    "\n",
    "        nn_save(model = mean_model,\n",
    "                path_name = file_model)\n",
    "        \n",
    "        if batch_evaluation[\"mean_model\"]:\n",
    "            full_dict = {}\n",
    "            full_dict[\"mean_model\"] = train_batch_mse_mean_dict\n",
    "            if batch_evaluation[\"particles\"]:\n",
    "                full_dict[\"particles\"] = train_batch_mse_particle_dict\n",
    "            save_objects(obj_dict = full_dict,\n",
    "                         file = batch_evaluation[\"file\"])\n",
    "        elif batch_evaluation[\"particles\"]:\n",
    "            full_dict = {}\n",
    "            full_dict[\"particles\"] = train_batch_mse_particle_dict\n",
    "            if batch_evaluation[\"mean_model\"]:\n",
    "                full_dict[\"mean_model\"] = train_batch_mse_mean_dict\n",
    "            save_objects(obj_dict = full_dict,\n",
    "                         file = batch_evaluation[\"file\"])\n",
    " \n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enkf_regressor_analysis(X_train,\n",
    "                            X_test,\n",
    "                            y_train,\n",
    "                            y_test,\n",
    "                            layers,\n",
    "                            neurons,\n",
    "                            setting_dict,\n",
    "                            analysis_dict,\n",
    "                            save_all = False,\n",
    "                            file_var = \"file.pckl\",\n",
    "                            file_model = \"file.h5\",\n",
    "                            verbose = 0\n",
    "                            ):\n",
    "\n",
    "    \"\"\" Ensemble Kalman Filter algorithm analysis for regression problems.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train (np.ndarray): Training data X.\n",
    "    X_test (np.ndarray): Test data X.\n",
    "    y_train (pd.DataFrame): Training data y.\n",
    "    y_test (pd.DataFrame): Test data y.\n",
    "    layers (int): Number of layers.\n",
    "    neurons (list): Number of neurons in each layer.\n",
    "    setting_dict (dict): Dictionary containing\n",
    "        particles (int): Number of particles in the ensemble.\n",
    "        epochs (int): Number of epochs.\n",
    "        batch_size (None or int): Size of the batches. Must be between 0 and the number of observations in the training set.\n",
    "        h_0 (int or float): Starting step size.\n",
    "        delta (float): Constant for numerical stability in the jacobian.\n",
    "        epsilon (float): Constant for numerical stability in the step size.\n",
    "        shuffle (bool): Whether or not to shuffle the data prior to each epoch.\n",
    "        early_stopping (float or None): Minimum change before early stopping is applied.\n",
    "    analysis_dict (dict): Dictionary containing\n",
    "        disjoint_batch (bool): Whether or not to use disjoint batches. If False then each batch is sampled with replacement.\n",
    "        batch_particle_connection (dict): Dictionary containing\n",
    "            connect (bool): Whether or not to connect particles and batches.\n",
    "            shuffle (str or None): Whether or not and how to shuffle the connection. None = no shuffle. \"permute\" = change the allocation of the existing batches and particle sets. \"particle\" = shuffle the particle sets for fixed batches. \"batch\" = shuffle the batch for fixed particle sets. \"full\" = shuffle the particle sets and their corresponding batch.\n",
    "        tikhonov (dict): Dictionary containing\n",
    "            regularize (bool): Whether or not to use Tikhonov regularization.\n",
    "            lambda (None or float): Lambda parameter in Tikhonov regularization. \n",
    "    save_all (bool): Whether or not to save all important variables and models.\n",
    "    file_var (str): Path and name of the file to save variables into.\n",
    "    file_model (str): Path and name of the file to save the final model into.\n",
    "    verbose (int): If 0, then don't print anything throughout the training process. If 1, then print training and test accuracy after each epoch.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    mean_model (tensorflow.python.keras.engine.sequential.Sequential): The final model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    particles = setting_dict[\"particles\"]\n",
    "    epochs = setting_dict[\"epochs\"]\n",
    "    batch_size = setting_dict[\"batch_size\"]\n",
    "    h_0 = setting_dict[\"h_0\"]\n",
    "    delta = None\n",
    "    epsilon = setting_dict[\"epsilon\"]\n",
    "    shuffle = setting_dict[\"shuffle\"]\n",
    "    early_stopping = setting_dict[\"early_stopping\"]\n",
    "    \n",
    "    disjoint_batch = analysis_dict[\"disjoint_batch\"]\n",
    "    batch_particle_connection = analysis_dict[\"batch_particle_connection\"][\"connect\"]\n",
    "    batch_particle_shuffle = analysis_dict[\"batch_particle_connection\"][\"shuffle\"]\n",
    "    tik_regularize = analysis_dict[\"tikhonov\"][\"regularize\"]\n",
    "    tik_lambda = analysis_dict[\"tikhonov\"][\"lambda\"]\n",
    "    if not tik_regularize:\n",
    "        tik_lambda = None\n",
    "    if tik_regularize and tik_lambda is None:\n",
    "        tik_lambda = 0\n",
    "        \n",
    "    def regularize_pred(y_pred, weights):\n",
    "        if tik_regularize and tik_lambda != 0:\n",
    "            return np.hstack([y_pred.ravel(), np.sqrt(tik_lambda) * weights])\n",
    "        else:\n",
    "            return y_pred.ravel()\n",
    "    \n",
    "    def regularize_true(y_true, weights):\n",
    "        if tik_regularize and tik_lambda != 0:\n",
    "            return np.hstack([y_true, np.zeros(shape = weights.shape)])\n",
    "        else:\n",
    "            return y_true.ravel()\n",
    "    \n",
    "    if batch_size == None:\n",
    "        batch_size = len(X_train)\n",
    "\n",
    "    n_cols = X_train.shape[1]\n",
    "    \n",
    "    if disjoint_batch:\n",
    "        n = len(X_train)\n",
    "        num_batches = int(np.ceil(n / batch_size))\n",
    "        batch_indices = np.cumsum([0] + list(np.ones(num_batches) * batch_size))\n",
    "        batch_indices[-1] = n\n",
    "    else:\n",
    "        n = len(X_train)\n",
    "        num_batches = int(np.ceil(n / batch_size))\n",
    "        last_batch_size = n % batch_size\n",
    "     \n",
    "    if batch_particle_connection:\n",
    "        batch_particle_dict = {}\n",
    "        batch_particle_indices = np.arange(particles) + 1\n",
    "        np.random.shuffle(batch_particle_indices)\n",
    "        if particles == num_batches:\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[i]\n",
    "        elif particles > num_batches:\n",
    "            base_batches = particles // num_batches\n",
    "            add_batches = particles % num_batches\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[:base_batches]\n",
    "                batch_particle_indices = batch_particle_indices[base_batches:]\n",
    "            for i in range(add_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = np.concatenate([batch_particle_dict[\"batch_{}\".format(str(i+1))], np.array([batch_particle_indices[i]])])\n",
    "        elif num_batches > particles:\n",
    "            num_reps = int(np.ceil(num_batches / particles))\n",
    "            particles_repeated = np.tile(batch_particle_indices, num_reps)\n",
    "            for i in range(num_batches):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = particles_repeated[i]\n",
    "    else:\n",
    "        batch_particle_dict = None\n",
    "\n",
    "    model_dict = {}\n",
    "    weights_dict = {}\n",
    "    y_pred_dict = {}\n",
    "    jacobian_dict = {}\n",
    "    weights_vector_dict = {}\n",
    "    train_mse_dict = {}\n",
    "    test_mse_dict = {}\n",
    "\n",
    "    # init_model already has weights and biases following the Glorot distribution\n",
    "    # it can already be used to predict and evaluate, but it is very bad\n",
    "    # only used to determine shapes and shape_elements via its weights\n",
    "    init_model = nn_model_structure(layers = layers,\n",
    "                                    neurons = neurons,\n",
    "                                    n_cols = n_cols,\n",
    "                                    kernel_regularizer_lambda = tik_lambda,\n",
    "                                    bias_regularizer_lambda = tik_lambda,\n",
    "                                    classification = False)\n",
    "    init_model = nn_model_compile(init_model,\n",
    "                                  optimizer = \"sgd\")\n",
    "    weights = init_model.get_weights()\n",
    "    # shape contains the shapes of the weight matrices and bias vectors as a list of arrays\n",
    "    shapes = [np.array(params.shape) for params in weights]\n",
    "    # shape_elements contains the indices of the weights as a vector and tells where to cut\n",
    "    shape_elements = np.cumsum([0] + [np.prod(shape) for shape in shapes])\n",
    "\n",
    "    for i in range(particles):\n",
    "        \n",
    "        # just an initial model with the correct structure regarding neurons, layers, activation functions, Glorot initialization, Tikhonov regularization\n",
    "        model = nn_model_structure(layers = layers,\n",
    "                                   neurons = neurons,\n",
    "                                   n_cols = n_cols,\n",
    "                                   kernel_regularizer_lambda = tik_lambda,\n",
    "                                   bias_regularizer_lambda = tik_lambda,\n",
    "                                   classification = False)\n",
    "        model = nn_model_compile(model,\n",
    "                                 optimizer = \"sgd\")\n",
    "        # for every particle write the model in a dictionary\n",
    "        model_dict[\"model_{}\".format(str(i+1))] = model\n",
    "\n",
    "        # for every particles write the weights and biases in a dictionary\n",
    "        weights_dict[\"model_{}\".format(str(i+1))] = model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                        .get_weights()\n",
    "        \n",
    "        # for every particle write the predictions on the training batches in a dictionary\n",
    "        weights_array_tik = np.array([])\n",
    "        for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "            weights_array_tik = np.append(weights_array_tik, weights_dict[\"model_{}\".format(str(i+1))][j].ravel())        \n",
    "        y_pred_dict[\"model_{}\".format(str(i+1))] = regularize_pred(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                        .predict(X_train[:batch_size,:]),\n",
    "                                                                   weights_array_tik)\n",
    "\n",
    "        # for every particle write the Jacobian in a dictionary\n",
    "        jacobian_dict[\"model_{}\".format(str(i+1))] = 1/len(regularize_true(y_train[:batch_size], weights_array_tik)) * (-2)*(regularize_true(y_train[:batch_size], weights_array_tik) - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "\n",
    "        train_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "        test_mse_dict[\"model_{}\".format(str(i+1))] = []\n",
    "\n",
    "    # mean_model as the model with the mean of the weights of all particle models\n",
    "    mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "    mean_model = init_model\n",
    "    mean_model.set_weights(mean_weights)\n",
    "\n",
    "    mean_model_train_mse = np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1])\n",
    "    mean_model_test_mse = np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "    # loop over all epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # early stopping\n",
    "        if early_stopping is not None:\n",
    "            if epoch == 0:\n",
    "                train_mse_old = 0\n",
    "                test_mse_old = 0\n",
    "            else:\n",
    "                train_mse_new = mean_model_train_mse[epoch]\n",
    "                test_mse_new = mean_model_test_mse[epoch]\n",
    "                if np.absolute(test_mse_new - test_mse_old) <= early_stopping and np.absolute(train_mse_new - train_mse_old) <= early_stopping:\n",
    "                    print(\"STOP: Early Stopping after epoch {} because improvement in training MSE is only {} and in test mse only {}.\"\\\n",
    "                                                                         .format(epoch, train_mse_new - train_mse_old, test_mse_new - test_mse_old))\n",
    "                    break\n",
    "                test_mse_old = test_mse_new\n",
    "                                                                                    \n",
    "        # shuffle the data\n",
    "        if shuffle:\n",
    "            indices = y_train.sample(frac=1).index\n",
    "        else:\n",
    "            indices = y_train.index\n",
    "            \n",
    "        if disjoint_batch:\n",
    "            X_batches = [np.array(X_train)[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [y_train.iloc[indices].reset_index(drop = True)[int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            y_batches = [np.array(i) for i in y_batches]\n",
    "        else:\n",
    "            if last_batch_size != 0:\n",
    "                indices = [np.random.choice(len(X_train), size = batch_size, replace = True) for i in range(num_batches-1)]\n",
    "                indices.append(np.random.choice(len(X_train), size = last_batch_size, replace = True))\n",
    "            else:\n",
    "                indices = [np.random.choice(len(X_train), size = batch_size, replace = True) for i in range(num_batches)]\n",
    "            X_batches = [X_train[indices[i]] for i in range(len(indices))]\n",
    "            y_batches = [y_train[indices[i]] for i in range(len(indices))]\n",
    "        \n",
    "        # shuffling for batch particle connection\n",
    "        if batch_particle_connection and batch_particle_shuffle == \"permute\":\n",
    "            shuffled_indices = np.hstack(list(batch_particle_dict.values()))\n",
    "            np.random.shuffle(shuffled_indices)\n",
    "            batch_particle_values = list(batch_particle_dict.values())\n",
    "            for i in range(len(batch_particle_values)):\n",
    "                batch_particle_dict[\"batch_{}\".format(str(i+1))] = shuffled_indices[i*len(batch_particle_values[i]):(i+1)*len(batch_particle_values[i])]\n",
    "        if batch_particle_connection and (batch_particle_shuffle == \"particle\" or batch_particle_shuffle == \"full\"):\n",
    "            batch_particle_dict = {}\n",
    "            batch_particle_indices = np.arange(particles) + 1\n",
    "            np.random.shuffle(batch_particle_indices)\n",
    "            if particles == num_batches:\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[i]\n",
    "            elif particles > num_batches:\n",
    "                base_batches = particles // num_batches\n",
    "                add_batches = particles % num_batches\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = batch_particle_indices[:base_batches]\n",
    "                    batch_particle_indices = batch_particle_indices[base_batches:]\n",
    "                for i in range(add_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = np.concatenate([batch_particle_dict[\"batch_{}\".format(str(i+1))], np.array([batch_particle_indices[i]])])\n",
    "            elif num_batches > particles:\n",
    "                num_reps = int(np.ceil(num_batches / particles))\n",
    "                particles_repeated = np.tile(batch_particle_indices, num_reps)\n",
    "                for i in range(num_batches):\n",
    "                    batch_particle_dict[\"batch_{}\".format(str(i+1))] = particles_repeated[i]\n",
    "        if batch_particle_connection and (batch_particle_shuffle == \"batch\" or batch_particle_shuffle == \"full\"):\n",
    "            indices = np.arange(n)\n",
    "            np.random.shuffle(indices)\n",
    "            if disjoint_batch:\n",
    "                X_batches = [X_train[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "                y_batches = [y_train[indices][int(batch_indices[i]):int(batch_indices[i+1])] for i in range(len(batch_indices)-1)]\n",
    "            else:\n",
    "                if last_batch_size != 0:\n",
    "                    indices = [np.random.choice(X_train.shape[0], size = batch_size, replace = True) for i in range(num_batches-1)]\n",
    "                    indices.append(np.random.choice(X_train.shape[0], size = last_batch_size, replace = True))\n",
    "                else:\n",
    "                    indices = [np.random.choice(X_train.shape[0], size = batch_size, replace = True) for i in range(num_batches)]\n",
    "                X_batches = [X_train[indices[i]] for i in range(len(indices))]\n",
    "                y_batches = [y_train[indices[i]] for i in range(len(indices))]\n",
    "               \n",
    "        # loop over all batches\n",
    "        for b in range(num_batches):\n",
    "            batch_particles = []\n",
    "            for i in range(particles):\n",
    "                if batch_particle_connection: \n",
    "                    if num_batches == particles or num_batches > particles:\n",
    "                        if batch_particle_dict[\"batch_{}\".format(str(b+1))] != i+1:\n",
    "                            continue\n",
    "                    else:\n",
    "                        if i+1 not in batch_particle_dict[\"batch_{}\".format(str(b+1))]:\n",
    "                            continue\n",
    "                if batch_particle_connection:\n",
    "                    batch_particles.append(i+1)\n",
    "\n",
    "                # set new weights for model\n",
    "                model_dict[\"model_{}\".format(str(i+1))].set_weights(weights_dict[\"model_{}\".format(str(i+1))])\n",
    "\n",
    "                # for every particle write the predictions on the training batches in a dictionary\n",
    "                weights_array_tik = np.array([])\n",
    "                for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                    weights_array_tik = np.append(weights_array_tik, weights_dict[\"model_{}\".format(str(i+1))][j].ravel())\n",
    "                y_pred_dict[\"model_{}\".format(str(i+1))] = regularize_pred(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                                .predict(X_batches[b]),\n",
    "                                                                           weights_array_tik)\n",
    "                \n",
    "                # for every particle write the Jacobian in a dictionary\n",
    "                jacobian_dict[\"model_{}\".format(str(i+1))] = 1/len(regularize_true(y_batches[b], weights_array_tik)) * (-2)*(regularize_true(y_batches[b], weights_array_tik) - y_pred_dict[\"model_{}\".format(str(i+1))].ravel())\n",
    "\n",
    "            if not batch_particle_connection:        \n",
    "                # compute the mean of the predictions\n",
    "                y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "                # compute the matrix D elementwise\n",
    "                d = np.zeros(shape = (particles, particles))\n",
    "                for k in range(particles):\n",
    "                    y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                    for j in range(particles):\n",
    "                        d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_dict[\"model_{}\".format(str(j+1))])\n",
    "                d = np.transpose(d)\n",
    "\n",
    "                # compute the scalar h_t\n",
    "                h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "                # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "                for i in range(particles):\n",
    "                    weights_array = np.array([])\n",
    "                    for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                        weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                    weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "                # matrix with particle parameters as row vectors\n",
    "                weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "                # compute the matrix with the updates for each particle\n",
    "                weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "                for i in range(particles):\n",
    "                    # write the updates back into the dictionary\n",
    "                    weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                    # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                    for l in range(len(shape_elements)-1):\n",
    "                        start = shape_elements[l]\n",
    "                        end = shape_elements[l+1]\n",
    "                        weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                \n",
    "        if batch_particle_connection:\n",
    "            # compute the mean of the predictions\n",
    "            y_pred_mean = np.mean(list(y_pred_dict.values()), axis = 0)\n",
    "\n",
    "            # compute the matrix D elementwise\n",
    "            d = np.zeros(shape = (particles, particles))\n",
    "            for k in range(particles):\n",
    "                y_pred_centered = y_pred_dict[\"model_{}\".format(str(k+1))] - y_pred_mean\n",
    "                for j in range(particles):\n",
    "                    d[k][j] = np.dot(y_pred_centered.ravel(), jacobian_dict[\"model_{}\".format(str(j+1))])\n",
    "            d = np.transpose(d)\n",
    "\n",
    "            # compute the scalar h_t\n",
    "            h_t = h_0 / (np.sqrt(np.sum(d**2)) + epsilon)\n",
    "\n",
    "            # Reshape the weights and biases so that they are no longer matrices and vectores, but now one single vector\n",
    "            for i in range(particles):\n",
    "                weights_array = np.array([])\n",
    "                for j in range(len(weights_dict[\"model_{}\".format(str(i+1))])):\n",
    "                    weights_array = np.append(weights_array, np.reshape(weights_dict[\"model_{}\".format(str(i+1))][j], (1, -1)).ravel())\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_array\n",
    "\n",
    "            # matrix with particle parameters as row vectors\n",
    "            weights_all_ptcls = np.array(list(weights_vector_dict.values()))\n",
    "\n",
    "            # compute the matrix with the updates for each particle\n",
    "            weights_all_ptcls = weights_all_ptcls - h_t * np.matmul(d, weights_all_ptcls)\n",
    "\n",
    "            for i in range(particles):\n",
    "                # write the updates back into the dictionary\n",
    "                weights_vector_dict[\"model_{}\".format(str(i+1))] = weights_all_ptcls[i]\n",
    "                # reshape the updates, so that they are of the original matrx and vector shape\n",
    "                for l in range(len(shape_elements)-1):\n",
    "                    start = shape_elements[l]\n",
    "                    end = shape_elements[l+1]\n",
    "                    weights_dict[\"model_{}\".format(str(i+1))][l] = np.reshape(weights_vector_dict[\"model_{}\".format(str(i+1))][start:end], tuple(shapes[l]))\n",
    "                                                            \n",
    "        for i in range(particles):\n",
    "            # for every particle write the training MSE of the current iteration in a dictionary\n",
    "            train_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_train, y_train, verbose = 0)[1])\n",
    "\n",
    "            # for every particle write the test MSE of the current iteration in a dictionary\n",
    "            test_mse_dict[\"model_{}\".format(str(i+1))].append(model_dict[\"model_{}\".format(str(i+1))]\\\n",
    "                                                                      .evaluate(X_test, y_test, verbose = 0)[1])\n",
    "\n",
    "        # update the mean_model\n",
    "        mean_weights = list(np.mean(list(weights_dict.values()), axis = 0))\n",
    "        mean_model.set_weights(mean_weights)\n",
    "\n",
    "        mean_model_train_mse = np.append(mean_model_train_mse, np.array(mean_model.evaluate(X_train, y_train, verbose = 0)[1]))\n",
    "        mean_model_test_mse = np.append(mean_model_test_mse, np.array(mean_model.evaluate(X_test, y_test, verbose = 0)[1])) \n",
    "\n",
    "        if verbose == 1:\n",
    "            print(\"Epoch {}. Training MSE: {}, Test MSE: {}.\".format(epoch+1,\n",
    "                                                                     np.round(mean_model_train_mse[-1], 3),\n",
    "                                                                     np.round(mean_model_test_mse[-1], 3)))\n",
    "            \n",
    "    mean_model.history.history = {\"mse\": mean_model_train_mse[1:],\n",
    "                                  \"val_mse\": mean_model_test_mse[1:]}\n",
    "        \n",
    "    if save_all:\n",
    "        param_dict = param_to_dict(X_train,\n",
    "                                   X_test,\n",
    "                                   y_train,\n",
    "                                   y_test,\n",
    "                                   layers,\n",
    "                                   neurons,\n",
    "                                   particles,\n",
    "                                   epochs,\n",
    "                                   batch_size,\n",
    "                                   h_0,\n",
    "                                   delta,\n",
    "                                   epsilon,\n",
    "                                   shuffle,\n",
    "                                   early_stopping\n",
    "                                   )\n",
    "        results_dict = results_to_dict(mean_model_train_mse,\n",
    "                                       mean_model_test_mse,\n",
    "                                       train_mse_dict,\n",
    "                                       test_mse_dict,\n",
    "                                       weights_dict,\n",
    "                                       y_pred_dict,\n",
    "                                       False\n",
    "                                       )\n",
    "\n",
    "        saving_dict = {}\n",
    "        saving_dict[\"parameters\"] = param_dict\n",
    "        saving_dict[\"results\"] = results_dict\n",
    "        saving_dict[\"analysis\"] = analysis_dict\n",
    "\n",
    "        save_objects(obj_dict = saving_dict,\n",
    "                     file = file_var)\n",
    "\n",
    "        nn_save(model = mean_model,\n",
    "                path_name = file_model)\n",
    " \n",
    "    return mean_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_dict = {\"particles\": 100,\n",
    "                \"epochs\": 20,\n",
    "                \"batch_size\": len(X_train),    # len(X_train)\n",
    "                \"h_0\": 2,\n",
    "                \"epsilon\": 0.5,\n",
    "                \"shuffle\": True,\n",
    "                \"early_stopping\": None\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dict = {\"disjoint_batch\": True,\n",
    "                 \"batch_particle_connection\": {\"connect\": False,\n",
    "                                               \"shuffle\": \"particle\"},        # None, \"permute\", \"particle\", \"batch\", \"full\"\n",
    "                 \"tikhonov\": {\"regularize\": True,\n",
    "                              \"lambda\": 1}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training MSE: 17.026, Test MSE: 17.035.\n",
      "Epoch 2. Training MSE: 8.826, Test MSE: 8.832.\n",
      "Epoch 3. Training MSE: 5.243, Test MSE: 5.248.\n",
      "Epoch 4. Training MSE: 3.622, Test MSE: 3.625.\n",
      "Epoch 5. Training MSE: 2.765, Test MSE: 2.765.\n",
      "Epoch 6. Training MSE: 2.131, Test MSE: 2.126.\n",
      "Epoch 7. Training MSE: 1.644, Test MSE: 1.634.\n",
      "Epoch 8. Training MSE: 1.324, Test MSE: 1.313.\n",
      "Epoch 9. Training MSE: 1.102, Test MSE: 1.092.\n",
      "Epoch 10. Training MSE: 0.965, Test MSE: 0.956.\n",
      "Epoch 11. Training MSE: 0.874, Test MSE: 0.869.\n",
      "Epoch 12. Training MSE: 0.805, Test MSE: 0.804.\n",
      "Epoch 13. Training MSE: 0.753, Test MSE: 0.757.\n",
      "Epoch 14. Training MSE: 0.719, Test MSE: 0.729.\n",
      "Epoch 15. Training MSE: 0.696, Test MSE: 0.713.\n",
      "Epoch 16. Training MSE: 0.678, Test MSE: 0.7.\n",
      "Epoch 17. Training MSE: 0.661, Test MSE: 0.689.\n",
      "Epoch 18. Training MSE: 0.646, Test MSE: 0.679.\n",
      "Epoch 19. Training MSE: 0.634, Test MSE: 0.67.\n",
      "Epoch 20. Training MSE: 0.623, Test MSE: 0.66.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "reg_model = enkf_regressor_analysis(X_train,\n",
    "                                    X_test,\n",
    "                                    y_train,\n",
    "                                    y_test,\n",
    "                                    layers,\n",
    "                                    neurons,\n",
    "                                    setting_dict,\n",
    "                                    analysis_dict,\n",
    "                                    save_all = True,\n",
    "                                    file_var = \"../objects/wine/wine_enkf_E{}_B{}_P{}_H{}_Reg.pckl\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    file_model = \"../models/wine/wine_enkf_E{}_B{}_P{}_H{}_Reg.h5\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_mse(reg_model,\n",
    "            mse_mean = None,\n",
    "            start_epoch = 1,\n",
    "            save = None)#\"../img/wine/wine_enkf_E{}_B{}_P{}_H{}_Reg.png\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_dict = {\"particles\": 181,\n",
    "                \"epochs\": 20,\n",
    "                \"batch_size\": 23,    # len(X_train)\n",
    "                \"h_0\": 2,\n",
    "                \"epsilon\": 0.5,\n",
    "                \"shuffle\": True,\n",
    "                \"early_stopping\": None\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dict = {\"disjoint_batch\": True,\n",
    "                 \"batch_particle_connection\": {\"connect\": True,\n",
    "                                               \"shuffle\": \"particle\"},        # None, \"permute\", \"particle\", \"batch\", \"full\"\n",
    "                 \"tikhonov\": {\"regularize\": False,\n",
    "                              \"lambda\": 1}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training MSE: 17.696, Test MSE: 17.706.\n",
      "Epoch 2. Training MSE: 9.214, Test MSE: 9.221.\n",
      "Epoch 3. Training MSE: 5.652, Test MSE: 5.658.\n",
      "Epoch 4. Training MSE: 3.813, Test MSE: 3.817.\n",
      "Epoch 5. Training MSE: 3.121, Test MSE: 3.123.\n",
      "Epoch 6. Training MSE: 2.816, Test MSE: 2.817.\n",
      "Epoch 7. Training MSE: 2.497, Test MSE: 2.495.\n",
      "Epoch 8. Training MSE: 2.409, Test MSE: 2.403.\n",
      "Epoch 9. Training MSE: 2.121, Test MSE: 2.111.\n",
      "Epoch 10. Training MSE: 1.975, Test MSE: 1.961.\n",
      "Epoch 11. Training MSE: 1.826, Test MSE: 1.81.\n",
      "Epoch 12. Training MSE: 1.731, Test MSE: 1.714.\n",
      "Epoch 13. Training MSE: 1.666, Test MSE: 1.647.\n",
      "Epoch 14. Training MSE: 1.618, Test MSE: 1.598.\n",
      "Epoch 15. Training MSE: 1.541, Test MSE: 1.52.\n",
      "Epoch 16. Training MSE: 1.474, Test MSE: 1.453.\n",
      "Epoch 17. Training MSE: 1.414, Test MSE: 1.393.\n",
      "Epoch 18. Training MSE: 1.385, Test MSE: 1.362.\n",
      "Epoch 19. Training MSE: 1.365, Test MSE: 1.341.\n",
      "Epoch 20. Training MSE: 1.329, Test MSE: 1.304.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "bpc_model = enkf_regressor_analysis(X_train,\n",
    "                                    X_test,\n",
    "                                    y_train,\n",
    "                                    y_test,\n",
    "                                    layers,\n",
    "                                    neurons,\n",
    "                                    setting_dict,\n",
    "                                    analysis_dict,\n",
    "                                    save_all = True,\n",
    "                                    file_var = \"../objects/wine/wine_enkf_E{}_B{}_P{}_H{}_BPC.pckl\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    file_model = \"../models/wine/wine_enkf_E{}_B{}_P{}_H{}_BPC.h5\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_mse(bpc_model,\n",
    "            mse_mean = None,\n",
    "            start_epoch = 1,\n",
    "            save = None)#\"../img/wine/wine_enkf_E{}_B{}_P{}_H{}_BPC.png\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_dict = {\"particles\": 181,\n",
    "                \"epochs\": 20,\n",
    "                \"batch_size\": len(X_train),    # len(X_train)\n",
    "                \"h_0\": 2,\n",
    "                \"epsilon\": 0.5,\n",
    "                \"shuffle\": True,\n",
    "                \"early_stopping\": None\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dict = {\"disjoint_batch\": True,\n",
    "                 \"batch_particle_connection\": {\"connect\": True,\n",
    "                                               \"shuffle\": \"particle\"},        # None, \"permute\", \"particle\", \"batch\", \"full\"\n",
    "                 \"tikhonov\": {\"regularize\": False,\n",
    "                              \"lambda\": 1}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training MSE: 17.244, Test MSE: 17.253.\n",
      "Epoch 2. Training MSE: 8.845, Test MSE: 8.852.\n",
      "Epoch 3. Training MSE: 4.928, Test MSE: 4.933.\n",
      "Epoch 4. Training MSE: 3.083, Test MSE: 3.086.\n",
      "Epoch 5. Training MSE: 2.183, Test MSE: 2.185.\n",
      "Epoch 6. Training MSE: 1.696, Test MSE: 1.698.\n",
      "Epoch 7. Training MSE: 1.361, Test MSE: 1.361.\n",
      "Epoch 8. Training MSE: 1.082, Test MSE: 1.079.\n",
      "Epoch 9. Training MSE: 0.918, Test MSE: 0.913.\n",
      "Epoch 10. Training MSE: 0.856, Test MSE: 0.852.\n",
      "Epoch 11. Training MSE: 0.826, Test MSE: 0.823.\n",
      "Epoch 12. Training MSE: 0.808, Test MSE: 0.806.\n",
      "Epoch 13. Training MSE: 0.797, Test MSE: 0.796.\n",
      "Epoch 14. Training MSE: 0.789, Test MSE: 0.79.\n",
      "Epoch 15. Training MSE: 0.784, Test MSE: 0.786.\n",
      "Epoch 16. Training MSE: 0.779, Test MSE: 0.782.\n",
      "Epoch 17. Training MSE: 0.776, Test MSE: 0.779.\n",
      "Epoch 18. Training MSE: 0.772, Test MSE: 0.775.\n",
      "Epoch 19. Training MSE: 0.767, Test MSE: 0.771.\n",
      "Epoch 20. Training MSE: 0.762, Test MSE: 0.766.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "eki_model = enkf_regressor_analysis(X_train,\n",
    "                                    X_test,\n",
    "                                    y_train,\n",
    "                                    y_test,\n",
    "                                    layers,\n",
    "                                    neurons,\n",
    "                                    setting_dict,\n",
    "                                    analysis_dict,\n",
    "                                    save_all = True,\n",
    "                                    file_var = \"../objects/wine/wine_enkf_E{}_B{}_P{}_H{}.pckl\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    file_model = \"../models/wine/wine_enkf_E{}_B{}_P{}_H{}.h5\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]),\n",
    "                                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_plot_mse(eki_model,\n",
    "            mse_mean = None,\n",
    "            start_epoch = 1,\n",
    "            save = None)#\"../img/wine/wine_enkf_E{}_B{}_P{}_H{}.png\".format(setting_dict[\"epochs\"], setting_dict[\"batch_size\"], setting_dict[\"particles\"], setting_dict[\"h_0\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
